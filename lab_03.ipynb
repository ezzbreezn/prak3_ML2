{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "lab_03_1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "9bfn8PwjWdRZ"
      ]
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Третье практическое задание. Реализация дропаута в рекуррентных нейронных сетях\n",
        "Практикум на ЭВМ для 317 группы, весна 2022\n",
        "\n",
        "#### Фамилия, имя: Михеев Борис\n",
        "\n",
        "Дата выдачи: 3 апреля 18:00\n",
        "\n",
        "Мягкий дедлайн: 17 апреля 23:59"
      ],
      "metadata": {
        "id": "Pe2L4CAwWdO4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Данное задание будет состоять из двух частей:\n",
        "1. Применение рекуррентной сети для решения задачи классификации текста. Более конкретно -- предсказания рейтинга отзыва фильма.\n",
        "2. Простейшая лингвистическая модель для генерации текста на основе LSTM."
      ],
      "metadata": {
        "id": "aWmbkHKWWdO-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "При выполнении задания вы обучите LSTM с разным уровнем \"коробочности\", а также познакомитесь с различными способами применения DropOut к рекуррентным архитектурам. В рекуррентных архитектурах вариантов, куда можно наложить бинарную маску шума, гораздо больше, чем в нейросетях прямого прохода.\n",
        "\n",
        "Во второй части вы попробуете реализовать простейший рекуррентный декодер для генерации текстов.\n",
        "\n",
        "Задание сделано так, чтобы его можно было выполнять на CPU, однако RNN - это ресурсоёмкая вещь, поэтому на GPU с ними работать приятнее. Можете попробовать использовать [https://colab.research.google.com](https://colab.research.google.com) - бесплатное облако с GPU."
      ],
      "metadata": {
        "id": "73FRVlItWdPA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Для корректного отображения картинок, вам может понадобится сделать ноутбук доверенным (Trusted) в правом верхнем углу**"
      ],
      "metadata": {
        "id": "JPHJxSgQWdPD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Часть 0. Загрузка и предобработка данных. (1 балл)"
      ],
      "metadata": {
        "id": "duiwjojSWdPF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Рекомендуемые гиперпараметры"
      ],
      "metadata": {
        "id": "9x9uRZ0UWdPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 200\n",
        "top_n_words = 5000\n",
        "\n",
        "hidden_dim = 128\n",
        "embedding_dim = 32\n",
        "\n",
        "num_epochs = 15\n",
        "batch_size = 64\n",
        "learning_rate = 1e-3"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:04:28.454122Z",
          "start_time": "2021-04-02T00:04:28.438278Z"
        },
        "execution": {
          "iopub.status.busy": "2022-04-12T19:35:50.527099Z",
          "iopub.execute_input": "2022-04-12T19:35:50.527366Z",
          "iopub.status.idle": "2022-04-12T19:35:50.531766Z",
          "shell.execute_reply.started": "2022-04-12T19:35:50.527335Z",
          "shell.execute_reply": "2022-04-12T19:35:50.530625Z"
        },
        "trusted": true,
        "id": "Ln9dumbuWdPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Первое, что нужно сделать -- скачать, предобработать данные и организовать их таким образом, чтобы их можно было подавать в нейронную сеть.\n",
        "\n",
        "Для обеих частей задания мы будем использовать [**Large Movie Review Dataset**](https://ai.stanford.edu/~amaas/data/sentiment/)."
      ],
      "metadata": {
        "id": "VRPe_N6XWdPL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Загрузка и предобработка данных"
      ],
      "metadata": {
        "id": "ljDBBmhHWdPM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузите данные по ссылке выше. (**tip**: используйте `wget`)"
      ],
      "metadata": {
        "id": "0Xi0yThmWdPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "!wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-30T18:34:47.261797Z",
          "start_time": "2021-03-30T18:34:33.768597Z"
        },
        "execution": {
          "iopub.status.busy": "2022-04-12T19:35:56.467197Z",
          "iopub.execute_input": "2022-04-12T19:35:56.467797Z",
          "iopub.status.idle": "2022-04-12T19:36:05.892810Z",
          "shell.execute_reply.started": "2022-04-12T19:35:56.467762Z",
          "shell.execute_reply": "2022-04-12T19:36:05.891905Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFAeCSOYWdPR",
        "outputId": "e8d15762-4bb8-4331-c1c5-5f6db9523d5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-15 07:02:21--  https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  64.4MB/s    in 1.2s    \n",
            "\n",
            "2022-04-15 07:02:22 (64.4 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Распакуйте скачанные данные в папку `aclImdb` (**tip:** используйте `tar`)"
      ],
      "metadata": {
        "id": "x8fhZfyPWdPS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "!tar -xzf aclImdb_v1.tar.gz"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-30T17:48:59.76399Z",
          "start_time": "2021-03-30T17:48:56.998383Z"
        },
        "execution": {
          "iopub.status.busy": "2022-04-12T19:36:09.635608Z",
          "iopub.execute_input": "2022-04-12T19:36:09.636138Z",
          "iopub.status.idle": "2022-04-12T19:36:17.514269Z",
          "shell.execute_reply.started": "2022-04-12T19:36:09.636101Z",
          "shell.execute_reply": "2022-04-12T19:36:17.513264Z"
        },
        "trusted": true,
        "id": "5CT1t0OLWdPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрите в файле `./aclImdb/README` как организованы данные"
      ],
      "metadata": {
        "id": "Wqowy4-hWdPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! cat ./aclImdb/train/pos/10003_8.txt"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T23:55:43.946032Z",
          "start_time": "2021-04-01T23:55:43.814779Z"
        },
        "execution": {
          "iopub.status.busy": "2022-04-12T19:36:20.795803Z",
          "iopub.execute_input": "2022-04-12T19:36:20.796327Z",
          "iopub.status.idle": "2022-04-12T19:36:21.492493Z",
          "shell.execute_reply.started": "2022-04-12T19:36:20.796286Z",
          "shell.execute_reply": "2022-04-12T19:36:21.491628Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCRdzotDWdPW",
        "outputId": "21e398f6-8ac4-4d56-ea00-27727d90c1fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is not the typical Mel Brooks film. It was much less slapstick than most of his movies and actually had a plot that was followable. Leslie Ann Warren made the movie, she is such a fantastic, under-rated actress. There were some moments that could have been fleshed out a bit more, and some scenes that could probably have been cut to make the room to do so, but all in all, this is worth the price to rent and see it. The acting was good overall, Brooks himself did a good job without his characteristic speaking to directly to the audience. Again, Warren was the best actor in the movie, but \"Fume\" and \"Sailor\" both played their parts well."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cat ./aclImdb/README"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-12T19:36:24.960572Z",
          "iopub.execute_input": "2022-04-12T19:36:24.960859Z",
          "iopub.status.idle": "2022-04-12T19:36:25.832256Z",
          "shell.execute_reply.started": "2022-04-12T19:36:24.960830Z",
          "shell.execute_reply": "2022-04-12T19:36:25.830899Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQnDw8DIWdPX",
        "outputId": "7859f47e-2511-4fd7-c465-ea744019fe56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Large Movie Review Dataset v1.0\n",
            "\n",
            "Overview\n",
            "\n",
            "This dataset contains movie reviews along with their associated binary\n",
            "sentiment polarity labels. It is intended to serve as a benchmark for\n",
            "sentiment classification. This document outlines how the dataset was\n",
            "gathered, and how to use the files provided. \n",
            "\n",
            "Dataset \n",
            "\n",
            "The core dataset contains 50,000 reviews split evenly into 25k train\n",
            "and 25k test sets. The overall distribution of labels is balanced (25k\n",
            "pos and 25k neg). We also include an additional 50,000 unlabeled\n",
            "documents for unsupervised learning. \n",
            "\n",
            "In the entire collection, no more than 30 reviews are allowed for any\n",
            "given movie because reviews for the same movie tend to have correlated\n",
            "ratings. Further, the train and test sets contain a disjoint set of\n",
            "movies, so no significant performance is obtained by memorizing\n",
            "movie-unique terms and their associated with observed labels.  In the\n",
            "labeled train/test sets, a negative review has a score <= 4 out of 10,\n",
            "and a positive review has a score >= 7 out of 10. Thus reviews with\n",
            "more neutral ratings are not included in the train/test sets. In the\n",
            "unsupervised set, reviews of any rating are included and there are an\n",
            "even number of reviews > 5 and <= 5.\n",
            "\n",
            "Files\n",
            "\n",
            "There are two top-level directories [train/, test/] corresponding to\n",
            "the training and test sets. Each contains [pos/, neg/] directories for\n",
            "the reviews with binary labels positive and negative. Within these\n",
            "directories, reviews are stored in text files named following the\n",
            "convention [[id]_[rating].txt] where [id] is a unique id and [rating] is\n",
            "the star rating for that review on a 1-10 scale. For example, the file\n",
            "[test/pos/200_8.txt] is the text for a positive-labeled test set\n",
            "example with unique id 200 and star rating 8/10 from IMDb. The\n",
            "[train/unsup/] directory has 0 for all ratings because the ratings are\n",
            "omitted for this portion of the dataset.\n",
            "\n",
            "We also include the IMDb URLs for each review in a separate\n",
            "[urls_[pos, neg, unsup].txt] file. A review with unique id 200 will\n",
            "have its URL on line 200 of this file. Due the ever-changing IMDb, we\n",
            "are unable to link directly to the review, but only to the movie's\n",
            "review page.\n",
            "\n",
            "In addition to the review text files, we include already-tokenized bag\n",
            "of words (BoW) features that were used in our experiments. These \n",
            "are stored in .feat files in the train/test directories. Each .feat\n",
            "file is in LIBSVM format, an ascii sparse-vector format for labeled\n",
            "data.  The feature indices in these files start from 0, and the text\n",
            "tokens corresponding to a feature index is found in [imdb.vocab]. So a\n",
            "line with 0:7 in a .feat file means the first word in [imdb.vocab]\n",
            "(the) appears 7 times in that review.\n",
            "\n",
            "LIBSVM page for details on .feat file format:\n",
            "http://www.csie.ntu.edu.tw/~cjlin/libsvm/\n",
            "\n",
            "We also include [imdbEr.txt] which contains the expected rating for\n",
            "each token in [imdb.vocab] as computed by (Potts, 2011). The expected\n",
            "rating is a good way to get a sense for the average polarity of a word\n",
            "in the dataset.\n",
            "\n",
            "Citing the dataset\n",
            "\n",
            "When using this dataset please cite our ACL 2011 paper which\n",
            "introduces it. This paper also contains classification results which\n",
            "you may want to compare against.\n",
            "\n",
            "\n",
            "@InProceedings{maas-EtAl:2011:ACL-HLT2011,\n",
            "  author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\n",
            "  title     = {Learning Word Vectors for Sentiment Analysis},\n",
            "  booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\n",
            "  month     = {June},\n",
            "  year      = {2011},\n",
            "  address   = {Portland, Oregon, USA},\n",
            "  publisher = {Association for Computational Linguistics},\n",
            "  pages     = {142--150},\n",
            "  url       = {http://www.aclweb.org/anthology/P11-1015}\n",
            "}\n",
            "\n",
            "References\n",
            "\n",
            "Potts, Christopher. 2011. On the negativity of negation. In Nan Li and\n",
            "David Lutz, eds., Proceedings of Semantics and Linguistic Theory 20,\n",
            "636-659.\n",
            "\n",
            "Contact\n",
            "\n",
            "For questions/comments/corrections please contact Andrew Maas\n",
            "amaas@cs.stanford.edu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_path = './aclImdb/test/'\n",
        "train_data_path = './aclImdb/train/'"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:04:33.729663Z",
          "start_time": "2021-04-02T00:04:33.710871Z"
        },
        "execution": {
          "iopub.status.busy": "2022-04-12T19:36:30.527873Z",
          "iopub.execute_input": "2022-04-12T19:36:30.528522Z",
          "iopub.status.idle": "2022-04-12T19:36:30.533464Z",
          "shell.execute_reply.started": "2022-04-12T19:36:30.528482Z",
          "shell.execute_reply": "2022-04-12T19:36:30.532441Z"
        },
        "trusted": true,
        "id": "QvU9AglqWdPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from functools import partial\n",
        "from collections import defaultdict\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import regex\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torchtext\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:04:33.709378Z",
          "start_time": "2021-04-02T00:04:32.22058Z"
        },
        "execution": {
          "iopub.status.busy": "2022-04-12T19:36:32.295425Z",
          "iopub.execute_input": "2022-04-12T19:36:32.295733Z",
          "iopub.status.idle": "2022-04-12T19:36:32.303295Z",
          "shell.execute_reply.started": "2022-04-12T19:36:32.295688Z",
          "shell.execute_reply": "2022-04-12T19:36:32.302250Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXou3AemWdPa",
        "outputId": "470c03a3-5b20-4d30-96fd-075bace33ee1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Стандартной предобработкой данных является токенизация текстов. Полученные токены можно будет закодировать и затем подавать на вход нейронной сети. Ключевым моментом, который влияет на скорость работы нейросети и её размер в памяти -- размер словаря, используемого при токенизации. Для задачи классификации мы можем убрать часть слов (стоп слова, редкие слова), ускорив обучение без потери в качестве."
      ],
      "metadata": {
        "id": "wx6dKHKHWdPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "STOPWORDS = nltk.corpus.stopwords.words('english')"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:04:35.270825Z",
          "start_time": "2021-04-02T00:04:35.250283Z"
        },
        "execution": {
          "iopub.status.busy": "2022-04-12T19:36:36.240275Z",
          "iopub.execute_input": "2022-04-12T19:36:36.241035Z",
          "iopub.status.idle": "2022-04-12T19:36:36.246207Z",
          "shell.execute_reply.started": "2022-04-12T19:36:36.240995Z",
          "shell.execute_reply": "2022-04-12T19:36:36.245104Z"
        },
        "trusted": true,
        "id": "Sa5tmdGPWdPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Реализуйте функцию для токенизации текста. Выполнять токенизацию можно по-разному, но в данном задании предлагается это делать следующим образом:\n",
        "1. Привести текст к нижнему регистру\n",
        "2. Убрать html разметку из текстов (`<br />`)\n",
        "3. Убрать все символы кроме латинских букв\n",
        "4. Разбить строку по пробелам\n",
        "5. Убрать стоп слова"
      ],
      "metadata": {
        "id": "bIoMZTxTWdPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text):\n",
        "    \"\"\"\n",
        "    :param str text: Input text \n",
        "    :return List[str]: List of words\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "    preprocessed_text = regex.sub('<br />', '', text.lower())\n",
        "    list_of_words = [word for word in regex.findall('[a-z]+', preprocessed_text) if word not in STOPWORDS]\n",
        "    return list_of_words"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:04:36.003194Z",
          "start_time": "2021-04-02T00:04:35.980408Z"
        },
        "execution": {
          "iopub.status.busy": "2022-04-12T19:36:39.479185Z",
          "iopub.execute_input": "2022-04-12T19:36:39.479824Z",
          "iopub.status.idle": "2022-04-12T19:36:39.484913Z",
          "shell.execute_reply.started": "2022-04-12T19:36:39.479784Z",
          "shell.execute_reply": "2022-04-12T19:36:39.483690Z"
        },
        "trusted": true,
        "id": "P4NYlg4zWdPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize('1. Hello <br /> words!! <br />')"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T21:27:12.428149Z",
          "start_time": "2021-04-01T21:27:12.402448Z"
        },
        "execution": {
          "iopub.status.busy": "2022-04-12T19:36:41.216865Z",
          "iopub.execute_input": "2022-04-12T19:36:41.217449Z",
          "iopub.status.idle": "2022-04-12T19:36:41.225361Z",
          "shell.execute_reply.started": "2022-04-12T19:36:41.217414Z",
          "shell.execute_reply": "2022-04-12T19:36:41.224506Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mP4bTvwNWdPf",
        "outputId": "6dc6ef02-45cb-48c8-bfc9-dd1ed91cfc9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hello', 'words']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь мы можем создать словарь, с помощью которого мы будем численно кодировать токены из текста и наоборот.\n",
        "\n",
        "Удобной обёрткой для создания словарей является класс `torchtext.vocab.Vocab` и фабрика для создания таких классов `torchtext.vocab.vocab`."
      ],
      "metadata": {
        "id": "TquXrcbIWdPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torchtext.vocab.vocab??"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T21:27:21.466887Z",
          "start_time": "2021-04-01T21:27:21.352085Z"
        },
        "execution": {
          "iopub.status.busy": "2022-04-12T19:36:44.188033Z",
          "iopub.execute_input": "2022-04-12T19:36:44.188305Z",
          "iopub.status.idle": "2022-04-12T19:36:44.204350Z",
          "shell.execute_reply.started": "2022-04-12T19:36:44.188276Z",
          "shell.execute_reply": "2022-04-12T19:36:44.203587Z"
        },
        "trusted": true,
        "id": "BLxH9kKpWdPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Чтобы создать такой словарь, сначала нужно создать словарь со всеми токенами в тексте и их частотами встречаемости:"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T19:51:55.300753Z",
          "start_time": "2021-04-01T19:51:55.275188Z"
        },
        "id": "RPSxldR_WdPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "counter = defaultdict(int)\n",
        "\n",
        "for path in ['./aclImdb/test/neg', './aclImdb/test/pos', './aclImdb/train/neg', './aclImdb/train/pos']:\n",
        "    for file_path in os.listdir(path):\n",
        "        text = open(os.path.join(path, file_path), 'r', encoding='utf-8', errors='ignore').read().strip()\n",
        "        for token in tokenize(text):\n",
        "            counter[token] += 1"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:05:13.547038Z",
          "start_time": "2021-04-02T00:04:38.190688Z"
        },
        "execution": {
          "iopub.status.busy": "2022-04-12T19:36:47.275428Z",
          "iopub.execute_input": "2022-04-12T19:36:47.275833Z",
          "iopub.status.idle": "2022-04-12T19:37:15.627321Z",
          "shell.execute_reply.started": "2022-04-12T19:36:47.275783Z",
          "shell.execute_reply": "2022-04-12T19:37:15.626616Z"
        },
        "trusted": true,
        "id": "9SGgkZKUWdPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для работы с текстами нам необходимо зарезервировать два специальных токена:\n",
        "1. `<pad>` для токена означающего паддинг\n",
        "2. `<unk>` для токенов, которые отсутствуют в словаре"
      ],
      "metadata": {
        "id": "__6YqNxXWdPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "specials = ['<pad>', '<unk>']\n",
        "for special in specials:\n",
        "    counter[special] = 0"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T21:28:18.239274Z",
          "start_time": "2021-04-01T21:28:18.214979Z"
        },
        "execution": {
          "iopub.status.busy": "2022-04-12T19:37:21.827939Z",
          "iopub.execute_input": "2022-04-12T19:37:21.828195Z",
          "iopub.status.idle": "2022-04-12T19:37:21.832104Z",
          "shell.execute_reply.started": "2022-04-12T19:37:21.828164Z",
          "shell.execute_reply": "2022-04-12T19:37:21.831144Z"
        },
        "trusted": true,
        "id": "m9YEwluNWdPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создайте словарь из словаря частот `counter`. Наименьшие id отдайте под специальные токены. \n",
        "\n",
        "Отбросьте низкочастотные слова, оставив только `top_n_words` слов. Можете использовать любой способ реализации этого условия, например:\n",
        "1. Оставить в словаре `counter` нужное число слов\n",
        "2. Подобрать параметр `min_freq`, чтобы оставшееся число слов было близко к необходимому порогу"
      ],
      "metadata": {
        "id": "AUbmjSoFWdPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "from collections import OrderedDict\n",
        "sorted_by_freq_tuples = sorted(counter.items(), key=lambda x: x[1], reverse=True)[:top_n_words]\n",
        "ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
        "vocab = torchtext.vocab.vocab(ordered_dict)\n",
        "vocab.insert_token('<pad>', 0)\n",
        "vocab.insert_token('<unk>', 1)\n",
        "vocab.set_default_index(vocab['<unk>'])"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T21:28:23.041153Z",
          "start_time": "2021-04-01T21:28:22.899444Z"
        },
        "execution": {
          "iopub.status.busy": "2022-04-12T19:37:30.363236Z",
          "iopub.execute_input": "2022-04-12T19:37:30.363507Z",
          "iopub.status.idle": "2022-04-12T19:37:30.497483Z",
          "shell.execute_reply.started": "2022-04-12T19:37:30.363477Z",
          "shell.execute_reply": "2022-04-12T19:37:30.496722Z"
        },
        "trusted": true,
        "id": "Va8c-WD3WdPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab.lookup_indices(['<pad>', '<unk>'])"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T21:28:24.332126Z",
          "start_time": "2021-04-01T21:28:24.30689Z"
        },
        "execution": {
          "iopub.status.busy": "2022-04-12T19:37:32.039487Z",
          "iopub.execute_input": "2022-04-12T19:37:32.040287Z",
          "iopub.status.idle": "2022-04-12T19:37:32.050967Z",
          "shell.execute_reply.started": "2022-04-12T19:37:32.040238Z",
          "shell.execute_reply": "2022-04-12T19:37:32.050070Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84pbbT-eWdPo",
        "outputId": "cdf5ece4-6ff1-4e47-fcf2-c88a9c324d44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab.lookup_indices(['this', 'film', 'was', 'awful'])"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T21:28:26.25491Z",
          "start_time": "2021-04-01T21:28:26.231012Z"
        },
        "execution": {
          "iopub.status.busy": "2022-04-12T19:37:33.171524Z",
          "iopub.execute_input": "2022-04-12T19:37:33.172189Z",
          "iopub.status.idle": "2022-04-12T19:37:33.179442Z",
          "shell.execute_reply.started": "2022-04-12T19:37:33.172149Z",
          "shell.execute_reply": "2022-04-12T19:37:33.178715Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAB1hIiSWdPo",
        "outputId": "2f6ccf83-eb19-4c93-f1d4-4c45e8e629f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 3, 1, 254]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь мы готовы создать обёртку-датасет для наших данных. \n",
        "\n",
        "Необходимо добавить несколько опции, которые понадобятся во второй части задания:\n",
        "1. Ограничение на максимальную длину текста в токенах. Если текст оказывается длиннее, то последние токены отбрасываются\n",
        "2. Возможность добавить в специальные токены `<sos>`, `<eos>` в начало и конец токенизированного текста\n",
        "    \n",
        "**tips:**\n",
        "1. Обратите особое внимание, что у длинных текстов не должен обрезаться паддинг\n",
        "2. В исходных данных рейтинг закодирован в названии файла в виде числа от 1 до 10. Для удобства, вычтите 1, чтобы рейтинг был от 0 до 9"
      ],
      "metadata": {
        "id": "9OcrHzxMWdPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LargeMovieReviewDataset(Dataset):\n",
        "    def __init__(self, data_path, vocab, max_len, pad_sos=False, pad_eos=False):\n",
        "        \"\"\"\n",
        "        :param str data_path: Path to folder with one of the data splits (train or test)\n",
        "        :param torchtext.vocab.Vocab vocab: dictionary with lookup_indices method\n",
        "        :param int max_len: Maximum length of tokenized text\n",
        "        :param bool pad_sos: If True pad sequence at the beginning with <sos> \n",
        "        :param bool pad_eos: If True pad sequence at the end with <eos>         \n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        \n",
        "        self.pad_sos = pad_sos\n",
        "        if self.pad_sos:\n",
        "            self.sos_id = vocab.lookup_indices(['<sos>'])[0]\n",
        "        self.pad_eos = pad_eos\n",
        "        if self.pad_eos:\n",
        "            self.eos_id = vocab.lookup_indices(['<eos>'])[0]\n",
        "        \n",
        "        self.vocab = vocab\n",
        "        self.max_len = max_len\n",
        "        self.data_path = data_path\n",
        "        self.negative_path = os.path.join(data_path, 'neg')\n",
        "        self.positive_path = os.path.join(data_path, 'pos')\n",
        "        \n",
        "        self.negative_paths = []\n",
        "        self.positive_paths = []\n",
        "\n",
        "        for file_path in os.listdir(self.negative_path):\n",
        "            self.negative_paths.append(os.path.join(self.negative_path, file_path))\n",
        "\n",
        "        for file_path in os.listdir(self.positive_path):\n",
        "            self.positive_paths.append(os.path.join(self.positive_path, file_path))\n",
        "        \n",
        "        self.texts = []\n",
        "        self.tokens = []\n",
        "        self.ratings = []\n",
        "        self.labels = [0] * len(self.negative_paths) + [1] * len(self.positive_paths)\n",
        "        \n",
        "        # Read each file in data_path, tokenize it, get tokens ids, its rating and store\n",
        "        for path in self.negative_paths + self.positive_paths:\n",
        "            # YOUR CODE HERE\n",
        "            with open(path, 'r') as f:\n",
        "                content = f.read()\n",
        "            self.texts.append(content)\n",
        "            self.tokens.append(vocab.lookup_indices(tokenize(content)))\n",
        "            rating = int(path[-5])\n",
        "            if rating == 0:\n",
        "                rating = 9\n",
        "            else:\n",
        "                rating -= 1\n",
        "            self.ratings.append(rating)\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        :param int idx: index of object in dataset\n",
        "        :return dict: Dictionary with all useful object data \n",
        "            {\n",
        "                'text' str: unprocessed text,\n",
        "                'label' torch.tensor(dtype=torch.long): sentiment of the text (0 for negative, 1 for positive)\n",
        "                'rating' torch.tensor(dtype=torch.long): rating of the text\n",
        "                'tokens' torch.tensor(dtype=torch.long): tensor of tokens ids for the text\n",
        "                'tokens_len' torch.tensor(dtype=torch.long): number of tokens\n",
        "            }\n",
        "        \"\"\"\n",
        "        # YOUR CODE HERE\n",
        "        # Do not forget to add padding if needed!\n",
        "        tokens = []\n",
        "        sos_len = 0\n",
        "        if self.pad_sos:\n",
        "            tokens += [self.sos_id]\n",
        "            sos_len += 1\n",
        "        tokens += self.tokens[idx][:self.max_len]\n",
        "        eos_len = 0\n",
        "        if self.pad_eos:\n",
        "            tokens += [self.eos_id]\n",
        "            eos_len += 1\n",
        "        data = {\n",
        "            'text': self.texts[idx],\n",
        "            'label': torch.tensor(self.labels[idx], dtype=torch.long),\n",
        "            'rating': torch.tensor(self.ratings[idx], dtype=torch.long),\n",
        "            'tokens': torch.tensor(tokens, dtype=torch.long),\n",
        "            'tokens_len': torch.tensor(len(tokens) - sos_len - eos_len, dtype=torch.long)\n",
        "        }\n",
        "        return data\n",
        "        \n",
        "    \n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        :return int: number of objects in dataset \n",
        "        \"\"\"\n",
        "        # YOUR CODE HERE\n",
        "        return len(self.texts)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:05:13.573249Z",
          "start_time": "2021-04-02T00:05:13.548593Z"
        },
        "execution": {
          "iopub.status.busy": "2022-04-12T19:55:13.289464Z",
          "iopub.execute_input": "2022-04-12T19:55:13.289809Z",
          "iopub.status.idle": "2022-04-12T19:55:13.315329Z",
          "shell.execute_reply.started": "2022-04-12T19:55:13.289772Z",
          "shell.execute_reply": "2022-04-12T19:55:13.314596Z"
        },
        "trusted": true,
        "id": "0DmyxNLYWdPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создайте датасеты для тестовой и обучающей выборки. \n",
        "\n",
        "Обратите внимание, что для задачи классификации нам не потребуется паддинг с помощью `<sos>`, `<eos>`. \n",
        "\n",
        "Не забудьте обрезать длинные тексты, передав параметр `max_length`."
      ],
      "metadata": {
        "id": "0d8XYTvgWdPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "test_dataset = LargeMovieReviewDataset(test_data_path, vocab, max_length)\n",
        "train_dataset = LargeMovieReviewDataset(train_data_path, vocab, max_length)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T21:31:32.123618Z",
          "start_time": "2021-04-01T21:30:54.950259Z"
        },
        "execution": {
          "iopub.status.busy": "2022-04-12T19:55:16.856644Z",
          "iopub.execute_input": "2022-04-12T19:55:16.856934Z",
          "iopub.status.idle": "2022-04-12T19:55:44.636970Z",
          "shell.execute_reply.started": "2022-04-12T19:55:16.856904Z",
          "shell.execute_reply": "2022-04-12T19:55:44.636155Z"
        },
        "trusted": true,
        "id": "BDTTlrqfWdPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрим, как выглядит объект в датасете:"
      ],
      "metadata": {
        "id": "o_hZk9-AWdPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset[0]"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T21:31:36.017106Z",
          "start_time": "2021-04-01T21:31:35.988797Z"
        },
        "execution": {
          "iopub.status.busy": "2022-04-12T19:55:59.993661Z",
          "iopub.execute_input": "2022-04-12T19:55:59.993924Z",
          "iopub.status.idle": "2022-04-12T19:56:00.021951Z",
          "shell.execute_reply.started": "2022-04-12T19:55:59.993896Z",
          "shell.execute_reply": "2022-04-12T19:56:00.021261Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_ON4leCWdPu",
        "outputId": "b62c883f-88e7-45b7-ed46-408267e9630a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': tensor(0),\n",
              " 'rating': tensor(3),\n",
              " 'text': \"Oh dear! The BBC is not about to be knocked off its pedestal for absorbing period dramas by this one. I agree this novel of Jane Austens is the difficult to portray particularly to a modern audience, the heroine is hardly a Elizabeth Bennet, even Edmund is not calculated to cause female hearts to skip a beat. However I must say I was hoping for an improvement on the last and was sadly disappointed. The basic story was preserved, but the dialogue was so altered that all that was Jane Austen's tone, manner, feeling, wit, depth, was diluted if not lost. If some past adaptions may be seen as dated the weakness of this one must be that it is too modern ('his life is one long party'?????) The cast was generally adequate, but I think Billie Piper was the wrong choice, it needed someone more restrained, I gained no impression of hidden depths beneath a submissive exterior, she was more like a frolicking child. I see I must wait for the BBC to weave its magic once again.\",\n",
              " 'tokens': tensor([ 300, 2799, 2000,    1,    1,    1,  681, 3011,    4,  870,  537,  937,\n",
              "            1,  733, 1890,  448,  547,  186, 1724,  881, 2273,    1,    8,    1,\n",
              "            1,  914,  517, 3039, 1689, 1328,   88,   98,   49, 1244, 4848,  128,\n",
              "          918,  541, 1012,   10,    1,  289,    1,  937, 3335, 1107, 1259,  424,\n",
              "         2100,  974,    1,  303,  379,    1,   95,   33, 1873,    1,    4,   98,\n",
              "          547,   37,    4,   93,  846,   76, 1142, 3980,   27,    1,    1,  237,\n",
              "          957,  736,  169,    1,    1, 1230, 1546,    1, 3824,    1,    1,    5,\n",
              "            1,  374,   12,   98,  709, 2000,    1, 1180]),\n",
              " 'tokens_len': tensor(92)}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь нам нужно создать `DataLoader` для наших данных. `DataLoader` умеет из коробки объединять список объектов из датасета в один батч, даже когда датасет возвращает словарь тензоров. Однако, это работает только в случае когда все эти тензоры имеют один и тот же размер во всех батчах. В нашем случае, это не так, так как разные тексты могут иметь разную длину.\n",
        "\n",
        "Чтобы обойти эту проблему у `DataLoader` есть параметр `collate_fn`, который позволяет задать функцию для объединения списка объектов в один батч."
      ],
      "metadata": {
        "id": "9pHpmHXQWdPv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Чтобы объединить несколько тензоров разной длины в один можно использовать функцию `torch.nn.utils.rnn.pad_sequence`\n",
        "\n",
        "Обратите внимание на её аргументы:\n",
        "1. `batch_first` определяет по какой оси \"складывать\" тензоры. Предпочтительнее использовать `batch_first=False` так как это может упростить выполнение задания в дальнейшем \n",
        "2. `padding_value` -- число, которое будет использоваться в качестве паддинга, чтобы сделать все тензоры одинаковой длины"
      ],
      "metadata": {
        "id": "4gTaMds0WdPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.nn.utils.rnn.pad_sequence([\n",
        "    torch.tensor([1, 2, 3]),\n",
        "    torch.tensor([4, 5]),\n",
        "    torch.tensor([6, 7, 8, 9])\n",
        "], batch_first=False, padding_value=-1)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T21:33:06.372403Z",
          "start_time": "2021-04-01T21:33:06.344559Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RU0e-2vQWdPw",
        "outputId": "27792396-4fac-4bf0-b84c-168fc817e8a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1,  4,  6],\n",
              "        [ 2,  5,  7],\n",
              "        [ 3, -1,  8],\n",
              "        [-1, -1,  9]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch, padding_value, batch_first=False):\n",
        "    \"\"\"\n",
        "    :param List[Dict] batch: List of objects from dataset\n",
        "    :param int padding_value: Value that will be used to pad tokens\n",
        "    :param bool batch_first: If True resulting tensor with tokens must have shape [B, T] otherwise [T, B]\n",
        "    :return dict: Dictionary with all data collated\n",
        "        {\n",
        "            'ratings' torch.tensor(dtype=torch.long): rating of the text for each object in batch\n",
        "            'labels' torch.tensor(dtype=torch.long): sentiment of the text for each object in batch\n",
        "            \n",
        "            'texts' List[str]: All texts in one list\n",
        "            'tokens' torch.tensor(dtype=torch.long): tensor of tokens ids padded with @padding_value\n",
        "            'tokens_lens' torch.tensor(dtype=torch.long): number of tokens for each object in batch\n",
        "        }\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "    common = {'rating': [], 'label': [], 'text': [], 'tokens': [], 'tokens_len': []}\n",
        "    for obj in batch:\n",
        "        for key, value in obj.items():\n",
        "            common[key].append(value)\n",
        "    data = {\n",
        "        'ratings': torch.stack(common['rating']),\n",
        "        'labels': torch.stack(common['label']),\n",
        "        'texts': common['text'],\n",
        "        'tokens': torch.nn.utils.rnn.pad_sequence(common['tokens'], batch_first, padding_value),\n",
        "        'tokens_lens': torch.stack(common['tokens_len'])    \n",
        "    }\n",
        "    return data"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:05:13.709466Z",
          "start_time": "2021-04-02T00:05:13.575053Z"
        },
        "id": "lXDe7-pPWdPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создайте даталоадеры с использованием `collate_fn`.\n",
        "\n",
        "**tips**:\n",
        "1. Передать в `collate_fn` правильное значение паддинга можно, например, с помощью `functools.partial`\n",
        "2. Если вы работаете в Google Colab, то, возможно, вам будет необходимо установить `num_workers=0` во избежание падения ноутбука."
      ],
      "metadata": {
        "id": "aGdj7kZ9WdPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "padding_value = vocab.lookup_indices(['<pad>'])[0]\n",
        "\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=partial(collate_fn, padding_value=padding_value), num_workers=0, shuffle=False)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=partial(collate_fn, padding_value=padding_value), num_workers=0, shuffle=True)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T21:33:37.87276Z",
          "start_time": "2021-04-01T21:33:37.847071Z"
        },
        "id": "n24VZHqMWdPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрим на какой-нибудь батч:"
      ],
      "metadata": {
        "id": "62yT-S5jWdP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(test_dataloader))\n",
        "batch.keys(), batch['labels'], batch['ratings'], batch['tokens'], batch['tokens_lens']"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T21:33:46.922744Z",
          "start_time": "2021-04-01T21:33:46.755275Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDdGyllGWdP0",
        "outputId": "c015e090-805c-499f-eb01-ddfe649b9ebc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(dict_keys(['ratings', 'labels', 'texts', 'tokens', 'tokens_lens']),\n",
              " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " tensor([3, 3, 3, 0, 3, 3, 2, 3, 2, 0, 3, 0, 0, 3, 3, 0, 0, 1, 3, 1, 1, 3, 0, 3,\n",
              "         3, 2, 2, 0, 2, 3, 1, 0, 2, 3, 2, 1, 3, 1, 0, 3, 1, 0, 0, 0, 0, 0, 0, 3,\n",
              "         3, 1, 0, 1, 0, 0, 2, 2, 2, 0, 3, 2, 0, 0, 3, 3]),\n",
              " tensor([[ 300,    2,  294,  ...,  210,  362,   13],\n",
              "         [2799,   60,    1,  ...,    2, 1476,  221],\n",
              "         [2000,  363,   99,  ..., 1867,   31,  156],\n",
              "         ...,\n",
              "         [   0,    0,    0,  ...,    0,    0,    0],\n",
              "         [   0,    0,    0,  ...,    0,    0,    0],\n",
              "         [   0,    0,    0,  ...,    0,    0,    0]]),\n",
              " tensor([ 92,  70,  73,  78,  95,  54,  65,  33,  48,  93,  84, 200, 187, 200,\n",
              "          76, 188,  87,  83, 200,  91,  75, 182,  79,  85, 138, 200, 196,  47,\n",
              "          76,  94,  76, 149,  94, 100,  73, 193,  78, 200,  79, 186, 120,  71,\n",
              "          90, 125, 200, 148, 112,  55, 176, 123,  90, 103,  57,  69,  92,  81,\n",
              "         150,  99, 102, 133,  55,  27,  61, 123]))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Часть 1. Классификация текстов. (6 баллов)"
      ],
      "metadata": {
        "id": "VtrUYPf5WdP1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Сборка и обучение RNN в pytorch (2 балла)"
      ],
      "metadata": {
        "id": "iAk3wwZOWdP3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим переменные для device-agnostic кода:"
      ],
      "metadata": {
        "id": "R3RPC-gxWdP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dtype, device, cuda_device_id = torch.float32, None, 0\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '{0}'.format(str(cuda_device_id) if cuda_device_id is not None else '')\n",
        "if cuda_device_id is not None and torch.cuda.is_available():\n",
        "    device = 'cuda:{0:d}'.format(0)\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "print(f'Using device: {device}, dtype: {dtype}')"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:05:13.809416Z",
          "start_time": "2021-04-02T00:05:13.711383Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhON95eVWdP5",
        "outputId": "8e4f3074-3247-404f-d47e-4033a189db7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0, dtype: torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Наша нейросеть будет обрабатывать входную последовательность по словам (word level). Мы будем использовать простую и стандартную рекуррентную архитектуру для классификации:\n",
        "1. Слой представлений, превращающий id токена в вектор-ембеддинг этого слова\n",
        "2. Слой LSTM\n",
        "3. Полносвязный слой, предсказывающий выход по последнему скрытому состоянию\n",
        "\n",
        "Ниже дан код для сборки и обучения нашей нейросети."
      ],
      "metadata": {
        "id": "kAZWBry-WdP5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Допишите класс-обёртку над LSTM для задачи классификации. \n",
        "**Не используйте циклы.**"
      ],
      "metadata": {
        "id": "GvtmDnhGWdP7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Для каждого тензора в функции `forward` подпишите в комментарии его размеры**"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T20:59:16.467178Z",
          "start_time": "2021-04-01T20:59:16.441112Z"
        },
        "id": "at96jGwpWdP7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNClassifier(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self, embedding_dim, hidden_dim, output_size, vocab,\n",
        "        rec_layer=torch.nn.LSTM, dropout=None, **kwargs\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dropout = dropout\n",
        "        \n",
        "        self.vocab = vocab\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_size = output_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        \n",
        "        # Create a simple lookup table that stores embeddings of a fixed dictionary and size.\n",
        "        #    Use torch.nn.Embedding. Do not forget specify padding_idx!\n",
        "        # YOUR CODE HERE\n",
        "        self.word_embeddings = torch.nn.Embedding(num_embeddings=len(vocab), embedding_dim=embedding_dim, padding_idx=vocab.lookup_indices(['<pad>'])[0])\n",
        "        \n",
        "        if dropout is not None:\n",
        "            self.rnn = rec_layer(self.embedding_dim, self.hidden_dim, dropout=self.dropout, **kwargs)\n",
        "        else:\n",
        "            self.rnn = rec_layer(self.embedding_dim, self.hidden_dim, **kwargs)\n",
        "        \n",
        "        # Create linear layer for classification\n",
        "        # YOUR CODE HERE\n",
        "        self.output = torch.nn.Linear(hidden_dim, output_size)\n",
        "    \n",
        "    def forward(self, tokens, tokens_lens):\n",
        "        \"\"\"\n",
        "        :param torch.tensor(dtype=torch.long) tokens: Batch of texts represented with tokens.\n",
        "        :param torch.tensor(dtype=torch.long) tokens_lens: Number of non-padding tokens for each object in batch.\n",
        "        :return torch.tensor(dtype=torch.long): Vector representation for each sequence in batch\n",
        "        \"\"\"\n",
        "        # Evaluate embeddings\n",
        "        # YOUR CODE HERE\n",
        "        # Size: (tokens.size(0), tokens.size(1), self.embedding_dim)\n",
        "        res = self.word_embeddings(tokens)\n",
        "        \n",
        "        # Make forward pass through recurrent network\n",
        "        # YOUR CODE HERE\n",
        "        # Size: (tokens.size(0), tokens.size(1), self.hidden_dim)\n",
        "        res = self.rnn(res)[0]\n",
        "\n",
        "        # Pass output from rnn to linear layer \n",
        "        # Note: each object in batch has its own length \n",
        "        #     so we must take rnn hidden state after the last token for each text in batch\n",
        "        # YOUR CODE HERE\n",
        "        # Size: (tokens.size(1), self.hidden_dim)\n",
        "        res = res[tokens_lens - 1, torch.arange(len(tokens_lens))]\n",
        "        # Size: (tokens.size(1), self.output_size)\n",
        "        res = self.output(res)\n",
        "        return res"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:05:13.873713Z",
          "start_time": "2021-04-02T00:05:13.81069Z"
        },
        "id": "DQ-3xQmuWdP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Исходный код LSTM](http://pytorch.org/docs/master/_modules/torch/nn/modules/rnn.html#LSTM)"
      ],
      "metadata": {
        "id": "AYT9t-Z-WdP9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Допишите функции для обучения и оценки модели:\n",
        "\n",
        "**tip:**\n",
        "1. В функции `evaluate` при подсчёте метрик учитывайте, что батчи могут иметь разный размер. (в частности последний батч)"
      ],
      "metadata": {
        "id": "C1dxybCzWdP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(dataloader, model, loss_fn, optimizer, device):\n",
        "    model.train()\n",
        "    for idx, data in enumerate(dataloader):\n",
        "        # 1. Take data from batch\n",
        "        # 2. Perform forward pass\n",
        "        # 3. Evaluate loss\n",
        "        # 4. Make optimizer step\n",
        "        # YOUR CODE HERE\n",
        "        model.zero_grad()\n",
        "        ratings = data['ratings'].to(device)\n",
        "        tokens = data['tokens'].to(device)\n",
        "        tokens_lens = data['tokens_lens'].to(device)\n",
        "        res = model(tokens, tokens_lens)\n",
        "        loss = loss_fn(res, ratings)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "def evaluate(dataloader, model, loss_fn, device):\n",
        "    model.eval()\n",
        "    \n",
        "    total_loss = 0.0\n",
        "    total_accuracy = 0.0\n",
        "    with torch.no_grad():\n",
        "        for idx, data in enumerate(dataloader):\n",
        "            # 1. Take data from batch\n",
        "            # 2. Perform forward pass\n",
        "            # 3. Evaluate loss\n",
        "            # 4. Evaluate accuracy\n",
        "            # YOUR CODE HERE\n",
        "            ratings = data['ratings'].to(device)\n",
        "            tokens = data['tokens'].to(device)\n",
        "            tokens_lens = data['tokens_lens'].to(device)\n",
        "            res = model(tokens, tokens_lens)\n",
        "            # Т. к. используем усреднение по батчу в дальнейшем\n",
        "            total_loss += loss_fn(res, ratings).item() * len(ratings)\n",
        "            total_accuracy += (res.argmax(axis=1) == ratings).sum().item()\n",
        "        \n",
        "    return total_loss / len(dataloader.dataset), total_accuracy / len(dataloader.dataset)\n",
        "    \n",
        "\n",
        "def train(\n",
        "    train_loader, test_loader, model, loss_fn, optimizer, device, num_epochs\n",
        "):\n",
        "    test_losses = []\n",
        "    train_losses = []\n",
        "    test_accuracies = []\n",
        "    train_accuracies = []\n",
        "    for epoch in range(num_epochs):\n",
        "        train_epoch(train_loader, model, loss_fn, optimizer, device)\n",
        "        \n",
        "        train_loss, train_acc = evaluate(train_loader, model, loss_fn, device)\n",
        "        train_accuracies.append(train_acc)\n",
        "        train_losses.append(train_loss)\n",
        "        \n",
        "        test_loss, test_acc = evaluate(test_loader, model, loss_fn, device)\n",
        "        test_accuracies.append(test_acc)\n",
        "        test_losses.append(test_loss)\n",
        "        \n",
        "        print(\n",
        "            'Epoch: {0:d}/{1:d}. Loss (Train/Test): {2:.3f}/{3:.3f}. Accuracy (Train/Test): {4:.3f}/{5:.3f}'.format(\n",
        "                epoch + 1, num_epochs, train_losses[-1], test_losses[-1], train_accuracies[-1], test_accuracies[-1]\n",
        "            )\n",
        "        )\n",
        "    return train_losses, train_accuracies, test_losses, test_accuracies"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:05:13.969665Z",
          "start_time": "2021-04-02T00:05:13.875379Z"
        },
        "id": "POaWCqL4WdP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим модель:"
      ],
      "metadata": {
        "id": "AGRXIFbXWdQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNNClassifier(\n",
        "    embedding_dim=embedding_dim, hidden_dim=hidden_dim, output_size=10, vocab=vocab,\n",
        "    rec_layer=torch.nn.LSTM, dropout=None\n",
        ").to(device)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T21:39:36.315652Z",
          "start_time": "2021-04-01T21:39:33.667776Z"
        },
        "id": "qW3X_jSmWdQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим класс для подсчёта функции потерь и оптимизатор:"
      ],
      "metadata": {
        "id": "nN-7R8xkWdQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss(reduction='mean')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T21:39:38.737281Z",
          "start_time": "2021-04-01T21:39:38.711948Z"
        },
        "id": "a8SBRK0OWdQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попробуем обучить модель:"
      ],
      "metadata": {
        "id": "5fgT7fvcWdQF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Сохраните все метрики и время работы модели. Это потребуется в конце первой части для построения графиков обучения и сравнения времени работы для всех моделей в этой секции**"
      ],
      "metadata": {
        "id": "r7mOnS8VWdQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "train_losses_pure, train_accuracies_pure, test_losses_pure, test_accuracies_pure = train(\n",
        "    train_dataloader, test_dataloader, model, loss_fn, optimizer, device, num_epochs\n",
        ")\n",
        "\n",
        "training_time = time.time() - start"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T21:44:27.733745Z",
          "start_time": "2021-04-01T21:41:52.821042Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ik5FnjN3WdQG",
        "outputId": "693ea5bd-f15d-4ee8-e4a9-e677c9b43590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/15. Loss (Train/Test): 1.973/1.979. Accuracy (Train/Test): 0.252/0.253\n",
            "Epoch: 2/15. Loss (Train/Test): 1.962/1.976. Accuracy (Train/Test): 0.273/0.271\n",
            "Epoch: 3/15. Loss (Train/Test): 1.777/1.802. Accuracy (Train/Test): 0.341/0.339\n",
            "Epoch: 4/15. Loss (Train/Test): 1.628/1.682. Accuracy (Train/Test): 0.370/0.360\n",
            "Epoch: 5/15. Loss (Train/Test): 1.544/1.632. Accuracy (Train/Test): 0.395/0.368\n",
            "Epoch: 6/15. Loss (Train/Test): 1.467/1.583. Accuracy (Train/Test): 0.420/0.390\n",
            "Epoch: 7/15. Loss (Train/Test): 1.423/1.579. Accuracy (Train/Test): 0.443/0.390\n",
            "Epoch: 8/15. Loss (Train/Test): 1.372/1.569. Accuracy (Train/Test): 0.461/0.394\n",
            "Epoch: 9/15. Loss (Train/Test): 1.330/1.552. Accuracy (Train/Test): 0.478/0.399\n",
            "Epoch: 10/15. Loss (Train/Test): 1.286/1.579. Accuracy (Train/Test): 0.493/0.392\n",
            "Epoch: 11/15. Loss (Train/Test): 1.250/1.614. Accuracy (Train/Test): 0.511/0.378\n",
            "Epoch: 12/15. Loss (Train/Test): 1.189/1.646. Accuracy (Train/Test): 0.539/0.379\n",
            "Epoch: 13/15. Loss (Train/Test): 1.117/1.650. Accuracy (Train/Test): 0.568/0.387\n",
            "Epoch: 14/15. Loss (Train/Test): 1.049/1.711. Accuracy (Train/Test): 0.599/0.378\n",
            "Epoch: 15/15. Loss (Train/Test): 0.973/1.757. Accuracy (Train/Test): 0.637/0.374\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Нерегуляризованные LSTM часто быстро переобучаются (и мы это видим по точности на контроле). Чтобы с этим бороться, часто используют L2-регуляризацию и дропаут.\n",
        "Однако способов накладывать дропаут на рекуррентный слой достаточно много, и далеко не все хорошо работают. По [ссылке](https://medium.com/@bingobee01/a-review-of-dropout-as-applied-to-rnns-72e79ecd5b7b) доступен хороший обзор дропаутов для RNN.\n",
        "\n",
        "Мы реализуем два варианта DropOut для RNN (и третий дополнительно). Заодно увидим, что для реализации различных усовершенствований рекуррентной архитектуры приходится \"вскрывать\" слой до различной \"глубины\"."
      ],
      "metadata": {
        "id": "TwYuBtwWWdQH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Реализация дропаута по статье Гала и Гарамани. Variational Dropout. (1 балл)"
      ],
      "metadata": {
        "id": "bHODqTerWdQI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Начнем с дропаута, описанного в [статье Гала и Гарамани](https://arxiv.org/abs/1512.05287).\n",
        "Для этого нам потребуется перейти от использования слоя `torch.nn.LSTM`, полностью скрывающего от нас рекуррентную логику, к использованию слоя `torch.nn.LSTMCell`, обрабатывающего лишь один временной шаг нашей последовательности (а всю логику вокруг придется реализовать самостоятельно). \n",
        "\n",
        "Допишите класс `RNNLayer`. При `dropout=0` ваш класс должен работать как обычный слой LSTM, а при `dropout > 0` накладывать бинарную маску на входной и скрытый вектор на каждом временном шаге, причем эта маска должна быть одинаковой во все моменты времени.\n",
        "\n",
        "Дропаут Гала и Гарамани в виде формул (m обозначает маску дропаута):\n",
        "\n",
        "$$\n",
        "h_{t-1} = h_{t-1}*m_h, \\, x_t = x_t * m_x\n",
        "$$\n",
        "\n",
        "Далее обычный шаг рекуррентной архитектуры, например, LSTM:\n",
        "\n",
        "$$\n",
        "i = \\sigma(h_{t-1}W^i + x_t U^i+b_i) \\quad\n",
        "o = \\sigma(h_{t-1}W^o + x_t U^o+b_o) \n",
        "$$\n",
        "$$\n",
        "f = \\sigma(h_{t-1}W^f + x_t U^f+b_f) \\quad \n",
        "g = tanh(h_{t-1} W^g + x_t U^g+b_g) \n",
        "$$\n",
        "$$\n",
        "c_t = f \\odot c_{t-1} +  i \\odot  g \\quad\n",
        "h_t =  o \\odot tanh(c_t)\n",
        "$$"
      ],
      "metadata": {
        "id": "t-B6Yf35WdQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_h0_c0(num_objects, hidden_size, some_existing_tensor):\n",
        "    \"\"\"\n",
        "    return h0 and c0, use some_existing_tensor.new_zeros() to gen them\n",
        "    h0 shape: num_objects x hidden_size\n",
        "    c0 shape: num_objects x hidden_size\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "    h0 = some_existing_tensor.new_zeros((num_objects, hidden_size))\n",
        "    c0 = some_existing_tensor.new_zeros((num_objects, hidden_size))\n",
        "    return h0, c0\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:05:14.068954Z",
          "start_time": "2021-04-02T00:05:13.971286Z"
        },
        "id": "7QjLObpMWdQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_dropout_mask(input_size, hidden_size, is_training, p, some_existing_tensor):\n",
        "    \"\"\"\n",
        "    is_training: if True, gen masks from Bernoulli\n",
        "                 if False, gen masks consisting of (1-p)\n",
        "    \n",
        "    return dropout masks of size input_size, hidden_size if p is not None\n",
        "    return one masks if p is None\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "    if p is None:\n",
        "        m_h = some_existing_tensor.new_ones(hidden_size)\n",
        "        m_x = some_existing_tensor.new_ones(input_size)\n",
        "    else:\n",
        "        if is_training:\n",
        "            m_h = some_existing_tensor.new_empty(hidden_size).bernoulli_(1 - p)\n",
        "            m_x = some_existing_tensor.new_empty(input_size).bernoulli_(1 - p)\n",
        "        else:\n",
        "            m_h = some_existing_tensor.new_full((hidden_size,), 1 - p)\n",
        "            m_x = some_existing_tensor.new_full((input_size,), 1 - p)\n",
        "    return m_x, m_h"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:05:14.131347Z",
          "start_time": "2021-04-02T00:05:14.071577Z"
        },
        "id": "RmD4_2mVWdQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Допишите класс-обёртку над LSTMCell для реализации Variational Dropout. **Используйте только цикл по времени**"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T21:09:12.282613Z",
          "start_time": "2021-04-01T21:09:12.256019Z"
        },
        "id": "XpGpvfkWWdQL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Для каждого тензора в функции `forward` подпишите в комментарии его размеры**"
      ],
      "metadata": {
        "id": "h5ydvu4zWdQM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNLayer(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout=None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dropout = dropout\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        \n",
        "        self.rnn_cell = torch.nn.LSTMCell(self.input_size, self.hidden_size)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Initialize h_0, c_0\n",
        "        # YOUR CODE HERE\n",
        "        batch_size = x.size(1)\n",
        "        # Size: (x.size(1), self.hidden_size) for both\n",
        "        h, c = init_h0_c0(batch_size, self.hidden_size, x)\n",
        "        \n",
        "        # Gen masks for input and hidden state\n",
        "        # YOUR CODE HERE\n",
        "        if self.dropout is not None:\n",
        "            # Size: m_x: (self.input_size,), m_h: (self.hidden_size,)\n",
        "            # Т. к. наследуемся от torch.nn.Module\n",
        "            m_x, m_h = gen_dropout_mask(self.input_size, self.hidden_size, self.training, self.dropout, x)\n",
        "            # Size: (x.size(0), x.size(1), x.size(2)) \n",
        "            x = m_x * x\n",
        "\n",
        "        # Implement recurrent logic and return what nn.LSTM returns\n",
        "        # Do not forget to apply generated dropout masks!\n",
        "        # YOUR CODE HERE\n",
        "        res = []\n",
        "        # Size: x: (x.size(0), x.size(1), x.size(2)) = (num_batches, batch_size, input_size) (т. к. используем разбиение данных на батчи)\n",
        "        # Size: batch: (x.size(1), x.size(2))\n",
        "        for batch in x:\n",
        "            # Size: (x.size(1), self.hidden_size) for both\n",
        "            h, c = self.rnn_cell(batch, (h, c))\n",
        "            if self.dropout is not None:\n",
        "                # Size: (x.size(1), self.hidden_size)\n",
        "                h = h * m_h\n",
        "            res.append(h)\n",
        "        res = torch.stack(res)\n",
        "        return res, (h, c)        "
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:05:14.190066Z",
          "start_time": "2021-04-02T00:05:14.132804Z"
        },
        "id": "tUQZP2dIWdQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Протестируйте реализованную модель с выключенным дропаутом (слой `RNNLayer` надо передать в `RNNClassifier` в качестве `rec_layer`). Замерьте время обучения. Сильно ли оно увеличилось по сравнению с `torch.nn.LSTM` (LSTM \"из коробки\")?"
      ],
      "metadata": {
        "id": "0280jmLSWdQO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Сохраните все метрики и время работы модели. Это потребуется в конце первой части для построения графиков обучения и сравнения времени работы для всех моделей в этой секции**"
      ],
      "metadata": {
        "id": "jjrgQIXAWdQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "model = RNNClassifier(embedding_dim=embedding_dim, hidden_dim=hidden_dim, output_size=10, vocab=vocab, rec_layer=RNNLayer, dropout=None).to(device)\n",
        "loss_fn = torch.nn.CrossEntropyLoss(reduction='mean')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "start1 = time.time()\n",
        "\n",
        "train_losses_pure1, train_accuracies_pure1, test_losses_pure1, test_accuracies_pure1 = train(\n",
        "    train_dataloader, test_dataloader, model, loss_fn, optimizer, device, num_epochs\n",
        ")\n",
        "\n",
        "training_time1 = time.time() - start1"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T22:04:19.104557Z",
          "start_time": "2021-04-01T21:50:02.992858Z"
        },
        "id": "XwA7SkC8WdQP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ddf8107-1e6c-4318-b178-134e9ff65608"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/15. Loss (Train/Test): 1.999/2.003. Accuracy (Train/Test): 0.240/0.244\n",
            "Epoch: 2/15. Loss (Train/Test): 1.811/1.834. Accuracy (Train/Test): 0.324/0.323\n",
            "Epoch: 3/15. Loss (Train/Test): 1.643/1.693. Accuracy (Train/Test): 0.362/0.354\n",
            "Epoch: 4/15. Loss (Train/Test): 1.546/1.624. Accuracy (Train/Test): 0.392/0.373\n",
            "Epoch: 5/15. Loss (Train/Test): 1.478/1.580. Accuracy (Train/Test): 0.416/0.385\n",
            "Epoch: 6/15. Loss (Train/Test): 1.422/1.562. Accuracy (Train/Test): 0.438/0.396\n",
            "Epoch: 7/15. Loss (Train/Test): 1.377/1.566. Accuracy (Train/Test): 0.458/0.394\n",
            "Epoch: 8/15. Loss (Train/Test): 1.326/1.571. Accuracy (Train/Test): 0.480/0.393\n",
            "Epoch: 9/15. Loss (Train/Test): 1.266/1.596. Accuracy (Train/Test): 0.498/0.402\n",
            "Epoch: 10/15. Loss (Train/Test): 1.200/1.588. Accuracy (Train/Test): 0.533/0.399\n",
            "Epoch: 11/15. Loss (Train/Test): 1.140/1.649. Accuracy (Train/Test): 0.558/0.384\n",
            "Epoch: 12/15. Loss (Train/Test): 1.064/1.677. Accuracy (Train/Test): 0.598/0.380\n",
            "Epoch: 13/15. Loss (Train/Test): 0.986/1.752. Accuracy (Train/Test): 0.631/0.382\n",
            "Epoch: 14/15. Loss (Train/Test): 0.898/1.817. Accuracy (Train/Test): 0.672/0.376\n",
            "Epoch: 15/15. Loss (Train/Test): 0.821/1.855. Accuracy (Train/Test): 0.713/0.364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Протестируйте полученную модель с `dropout=0.25`, вновь замерив время обучения. Получилось ли побороть переобучение? Сильно ли дольше обучается данная модель по сравнению с предыдущей? (доп. время тратится на генерацию масок дропаута)."
      ],
      "metadata": {
        "id": "ebdNCJv3WdQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "model = RNNClassifier(embedding_dim=embedding_dim, hidden_dim=hidden_dim, output_size=10, vocab=vocab, rec_layer=RNNLayer, dropout=0.25).to(device)\n",
        "loss_fn = torch.nn.CrossEntropyLoss(reduction='mean')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "start2 = time.time()\n",
        "\n",
        "train_losses_pure2, train_accuracies_pure2, test_losses_pure2, test_accuracies_pure2 = train(\n",
        "    train_dataloader, test_dataloader, model, loss_fn, optimizer, device, num_epochs\n",
        ")\n",
        "\n",
        "training_time2 = time.time() - start2"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T22:18:28.301613Z",
          "start_time": "2021-04-01T22:04:19.10785Z"
        },
        "id": "W51VbHJAWdQQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94b2dbfe-9a15-4f7d-d3fc-e9af0e928164"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/15. Loss (Train/Test): 2.015/2.015. Accuracy (Train/Test): 0.229/0.231\n",
            "Epoch: 2/15. Loss (Train/Test): 1.815/1.830. Accuracy (Train/Test): 0.328/0.330\n",
            "Epoch: 3/15. Loss (Train/Test): 1.685/1.714. Accuracy (Train/Test): 0.354/0.354\n",
            "Epoch: 4/15. Loss (Train/Test): 1.612/1.651. Accuracy (Train/Test): 0.375/0.368\n",
            "Epoch: 5/15. Loss (Train/Test): 1.569/1.618. Accuracy (Train/Test): 0.391/0.376\n",
            "Epoch: 6/15. Loss (Train/Test): 1.527/1.592. Accuracy (Train/Test): 0.409/0.384\n",
            "Epoch: 7/15. Loss (Train/Test): 1.492/1.570. Accuracy (Train/Test): 0.418/0.391\n",
            "Epoch: 8/15. Loss (Train/Test): 1.472/1.564. Accuracy (Train/Test): 0.428/0.394\n",
            "Epoch: 9/15. Loss (Train/Test): 1.438/1.543. Accuracy (Train/Test): 0.437/0.399\n",
            "Epoch: 10/15. Loss (Train/Test): 1.410/1.527. Accuracy (Train/Test): 0.446/0.405\n",
            "Epoch: 11/15. Loss (Train/Test): 1.390/1.519. Accuracy (Train/Test): 0.448/0.409\n",
            "Epoch: 12/15. Loss (Train/Test): 1.372/1.517. Accuracy (Train/Test): 0.455/0.408\n",
            "Epoch: 13/15. Loss (Train/Test): 1.351/1.511. Accuracy (Train/Test): 0.462/0.410\n",
            "Epoch: 14/15. Loss (Train/Test): 1.343/1.510. Accuracy (Train/Test): 0.463/0.411\n",
            "Epoch: 15/15. Loss (Train/Test): 1.311/1.508. Accuracy (Train/Test): 0.479/0.412\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Применение dropout помогло отчасти побороть переобучение, точность на обучении уже не так сильно отличается от точности на тесте. Однако получаемое качество все равно низкое, хотя на тесте на финальных эпохах оно увеличилось."
      ],
      "metadata": {
        "id": "moTyV4b5quwK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сравним время обучения с использованием слоя torch.nn.LSTM без dropout, с использованием слоя torch.nn.LSTMCell без dropout, и с torch.nn.LSTMCell с dropout=0.25."
      ],
      "metadata": {
        "id": "dVcGD1uFrFiP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Training time, torch.nn.LSTM, no dropout: {training_time}')\n",
        "print(f'Training time, torch.nn.LSTMCell, no dropout: {training_time1}')\n",
        "print(f'Training time, torch.nn.LSTMCell, dropout=0.25: {training_time2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-LW30eyrj8F",
        "outputId": "869e1b53-0a74-415c-f523-bb70975d39a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time, torch.nn.LSTM, no dropout: 148.8371925354004\n",
            "Training time, torch.nn.LSTMCell, no dropout: 456.829523563385\n",
            "Training time, torch.nn.LSTMCell, dropout=0.25: 540.3134038448334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Таким образом, применение torch.nn.LSTMCell вместо torch.nn.LSTM увеличивает время обучения. Дополнительное применение dropout также приводит к увеличению времени обучения."
      ],
      "metadata": {
        "id": "0db5IP_Qr5zw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Реализация дропаута по статье Гала и Гарамани. Дубль 2 (1 балл)"
      ],
      "metadata": {
        "id": "BQRFKDSFWdQR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<начало взлома pytorch>"
      ],
      "metadata": {
        "id": "htE5G2_dWdQR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "При разворачивании цикла по времени средствами python обучение рекуррентной нейросети сильно замедляется. Однако для реализации дропаута Гала и Гарамани необязательно явно задавать в коде домножение нейронов на маски. Можно схитрить и обойтись использованием слоя `torch.nn.LSTM`: перед вызовом `forward` слоя `torch.nn.LSTM` подменять его веса на веса, домноженные по строкам на маски. А обучаемые веса хранить отдельно. Именно так этот дропаут реализован в библиотеке `fastai`, код из которой использован в ячейке ниже.\n",
        "\n",
        "Такой слой реализуется в виде обертки над `torch.nn.LSTM`. Допишите класс:"
      ],
      "metadata": {
        "id": "dRyPeInYWdQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:05:14.286206Z",
          "start_time": "2021-04-02T00:05:14.19173Z"
        },
        "id": "qhxmLDEgWdQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FastRNNLayer(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout=0.0, layers_dropout=0.0, num_layers=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.dropout = dropout\n",
        "        self.layers_dropout = layers_dropout\n",
        "        self.module = torch.nn.LSTM(input_size, hidden_size, dropout=layers_dropout, num_layers=num_layers)\n",
        "\n",
        "        self.layer_names = []\n",
        "        for layer_n in range(self.num_layers):\n",
        "            self.layer_names += [f'weight_hh_l{layer_n}', f'weight_ih_l{layer_n}']\n",
        "\n",
        "        for layer in self.layer_names:\n",
        "            # Get torch.nn.Parameter with weights from torch.nn.LSTM instance\n",
        "            w = getattr(self.module, layer)\n",
        "\n",
        "            # Remove it from model\n",
        "            delattr(self.module, layer)\n",
        "\n",
        "            # And create new torch.nn.Parameter with the same data but different name\n",
        "            self.register_parameter(f'{layer}_raw', torch.nn.Parameter(w.data))\n",
        "\n",
        "            # Note. In torch.nn.LSTM.forward parameter with name `layer` will be used\n",
        "            #     so we must initialize it using `layer_raw` before forward pass\n",
        "\n",
        "    def _setweights(self, x):\n",
        "        \"\"\"\n",
        "            Apply dropout to the raw weights.\n",
        "        \"\"\"\n",
        "        for layer in self.layer_names:\n",
        "            # Get torch.nn.Parameter with weights\n",
        "            raw_w = getattr(self, f'{layer}_raw')\n",
        "\n",
        "            # Generate mask (use function gen_dropout_mask)\n",
        "            # YOUR CODE HERE\n",
        "            if self.dropout > 0:\n",
        "                m_x, m_h = gen_dropout_mask(raw_w.size(1), self.hidden_size, self.training, self.dropout, raw_w)\n",
        "\n",
        "            # Apply dropout mask\n",
        "            # YOUR CODE HERE\n",
        "                masked_raw_w = raw_w * m_x\n",
        "            else:\n",
        "                masked_raw_w = raw_w\n",
        "            # Set modified weights in its place\n",
        "            setattr(self.module, layer, masked_raw_w)\n",
        "\n",
        "    def forward(self, x, h_c=None):\n",
        "        \"\"\"\n",
        "        :param x: tensor containing the features of the input sequence.\n",
        "        :param Optional[Tuple[torch.tensor, torch.tensor]] h_c: initial hidden state and initial cell state\n",
        "        \"\"\"\n",
        "        with warnings.catch_warnings():\n",
        "            # To avoid the warning that comes because the weights aren't flattened.\n",
        "            warnings.simplefilter(\"ignore\")\n",
        "\n",
        "            # Set new weights of self.module and call its forward\n",
        "            # Pass h_c with x if it is not None. Otherwise pass only x\n",
        "            # YOUR CODE HERE\n",
        "            self._setweights(x)\n",
        "            if h_c is not None:\n",
        "                res = self.module(x, h_c)\n",
        "            else:\n",
        "                res = self.module(x)\n",
        "        return res\n",
        "\n",
        "    def reset(self):\n",
        "        if hasattr(self.module, 'reset'):\n",
        "            self.module.reset()"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T02:06:54.953123Z",
          "start_time": "2021-04-02T02:06:54.917017Z"
        },
        "id": "E5TJKfULWdQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Протестируйте реализованную модель с выключенным дропаутом (слой `FastRNNLayer` надо передать в `RNNClassifier` в качестве `rec_layer`). Замерьте время обучения. Убедитесь, что модель выдаёт такое же качество, как и оригинальная реализация LSTM."
      ],
      "metadata": {
        "id": "P9XtejMYWdQW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Сохраните все метрики и время работы модели. Это потребуется в конце первой части для построения графиков обучения и сравнения времени работы для всех моделей в этой секции**"
      ],
      "metadata": {
        "id": "cD4DNspuWdQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "model = RNNClassifier(embedding_dim=embedding_dim, hidden_dim=hidden_dim, output_size=10, vocab=vocab, rec_layer=FastRNNLayer, dropout=0).to(device)\n",
        "loss_fn = torch.nn.CrossEntropyLoss(reduction='mean')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "start3 = time.time()\n",
        "\n",
        "train_losses_pure3, train_accuracies_pure3, test_losses_pure3, test_accuracies_pure3 = train(\n",
        "    train_dataloader, test_dataloader, model, loss_fn, optimizer, device, num_epochs\n",
        ")\n",
        "\n",
        "training_time3 = time.time() - start3"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T22:25:23.843846Z",
          "start_time": "2021-04-01T22:22:43.059254Z"
        },
        "id": "Z8l5ux8-WdQY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9100c6ec-9b92-48ce-cad2-b68892098459"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/15. Loss (Train/Test): 1.930/1.936. Accuracy (Train/Test): 0.281/0.283\n",
            "Epoch: 2/15. Loss (Train/Test): 1.654/1.700. Accuracy (Train/Test): 0.362/0.345\n",
            "Epoch: 3/15. Loss (Train/Test): 1.556/1.631. Accuracy (Train/Test): 0.391/0.366\n",
            "Epoch: 4/15. Loss (Train/Test): 1.473/1.584. Accuracy (Train/Test): 0.423/0.385\n",
            "Epoch: 5/15. Loss (Train/Test): 1.419/1.560. Accuracy (Train/Test): 0.438/0.394\n",
            "Epoch: 6/15. Loss (Train/Test): 1.376/1.566. Accuracy (Train/Test): 0.460/0.389\n",
            "Epoch: 7/15. Loss (Train/Test): 1.318/1.590. Accuracy (Train/Test): 0.480/0.388\n",
            "Epoch: 8/15. Loss (Train/Test): 1.282/1.605. Accuracy (Train/Test): 0.486/0.395\n",
            "Epoch: 9/15. Loss (Train/Test): 1.204/1.618. Accuracy (Train/Test): 0.521/0.394\n",
            "Epoch: 10/15. Loss (Train/Test): 1.151/1.647. Accuracy (Train/Test): 0.543/0.396\n",
            "Epoch: 11/15. Loss (Train/Test): 1.076/1.683. Accuracy (Train/Test): 0.585/0.378\n",
            "Epoch: 12/15. Loss (Train/Test): 1.045/1.797. Accuracy (Train/Test): 0.592/0.361\n",
            "Epoch: 13/15. Loss (Train/Test): 0.940/1.821. Accuracy (Train/Test): 0.640/0.381\n",
            "Epoch: 14/15. Loss (Train/Test): 0.852/1.925. Accuracy (Train/Test): 0.689/0.366\n",
            "Epoch: 15/15. Loss (Train/Test): 0.785/2.021. Accuracy (Train/Test): 0.718/0.359\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Протестируйте полученный слой (вновь подставив его в `RNNClassifier` в качестве `rec_layer`) с `dropout=0.25`. Сравните время обучения с предыдущими моделями. Проследите, чтобы качество получилось такое же, как при первой реализации этого дропаута."
      ],
      "metadata": {
        "id": "3CbT4BUtWdQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "model = RNNClassifier(embedding_dim=embedding_dim, hidden_dim=hidden_dim, output_size=10, vocab=vocab, rec_layer=FastRNNLayer, dropout=0.25).to(device)\n",
        "loss_fn = torch.nn.CrossEntropyLoss(reduction='mean')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "start4 = time.time()\n",
        "\n",
        "train_losses_pure4, train_accuracies_pure4, test_losses_pure4, test_accuracies_pure4 = train(\n",
        "    train_dataloader, test_dataloader, model, loss_fn, optimizer, device, num_epochs\n",
        ")\n",
        "\n",
        "training_time4 = time.time() - start4"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T22:28:38.168777Z",
          "start_time": "2021-04-01T22:25:56.717326Z"
        },
        "id": "N6jO5vVvWdQa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b789662c-7832-4c85-ce08-08640e81d791"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/15. Loss (Train/Test): 2.015/2.016. Accuracy (Train/Test): 0.231/0.230\n",
            "Epoch: 2/15. Loss (Train/Test): 1.865/1.875. Accuracy (Train/Test): 0.309/0.315\n",
            "Epoch: 3/15. Loss (Train/Test): 1.701/1.726. Accuracy (Train/Test): 0.360/0.354\n",
            "Epoch: 4/15. Loss (Train/Test): 1.618/1.653. Accuracy (Train/Test): 0.383/0.372\n",
            "Epoch: 5/15. Loss (Train/Test): 1.532/1.583. Accuracy (Train/Test): 0.411/0.392\n",
            "Epoch: 6/15. Loss (Train/Test): 1.495/1.563. Accuracy (Train/Test): 0.420/0.392\n",
            "Epoch: 7/15. Loss (Train/Test): 1.462/1.550. Accuracy (Train/Test): 0.434/0.399\n",
            "Epoch: 8/15. Loss (Train/Test): 1.427/1.530. Accuracy (Train/Test): 0.445/0.406\n",
            "Epoch: 9/15. Loss (Train/Test): 1.394/1.514. Accuracy (Train/Test): 0.456/0.407\n",
            "Epoch: 10/15. Loss (Train/Test): 1.381/1.513. Accuracy (Train/Test): 0.459/0.410\n",
            "Epoch: 11/15. Loss (Train/Test): 1.351/1.504. Accuracy (Train/Test): 0.469/0.413\n",
            "Epoch: 12/15. Loss (Train/Test): 1.334/1.502. Accuracy (Train/Test): 0.482/0.410\n",
            "Epoch: 13/15. Loss (Train/Test): 1.308/1.504. Accuracy (Train/Test): 0.489/0.411\n",
            "Epoch: 14/15. Loss (Train/Test): 1.290/1.509. Accuracy (Train/Test): 0.494/0.410\n",
            "Epoch: 15/15. Loss (Train/Test): 1.293/1.534. Accuracy (Train/Test): 0.492/0.417\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Training time, FastRNN, no dropout: {training_time3}')\n",
        "print(f'Training time, FastRNN, dropout=0.25: {training_time4}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOZVydstuzN3",
        "outputId": "49ba79e6-f5ae-42b7-f546-aabd95d97bfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time, FastRNN, no dropout: 144.6406433582306\n",
            "Training time, FastRNN, dropout=0.25: 145.16568040847778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Полученное качество почти не отличается от предыдущих версий. Время работы меньше, чем у предыдущей версии."
      ],
      "metadata": {
        "id": "1lrsI0kfvCzH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "</конец взлома pytorch>"
      ],
      "metadata": {
        "id": "5-SQEunsWdQb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Реализация дропаута по статье Семениуты и др. (1 балл)"
      ],
      "metadata": {
        "id": "3PtnlV_sWdQc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Перейдем к реализации дропаута для LSTM по статье [Semeniuta et al](http://www.aclweb.org/anthology/C16-1165). \n",
        "\n",
        "Этот метод применения дропаута не менее популярен, чем предыдущий. Его особенность состоит в том, что он придуман специально для гейтовых архитектур. В контексте LSTM этот дропаут накладывается только на информационный поток (m_h - маска дропаута):\n",
        "$$\n",
        "i = \\sigma(h_{t-1}W^i + x_t U^i+b_i) \\quad\n",
        "o = \\sigma(h_{t-1}W^o + x_t U^o+b_o) \n",
        "$$\n",
        "$$\n",
        "f = \\sigma(h_{t-1}W^f + x_t U^f+b_f) \\quad \n",
        "g = tanh(h_{t-1} W^g + x_t U^g+b_g) \n",
        "$$\n",
        "$$\n",
        "c_t = f \\odot c_{t-1} +  i \\odot g \\odot {\\bf m_h} \\quad\n",
        "h_t =  o \\odot tanh(c_t)\n",
        "$$\n",
        "На входы $x_t$ маска накладывается как в предыдущем дропауте. Впрочем, на входы маску можно наложить вообще до вызова рекуррентного слоя.\n",
        "\n",
        "Согласно статье, маска дропаута может быть как одинаковая, так и разная для всех моментов времени. Мы сделаем одинаковую для всех моментов времени.\n",
        "\n",
        "Для реализации этого дропаута можно: \n",
        "1. самостоятельно реализовать LSTM (интерфейса LSTMCell не хватит) \n",
        "2. снова воспользоваться трюком с установкой весов (но тут мы опираемся на свойство $tanh(0)=0$, к тому же, трюк в данном случае выглядит менее тривиально, чем с дропаутом Гала). \n",
        "\n",
        "Предлагается реализовать дропаут по сценарию 1. Допишите класс:"
      ],
      "metadata": {
        "id": "WsKeFkGXWdQd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Для каждого тензора в функции `forward` подпишите в комментарии его размеры**"
      ],
      "metadata": {
        "id": "XWEELS9LWdQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HandmadeLSTM(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout=0.0):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.dropout = dropout\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        \n",
        "        self.input_weights = torch.nn.Linear(input_size, 4 * hidden_size)\n",
        "        self.hidden_weights = torch.nn.Linear(hidden_size, 4 * hidden_size)\n",
        "        \n",
        "        self.reset_params()\n",
        "\n",
        "    def reset_params(self):\n",
        "        \"\"\"\n",
        "        Initialization as in Pytorch. \n",
        "        Do not forget to call this method!\n",
        "        https://pytorch.org/docs/stable/_modules/torch/nn/modules/rnn.html#LSTM\n",
        "        \"\"\"\n",
        "        stdv = 1.0 / np.sqrt(self.hidden_size)\n",
        "        for weight in self.parameters():\n",
        "            torch.nn.init.uniform_(weight, -stdv, stdv)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Use functions init_h0_c0 and gen_dropout_masks defined above\n",
        "        # YOUR CODE HERE\n",
        "        batch_size = x.size(1)\n",
        "        # Size: (x.size(1), self.hidden_size) for both\n",
        "        h, c = init_h0_c0(batch_size, self.hidden_size, x)\n",
        "\n",
        "        if self.dropout > 0:\n",
        "            # Т. к. наследуемся от torch.nn.Module\n",
        "            # Size: m_x: (self.input_size,), m_h: (self.hidden_size,)\n",
        "            m_x, m_h = gen_dropout_mask(self.input_size, self.hidden_size, self.training, self.dropout, x)\n",
        "            # Size: (x.size(0), x.size(1), x.size(2))\n",
        "            x = x * m_x\n",
        "        # Implement recurrent logic to mimic torch.nn.LSTM\n",
        "        # Do not forget to apply dropout mask\n",
        "        # YOUR CODE HERE\n",
        "        res = []\n",
        "        # Size: x: (x.size(0), x.size(1), x.size(2)) = (num_batches, batch_size, input_size) (т. к. используем разбиение данных на батчи)\n",
        "        # Size: batch: (x.size(1), x.size(2))\n",
        "        for batch in x:\n",
        "            # Size: (x.size(1), 4 * self.hidden_size) for U and W\n",
        "            U = self.input_weights(batch)\n",
        "            W = self.hidden_weights(h)\n",
        "            # Size: (x.size(1), self.hidden_size) for all\n",
        "            U_i, U_o, U_f, U_g = U.split(self.hidden_size, dim=1)\n",
        "            # Size: (x.size(1), self.hidden_size) for all\n",
        "            W_i, W_o, W_f, W_g = W.split(self.hidden_size, dim=1)\n",
        "            # Size: (x.size(1), self.hidden_size) for i, o, f, g\n",
        "            i = torch.sigmoid(W_i + U_i)\n",
        "            o = torch.sigmoid(W_o + U_o)\n",
        "            f = torch.sigmoid(W_f + U_f)\n",
        "            g = torch.tanh(W_g + U_g)\n",
        "\n",
        "            if self.dropout > 0:\n",
        "                # Size: (x.size(1), self.hidden_size)\n",
        "                g = g * m_h\n",
        "            \n",
        "            # Size: (x.size(1), self.hidden_size) for c and h\n",
        "            c = f * c + i * g\n",
        "            h = o * torch.tanh(c)\n",
        "            res.append(h)\n",
        "        res = torch.stack(res)\n",
        "        return res, (h, c)        "
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:05:14.447201Z",
          "start_time": "2021-04-02T00:05:14.350457Z"
        },
        "id": "26rPQVOCWdQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Протестируйте вашу реализацию без дропаута (проконтролируйте качество и сравните время обучения с временем обучения `torch.nn.LSTM` и `RNNLayer`), а также с `dropout=0.25`. Сравните качество модели с таким дропаутом с качеством модели с дропаутом Гала и Гарамани."
      ],
      "metadata": {
        "id": "deCh9HlhWdQf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Сохраните все метрики и время работы модели. Это потребуется в конце первой части для построения графиков обучения и сравнения времени работы для всех моделей в этой секции**"
      ],
      "metadata": {
        "id": "AHmanJT_WdQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "model = RNNClassifier(embedding_dim=embedding_dim, hidden_dim=hidden_dim, output_size=10, vocab=vocab, rec_layer=HandmadeLSTM, dropout=0).to(device)\n",
        "loss_fn = torch.nn.CrossEntropyLoss(reduction='mean')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "start5 = time.time()\n",
        "\n",
        "train_losses_pure5, train_accuracies_pure5, test_losses_pure5, test_accuracies_pure5 = train(\n",
        "    train_dataloader, test_dataloader, model, loss_fn, optimizer, device, num_epochs\n",
        ")\n",
        "\n",
        "training_time5 = time.time() - start5"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T23:01:53.046622Z",
          "start_time": "2021-04-01T22:30:08.733475Z"
        },
        "id": "R217MOZUWdQg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad4a3aa3-c526-49e1-8b96-0edd9d0d1a6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/15. Loss (Train/Test): 2.025/2.030. Accuracy (Train/Test): 0.237/0.236\n",
            "Epoch: 2/15. Loss (Train/Test): 1.737/1.759. Accuracy (Train/Test): 0.343/0.342\n",
            "Epoch: 3/15. Loss (Train/Test): 1.583/1.640. Accuracy (Train/Test): 0.387/0.360\n",
            "Epoch: 4/15. Loss (Train/Test): 1.482/1.576. Accuracy (Train/Test): 0.422/0.393\n",
            "Epoch: 5/15. Loss (Train/Test): 1.425/1.551. Accuracy (Train/Test): 0.442/0.398\n",
            "Epoch: 6/15. Loss (Train/Test): 1.380/1.539. Accuracy (Train/Test): 0.467/0.398\n",
            "Epoch: 7/15. Loss (Train/Test): 1.323/1.557. Accuracy (Train/Test): 0.478/0.401\n",
            "Epoch: 8/15. Loss (Train/Test): 1.268/1.539. Accuracy (Train/Test): 0.507/0.402\n",
            "Epoch: 9/15. Loss (Train/Test): 1.242/1.599. Accuracy (Train/Test): 0.515/0.394\n",
            "Epoch: 10/15. Loss (Train/Test): 1.154/1.608. Accuracy (Train/Test): 0.545/0.402\n",
            "Epoch: 11/15. Loss (Train/Test): 1.083/1.643. Accuracy (Train/Test): 0.584/0.385\n",
            "Epoch: 12/15. Loss (Train/Test): 1.024/1.692. Accuracy (Train/Test): 0.605/0.391\n",
            "Epoch: 13/15. Loss (Train/Test): 0.949/1.784. Accuracy (Train/Test): 0.640/0.384\n",
            "Epoch: 14/15. Loss (Train/Test): 0.861/1.824. Accuracy (Train/Test): 0.692/0.365\n",
            "Epoch: 15/15. Loss (Train/Test): 0.770/1.950. Accuracy (Train/Test): 0.727/0.363\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "model = RNNClassifier(embedding_dim=embedding_dim, hidden_dim=hidden_dim, output_size=10, vocab=vocab, rec_layer=HandmadeLSTM, dropout=0.25).to(device)\n",
        "loss_fn = torch.nn.CrossEntropyLoss(reduction='mean')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "start6 = time.time()\n",
        "\n",
        "train_losses_pure6, train_accuracies_pure6, test_losses_pure6, test_accuracies_pure6 = train(\n",
        "    train_dataloader, test_dataloader, model, loss_fn, optimizer, device, num_epochs\n",
        ")\n",
        "\n",
        "training_time6 = time.time() - start6"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T23:33:28.808063Z",
          "start_time": "2021-04-01T23:01:53.049547Z"
        },
        "id": "kVlYvik3WdQi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7511cf2-9945-4cba-a045-2257cc678e42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/15. Loss (Train/Test): 2.084/2.084. Accuracy (Train/Test): 0.210/0.207\n",
            "Epoch: 2/15. Loss (Train/Test): 1.838/1.845. Accuracy (Train/Test): 0.315/0.321\n",
            "Epoch: 3/15. Loss (Train/Test): 1.716/1.732. Accuracy (Train/Test): 0.344/0.349\n",
            "Epoch: 4/15. Loss (Train/Test): 1.650/1.679. Accuracy (Train/Test): 0.356/0.359\n",
            "Epoch: 5/15. Loss (Train/Test): 1.586/1.631. Accuracy (Train/Test): 0.381/0.374\n",
            "Epoch: 6/15. Loss (Train/Test): 1.535/1.593. Accuracy (Train/Test): 0.398/0.383\n",
            "Epoch: 7/15. Loss (Train/Test): 1.493/1.566. Accuracy (Train/Test): 0.411/0.390\n",
            "Epoch: 8/15. Loss (Train/Test): 1.484/1.567. Accuracy (Train/Test): 0.417/0.396\n",
            "Epoch: 9/15. Loss (Train/Test): 1.477/1.581. Accuracy (Train/Test): 0.419/0.398\n",
            "Epoch: 10/15. Loss (Train/Test): 1.418/1.539. Accuracy (Train/Test): 0.440/0.403\n",
            "Epoch: 11/15. Loss (Train/Test): 1.402/1.536. Accuracy (Train/Test): 0.446/0.405\n",
            "Epoch: 12/15. Loss (Train/Test): 1.375/1.520. Accuracy (Train/Test): 0.451/0.408\n",
            "Epoch: 13/15. Loss (Train/Test): 1.367/1.528. Accuracy (Train/Test): 0.459/0.413\n",
            "Epoch: 14/15. Loss (Train/Test): 1.348/1.529. Accuracy (Train/Test): 0.463/0.415\n",
            "Epoch: 15/15. Loss (Train/Test): 1.351/1.551. Accuracy (Train/Test): 0.461/0.414\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Training time, HandmadeLSTM, no dropout: {training_time5}')\n",
        "print(f'Training time, HandmadeLSTM, dropout=0.25: {training_time6}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCs_FTYfyiZR",
        "outputId": "a7b0a737-73a9-49e8-bfcd-e277a957a0de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time, HandmadeLSTM, no dropout: 1252.3796310424805\n",
            "Training time, HandmadeLSTM, dropout=0.25: 1317.5278656482697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Качество на обучении и тесте почти такое же, как и в предыдущих реализациях, однако время обучения значительно возросло."
      ],
      "metadata": {
        "id": "nsXHNOnqD9dQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Сравнение всех предложенных моделей. (1 балл)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T23:33:28.831346Z",
          "start_time": "2021-04-01T23:33:28.810453Z"
        },
        "id": "tjYv6yUAWdQj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Используя замеры времени заполните табличку с временем работы четырёх реализованных моделей в следующей ячейке:"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T23:48:05.361634Z",
          "start_time": "2021-04-01T23:48:05.333901Z"
        },
        "id": "FCw74oXLWdQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = training_time // 60\n",
        "s = training_time % 60\n",
        "LSTM = f'{int(m)}m {round(s)}s'\n",
        "print('torch.nn.LSTM, no dropout: ' + LSTM)\n",
        "\n",
        "m1 = training_time1 // 60\n",
        "s1 = training_time1 % 60\n",
        "RNN = f'{int(m1)}m {round(s1)}s'\n",
        "print('RNNLayer, no dropout: ' + RNN)\n",
        "\n",
        "m3 = training_time3 // 60\n",
        "s3 = training_time3 % 60\n",
        "FRNN = f'{int(m3)}m {round(s3)}s'\n",
        "print('FastRNNLayer, no dropout: ' + FRNN)\n",
        "\n",
        "m5 = training_time5 // 60\n",
        "s5 = training_time5 % 60\n",
        "HLSTM = f'{int(m5)}m {round(s5)}s'\n",
        "print('HandmadeLSTM, no dropout: ' + HLSTM)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0KtiiWB6eMx",
        "outputId": "90548332-919c-4d4e-f121-ebe6df3e0d26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.nn.LSTM, no dropout: 2m 29s\n",
            "RNNLayer, no dropout: 7m 37s\n",
            "FastRNNLayer, no dropout: 2m 25s\n",
            "HandmadeLSTM, no dropout: 20m 52s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m2 = training_time2 // 60\n",
        "s2 = training_time2 % 60\n",
        "RNN = f'{int(m2)}m {round(s2)}s'\n",
        "print('RNNLayer, dropout=0.25: ' + RNN)\n",
        "\n",
        "m4 = training_time4 // 60\n",
        "s4 = training_time4 % 60\n",
        "FRNN = f'{int(m4)}m {round(s4)}s'\n",
        "print('FastRNNLayer, dropout=0.25: ' + FRNN)\n",
        "\n",
        "m6 = training_time6 // 60\n",
        "s6 = training_time6 % 60\n",
        "HLSTM = f'{int(m6)}m {round(s6)}s'\n",
        "print('HandmadeLSTM, dropout=0.25: ' + HLSTM)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcbYiXz5-eal",
        "outputId": "ba17d1ff-839f-4071-b7e8-adecdb8b3a9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNNLayer, dropout=0.25: 9m 0s\n",
            "FastRNNLayer, dropout=0.25: 2m 25s\n",
            "HandmadeLSTM, dropout=0.25: 21m 58s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Заполним таблицу:"
      ],
      "metadata": {
        "id": "PlB-uqovFb8r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "|            | torch.nn.LSTM | RNNLayer | FastRNNLayer | HandmadeLSTM |\n",
        "|------------|---------------|----------|--------------|--------------|\n",
        "|no dropout  | 2m 29s        | 7m 37s \t| 2m 25s       | 20m 52s      |\n",
        "|dropout=0.25|    -          | 9m 0s    | 2m 25s       | 21m 58s      |"
      ],
      "metadata": {
        "id": "V2_fZ-tpWdQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:05:14.722913Z",
          "start_time": "2021-04-02T00:05:14.448857Z"
        },
        "id": "J2lX3TeFWdQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Крайне желательно рисовать графики в векторном формате. \n",
        "\n",
        "Если по каким-то причинам, отрисовка не будет работать, закомментируйте следующую ячейку."
      ],
      "metadata": {
        "id": "_0hHJeeKWdQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "from IPython.display import set_matplotlib_formats\n",
        "\n",
        "set_matplotlib_formats('pdf', 'svg')"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:05:14.745238Z",
          "start_time": "2021-04-02T00:05:14.724188Z"
        },
        "id": "Yz3Y2UxdWdQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Нарисуйте два графика -- функция потерь и качество на обучающей и тестовой выборке для всех 7 моделей обученных выше."
      ],
      "metadata": {
        "id": "3zyjCUoTWdQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(2, 1, figsize=(15, 15))\n",
        "\n",
        "# YOUR CODE HERE\n",
        "epoch_nums = np.arange(num_epochs) + 1\n",
        "\n",
        "axes[0].plot(epoch_nums, train_losses_pure, label='torch.nn.LSTM, no dropout, train')\n",
        "axes[0].plot(epoch_nums, train_losses_pure1, label='RNNLayer, no dropout, train')\n",
        "axes[0].plot(epoch_nums, train_losses_pure2, label='RNNLayer, dropout=0.25, train')\n",
        "axes[0].plot(epoch_nums, train_losses_pure3, label='FastRNNLayer, no dropout, train')\n",
        "axes[0].plot(epoch_nums, train_losses_pure4, label='FastRNNLayer, dropout=0.25, train')\n",
        "axes[0].plot(epoch_nums, train_losses_pure5, label='HandmadeLSTM, no dropout, train')\n",
        "axes[0].plot(epoch_nums, train_losses_pure6, label='HandmadeLSTM, dropout=0.25, train')\n",
        "\n",
        "axes[0].plot(epoch_nums, test_losses_pure, label='torch.nn.LSTM, no dropout, test', linestyle='dashed')\n",
        "axes[0].plot(epoch_nums, test_losses_pure1, label='RNNLayer, no dropout, test', linestyle='dashed')\n",
        "axes[0].plot(epoch_nums, test_losses_pure2, label='RNNLayer, dropout=0.25, test', linestyle='dashed')\n",
        "axes[0].plot(epoch_nums, test_losses_pure3, label='FastRNNLayer, no dropout, test', linestyle='dashed')\n",
        "axes[0].plot(epoch_nums, test_losses_pure4, label='FastRNNLayer, dropout=0.25, test', linestyle='dashed')\n",
        "axes[0].plot(epoch_nums, test_losses_pure5, label='HandmadeLSTM, no dropout, test', linestyle='dashed')\n",
        "axes[0].plot(epoch_nums, test_losses_pure6, label='HandmadeLSTM, dropout=0.25, test', linestyle='dashed')\n",
        "\n",
        "\n",
        "axes[0].legend()\n",
        "axes[0].grid(True)\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_title('CrossEntropy Loss')\n",
        "\n",
        "axes[1].plot(epoch_nums, train_accuracies_pure, label='torch.nn.LSTM, no dropout, train')\n",
        "axes[1].plot(epoch_nums, train_accuracies_pure1, label='RNNLayer, no dropout, train')\n",
        "axes[1].plot(epoch_nums, train_accuracies_pure2, label='RNNLayer, dropout=0.25, train')\n",
        "axes[1].plot(epoch_nums, train_accuracies_pure3, label='FastRNNLayer, no dropout, train')\n",
        "axes[1].plot(epoch_nums, train_accuracies_pure4, label='FastRNNLayer, dropout=0.25, train')\n",
        "axes[1].plot(epoch_nums, train_accuracies_pure5, label='HandmadeLSTM, no dropout, train')\n",
        "axes[1].plot(epoch_nums, train_accuracies_pure6, label='HandmadeLSTM, dropout=0.25, train')\n",
        "\n",
        "axes[1].plot(epoch_nums, test_accuracies_pure, label='torch.nn.LSTM, no dropout, test', linestyle='dashed')\n",
        "axes[1].plot(epoch_nums, test_accuracies_pure1, label='RNNLayer, no dropout, test', linestyle='dashed')\n",
        "axes[1].plot(epoch_nums, test_accuracies_pure2, label='RNNLayer, dropout=0.25, test',linestyle='dashed')\n",
        "axes[1].plot(epoch_nums, test_accuracies_pure3, label='FastRNNLayer, no dropout, test', linestyle='dashed')\n",
        "axes[1].plot(epoch_nums, test_accuracies_pure4, label='FastRNNLayer, dropout=0.25, test', linestyle='dashed')\n",
        "axes[1].plot(epoch_nums, test_accuracies_pure5, label='HandmadeLSTM, no dropout, test', linestyle='dashed')\n",
        "axes[1].plot(epoch_nums, test_accuracies_pure6, label='HandmadeLSTM, dropout=0.25, test', linestyle='dashed')\n",
        "\n",
        "\n",
        "\n",
        "axes[1].legend()\n",
        "axes[1].grid(True)\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_title('Accuracy')\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-01T23:40:37.809057Z",
          "start_time": "2021-04-01T23:40:36.694896Z"
        },
        "id": "hHXMZPkuWdQt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9d06463b-257c-49df-a5b3-785eaba6be63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x1080 with 2 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"1071.274375pt\" version=\"1.1\" viewBox=\"0 0 1072.703125 1071.274375\" width=\"1072.703125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 1071.274375 \nL 1072.703125 1071.274375 \nL 1072.703125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 499.118125 \nL 1065.503125 499.118125 \nL 1065.503125 22.318125 \nL 30.103125 22.318125 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path clip-path=\"url(#p689111ef42)\" d=\"M 144.400528 499.118125 \nL 144.400528 22.318125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m1e8bbe0085\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"144.400528\" xlink:href=\"#m1e8bbe0085\" y=\"499.118125\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 2 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(141.219278 513.716563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path clip-path=\"url(#p689111ef42)\" d=\"M 278.86806 499.118125 \nL 278.86806 22.318125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"278.86806\" xlink:href=\"#m1e8bbe0085\" y=\"499.118125\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 4 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(275.68681 513.716563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path clip-path=\"url(#p689111ef42)\" d=\"M 413.335593 499.118125 \nL 413.335593 22.318125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"413.335593\" xlink:href=\"#m1e8bbe0085\" y=\"499.118125\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 6 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(410.154343 513.716563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path clip-path=\"url(#p689111ef42)\" d=\"M 547.803125 499.118125 \nL 547.803125 22.318125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"547.803125\" xlink:href=\"#m1e8bbe0085\" y=\"499.118125\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 8 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g transform=\"translate(544.621875 513.716563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path clip-path=\"url(#p689111ef42)\" d=\"M 682.270657 499.118125 \nL 682.270657 22.318125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"682.270657\" xlink:href=\"#m1e8bbe0085\" y=\"499.118125\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 10 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(675.908157 513.716563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_11\">\n      <path clip-path=\"url(#p689111ef42)\" d=\"M 816.73819 499.118125 \nL 816.73819 22.318125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"816.73819\" xlink:href=\"#m1e8bbe0085\" y=\"499.118125\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 12 -->\n      <g transform=\"translate(810.37569 513.716563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_13\">\n      <path clip-path=\"url(#p689111ef42)\" d=\"M 951.205722 499.118125 \nL 951.205722 22.318125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"951.205722\" xlink:href=\"#m1e8bbe0085\" y=\"499.118125\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 14 -->\n      <g transform=\"translate(944.843222 513.716563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_8\">\n     <!-- Epoch -->\n     <defs>\n      <path d=\"M 9.8125 72.90625 \nL 55.90625 72.90625 \nL 55.90625 64.59375 \nL 19.671875 64.59375 \nL 19.671875 43.015625 \nL 54.390625 43.015625 \nL 54.390625 34.71875 \nL 19.671875 34.71875 \nL 19.671875 8.296875 \nL 56.78125 8.296875 \nL 56.78125 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-69\"/>\n      <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n      <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n      <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 75.984375 \nL 18.109375 75.984375 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-104\"/>\n     </defs>\n     <g transform=\"translate(532.492187 527.394688)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"63.183594\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"126.660156\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"187.841797\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"242.822266\" xlink:href=\"#DejaVuSans-104\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_15\">\n      <path clip-path=\"url(#p689111ef42)\" d=\"M 30.103125 467.67557 \nL 1065.503125 467.67557 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_16\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"maf725b042b\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#maf725b042b\" y=\"467.67557\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.8 -->\n      <defs>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n      </defs>\n      <g transform=\"translate(7.2 471.474789)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_17\">\n      <path clip-path=\"url(#p689111ef42)\" d=\"M 30.103125 401.704421 \nL 1065.503125 401.704421 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_18\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#maf725b042b\" y=\"401.704421\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 1.0 -->\n      <g transform=\"translate(7.2 405.503639)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_19\">\n      <path clip-path=\"url(#p689111ef42)\" d=\"M 30.103125 335.733272 \nL 1065.503125 335.733272 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_20\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#maf725b042b\" y=\"335.733272\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 1.2 -->\n      <g transform=\"translate(7.2 339.53249)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_21\">\n      <path clip-path=\"url(#p689111ef42)\" d=\"M 30.103125 269.762122 \nL 1065.503125 269.762122 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_22\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#maf725b042b\" y=\"269.762122\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 1.4 -->\n      <g transform=\"translate(7.2 273.561341)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_23\">\n      <path clip-path=\"url(#p689111ef42)\" d=\"M 30.103125 203.790973 \nL 1065.503125 203.790973 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_24\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#maf725b042b\" y=\"203.790973\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 1.6 -->\n      <g transform=\"translate(7.2 207.590192)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_25\">\n      <path clip-path=\"url(#p689111ef42)\" d=\"M 30.103125 137.819824 \nL 1065.503125 137.819824 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_26\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#maf725b042b\" y=\"137.819824\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 1.8 -->\n      <g transform=\"translate(7.2 141.619043)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_27\">\n      <path clip-path=\"url(#p689111ef42)\" d=\"M 30.103125 71.848675 \nL 1065.503125 71.848675 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_28\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#maf725b042b\" y=\"71.848675\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 2.0 -->\n      <g transform=\"translate(7.2 75.647894)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_29\">\n    <path clip-path=\"url(#p689111ef42)\" d=\"M 77.166761 80.805829 \nL 144.400528 84.40297 \nL 211.634294 145.454271 \nL 278.86806 194.462143 \nL 346.101826 222.118907 \nL 413.335593 247.554476 \nL 480.569359 262.238548 \nL 547.803125 278.900607 \nL 615.036891 292.992801 \nL 682.270657 307.408567 \nL 749.504424 319.130783 \nL 816.73819 339.393088 \nL 883.971956 363.107318 \nL 951.205722 385.550394 \nL 1018.439489 410.678091 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_30\">\n    <path clip-path=\"url(#p689111ef42)\" d=\"M 77.166761 72.332598 \nL 144.400528 134.063483 \nL 211.634294 189.74848 \nL 278.86806 221.670696 \nL 346.101826 243.910502 \nL 413.335593 262.410199 \nL 480.569359 277.391393 \nL 547.803125 294.116516 \nL 615.036891 314.080186 \nL 682.270657 335.798594 \nL 749.504424 355.647019 \nL 816.73819 380.458501 \nL 883.971956 406.390402 \nL 951.205722 435.191947 \nL 1018.439489 460.623223 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_31\">\n    <path clip-path=\"url(#p689111ef42)\" d=\"M 77.166761 66.850365 \nL 144.400528 132.738281 \nL 211.634294 175.666559 \nL 278.86806 199.699595 \nL 346.101826 214.102123 \nL 413.335593 227.823834 \nL 480.569359 239.449018 \nL 547.803125 246.16087 \nL 615.036891 257.297375 \nL 682.270657 266.299826 \nL 749.504424 272.975106 \nL 816.73819 278.885481 \nL 883.971956 285.99262 \nL 951.205722 288.718225 \nL 1018.439489 299.253911 \n\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_32\">\n    <path clip-path=\"url(#p689111ef42)\" d=\"M 77.166761 94.924484 \nL 144.400528 186.036924 \nL 211.634294 218.285944 \nL 278.86806 245.53991 \nL 346.101826 263.622778 \nL 413.335593 277.656275 \nL 480.569359 296.738682 \nL 547.803125 308.66687 \nL 615.036891 334.547531 \nL 682.270657 352.026755 \nL 749.504424 376.733507 \nL 816.73819 386.722406 \nL 883.971956 421.467948 \nL 951.205722 450.59989 \nL 1018.439489 472.623958 \n\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_33\">\n    <path clip-path=\"url(#p689111ef42)\" d=\"M 77.166761 66.818503 \nL 144.400528 116.374727 \nL 211.634294 170.386598 \nL 278.86806 197.729079 \nL 346.101826 226.090442 \nL 413.335593 238.432948 \nL 480.569359 249.401583 \nL 547.803125 260.883419 \nL 615.036891 271.813405 \nL 682.270657 276.175695 \nL 749.504424 285.921692 \nL 816.73819 291.561595 \nL 883.971956 299.946378 \nL 951.205722 306.06247 \nL 1018.439489 305.013307 \n\" style=\"fill:none;stroke:#9467bd;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_34\">\n    <path clip-path=\"url(#p689111ef42)\" d=\"M 77.166761 63.455609 \nL 144.400528 158.74917 \nL 211.634294 209.498843 \nL 278.86806 242.801531 \nL 346.101826 261.360777 \nL 413.335593 276.510444 \nL 480.569359 295.226865 \nL 547.803125 313.362303 \nL 615.036891 321.953522 \nL 682.270657 350.839428 \nL 749.504424 374.262841 \nL 816.73819 393.625066 \nL 883.971956 418.446071 \nL 951.205722 447.521194 \nL 1018.439489 477.445398 \n\" style=\"fill:none;stroke:#8c564b;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_35\">\n    <path clip-path=\"url(#p689111ef42)\" d=\"M 77.166761 43.990852 \nL 144.400528 125.24719 \nL 211.634294 165.679928 \nL 278.86806 187.388082 \nL 346.101826 208.304521 \nL 413.335593 225.310595 \nL 480.569359 238.990861 \nL 547.803125 241.98973 \nL 615.036891 244.352987 \nL 682.270657 263.89732 \nL 749.504424 269.24703 \nL 816.73819 277.968751 \nL 883.971956 280.583082 \nL 951.205722 286.954851 \nL 1018.439489 285.903328 \n\" style=\"fill:none;stroke:#e377c2;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_36\">\n    <path clip-path=\"url(#p689111ef42)\" d=\"M 77.166761 78.726078 \nL 144.400528 79.895243 \nL 211.634294 137.073683 \nL 278.86806 176.676622 \nL 346.101826 193.311783 \nL 413.335593 209.510322 \nL 480.569359 210.701432 \nL 547.803125 213.990986 \nL 615.036891 219.689442 \nL 682.270657 210.747601 \nL 749.504424 199.11485 \nL 816.73819 188.663553 \nL 883.971956 187.458462 \nL 951.205722 167.028587 \nL 1018.439489 152.031892 \n\" style=\"fill:none;stroke:#7f7f7f;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_37\">\n    <path clip-path=\"url(#p689111ef42)\" d=\"M 77.166761 70.964354 \nL 144.400528 126.579978 \nL 211.634294 173.135981 \nL 278.86806 195.711795 \nL 346.101826 210.468393 \nL 413.335593 216.464306 \nL 480.569359 215.047131 \nL 547.803125 213.296705 \nL 615.036891 205.180025 \nL 682.270657 207.735504 \nL 749.504424 187.742903 \nL 816.73819 178.368243 \nL 883.971956 153.548081 \nL 951.205722 132.086346 \nL 1018.439489 119.571602 \n\" style=\"fill:none;stroke:#bcbd22;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_38\">\n    <path clip-path=\"url(#p689111ef42)\" d=\"M 77.166761 66.877006 \nL 144.400528 127.999624 \nL 211.634294 166.242301 \nL 278.86806 186.933972 \nL 346.101826 197.84202 \nL 413.335593 206.428665 \nL 480.569359 213.604858 \nL 547.803125 215.733355 \nL 615.036891 222.529931 \nL 682.270657 228.005929 \nL 749.504424 230.382944 \nL 816.73819 231.201124 \nL 883.971956 233.252639 \nL 951.205722 233.509335 \nL 1018.439489 234.174368 \n\" style=\"fill:none;stroke:#17becf;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_39\">\n    <path clip-path=\"url(#p689111ef42)\" d=\"M 77.166761 93.10601 \nL 144.400528 170.77104 \nL 211.634294 193.407582 \nL 278.86806 209.013066 \nL 346.101826 217.104627 \nL 413.335593 215.1617 \nL 480.569359 206.94941 \nL 547.803125 202.226302 \nL 615.036891 197.70512 \nL 682.270657 188.21055 \nL 749.504424 176.479421 \nL 816.73819 138.863285 \nL 883.971956 130.743563 \nL 951.205722 96.569519 \nL 1018.439489 64.827812 \n\" style=\"fill:none;stroke:#1f77b4;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_40\">\n    <path clip-path=\"url(#p689111ef42)\" d=\"M 77.166761 66.559886 \nL 144.400528 112.996207 \nL 211.634294 162.284997 \nL 278.86806 186.35953 \nL 346.101826 209.322625 \nL 413.335593 215.973786 \nL 480.569359 220.407946 \nL 547.803125 226.940363 \nL 615.036891 232.062742 \nL 682.270657 232.61615 \nL 749.504424 235.565156 \nL 816.73819 236.176225 \nL 883.971956 235.559246 \nL 951.205722 233.954502 \nL 1018.439489 225.434494 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_41\">\n    <path clip-path=\"url(#p689111ef42)\" d=\"M 77.166761 61.793902 \nL 144.400528 151.432051 \nL 211.634294 190.692643 \nL 278.86806 211.853123 \nL 346.101826 220.077659 \nL 413.335593 223.968822 \nL 480.569359 218.026957 \nL 547.803125 223.847137 \nL 615.036891 204.06816 \nL 682.270657 201.142765 \nL 749.504424 189.540704 \nL 816.73819 173.549021 \nL 883.971956 143.151858 \nL 951.205722 129.769345 \nL 1018.439489 88.313294 \n\" style=\"fill:none;stroke:#2ca02c;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_42\">\n    <path clip-path=\"url(#p689111ef42)\" d=\"M 77.166761 44.143701 \nL 144.400528 122.817476 \nL 211.634294 160.108845 \nL 278.86806 177.882183 \nL 346.101826 193.66553 \nL 413.335593 205.997422 \nL 480.569359 215.160173 \nL 547.803125 214.789116 \nL 615.036891 209.990822 \nL 682.270657 223.969012 \nL 749.504424 225.035667 \nL 816.73819 230.04586 \nL 883.971956 227.542244 \nL 951.205722 227.292286 \nL 1018.439489 219.857479 \n\" style=\"fill:none;stroke:#d62728;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 499.118125 \nL 30.103125 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 1065.503125 499.118125 \nL 1065.503125 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 499.118125 \nL 1065.503125 499.118125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 22.318125 \nL 1065.503125 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_16\">\n    <!-- CrossEntropy Loss -->\n    <defs>\n     <path d=\"M 64.40625 67.28125 \nL 64.40625 56.890625 \nQ 59.421875 61.53125 53.78125 63.8125 \nQ 48.140625 66.109375 41.796875 66.109375 \nQ 29.296875 66.109375 22.65625 58.46875 \nQ 16.015625 50.828125 16.015625 36.375 \nQ 16.015625 21.96875 22.65625 14.328125 \nQ 29.296875 6.6875 41.796875 6.6875 \nQ 48.140625 6.6875 53.78125 8.984375 \nQ 59.421875 11.28125 64.40625 15.921875 \nL 64.40625 5.609375 \nQ 59.234375 2.09375 53.4375 0.328125 \nQ 47.65625 -1.421875 41.21875 -1.421875 \nQ 24.65625 -1.421875 15.125 8.703125 \nQ 5.609375 18.84375 5.609375 36.375 \nQ 5.609375 53.953125 15.125 64.078125 \nQ 24.65625 74.21875 41.21875 74.21875 \nQ 47.75 74.21875 53.53125 72.484375 \nQ 59.328125 70.75 64.40625 67.28125 \nz\n\" id=\"DejaVuSans-67\"/>\n     <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n     <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n     <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n     <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n     <path d=\"M 32.171875 -5.078125 \nQ 28.375 -14.84375 24.75 -17.8125 \nQ 21.140625 -20.796875 15.09375 -20.796875 \nL 7.90625 -20.796875 \nL 7.90625 -13.28125 \nL 13.1875 -13.28125 \nQ 16.890625 -13.28125 18.9375 -11.515625 \nQ 21 -9.765625 23.484375 -3.21875 \nL 25.09375 0.875 \nL 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 11.921875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nz\n\" id=\"DejaVuSans-121\"/>\n     <path id=\"DejaVuSans-32\"/>\n     <path d=\"M 9.8125 72.90625 \nL 19.671875 72.90625 \nL 19.671875 8.296875 \nL 55.171875 8.296875 \nL 55.171875 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-76\"/>\n    </defs>\n    <g transform=\"translate(492.982812 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-67\"/>\n     <use x=\"69.824219\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"108.6875\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"169.869141\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"221.96875\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"274.068359\" xlink:href=\"#DejaVuSans-69\"/>\n     <use x=\"337.251953\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"400.630859\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"439.839844\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"478.703125\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"539.884766\" xlink:href=\"#DejaVuSans-112\"/>\n     <use x=\"603.361328\" xlink:href=\"#DejaVuSans-121\"/>\n     <use x=\"662.541016\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"694.328125\" xlink:href=\"#DejaVuSans-76\"/>\n     <use x=\"748.291016\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"809.472656\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"861.572266\" xlink:href=\"#DejaVuSans-115\"/>\n    </g>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 37.103125 494.118125 \nL 256.175 494.118125 \nQ 258.175 494.118125 258.175 492.118125 \nL 258.175 287.624375 \nQ 258.175 285.624375 256.175 285.624375 \nL 37.103125 285.624375 \nQ 35.103125 285.624375 35.103125 287.624375 \nL 35.103125 492.118125 \nQ 35.103125 494.118125 37.103125 494.118125 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_43\">\n     <path d=\"M 39.103125 293.722813 \nL 59.103125 293.722813 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_44\"/>\n    <g id=\"text_17\">\n     <!-- torch.nn.LSTM, no dropout, train -->\n     <defs>\n      <path d=\"M 53.515625 70.515625 \nL 53.515625 60.890625 \nQ 47.90625 63.578125 42.921875 64.890625 \nQ 37.9375 66.21875 33.296875 66.21875 \nQ 25.25 66.21875 20.875 63.09375 \nQ 16.5 59.96875 16.5 54.203125 \nQ 16.5 49.359375 19.40625 46.890625 \nQ 22.3125 44.4375 30.421875 42.921875 \nL 36.375 41.703125 \nQ 47.40625 39.59375 52.65625 34.296875 \nQ 57.90625 29 57.90625 20.125 \nQ 57.90625 9.515625 50.796875 4.046875 \nQ 43.703125 -1.421875 29.984375 -1.421875 \nQ 24.8125 -1.421875 18.96875 -0.25 \nQ 13.140625 0.921875 6.890625 3.21875 \nL 6.890625 13.375 \nQ 12.890625 10.015625 18.65625 8.296875 \nQ 24.421875 6.59375 29.984375 6.59375 \nQ 38.421875 6.59375 43.015625 9.90625 \nQ 47.609375 13.234375 47.609375 19.390625 \nQ 47.609375 24.75 44.3125 27.78125 \nQ 41.015625 30.8125 33.5 32.328125 \nL 27.484375 33.5 \nQ 16.453125 35.6875 11.515625 40.375 \nQ 6.59375 45.0625 6.59375 53.421875 \nQ 6.59375 63.09375 13.40625 68.65625 \nQ 20.21875 74.21875 32.171875 74.21875 \nQ 37.3125 74.21875 42.625 73.28125 \nQ 47.953125 72.359375 53.515625 70.515625 \nz\n\" id=\"DejaVuSans-83\"/>\n      <path d=\"M -0.296875 72.90625 \nL 61.375 72.90625 \nL 61.375 64.59375 \nL 35.5 64.59375 \nL 35.5 0 \nL 25.59375 0 \nL 25.59375 64.59375 \nL -0.296875 64.59375 \nz\n\" id=\"DejaVuSans-84\"/>\n      <path d=\"M 9.8125 72.90625 \nL 24.515625 72.90625 \nL 43.109375 23.296875 \nL 61.8125 72.90625 \nL 76.515625 72.90625 \nL 76.515625 0 \nL 66.890625 0 \nL 66.890625 64.015625 \nL 48.09375 14.015625 \nL 38.1875 14.015625 \nL 19.390625 64.015625 \nL 19.390625 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-77\"/>\n      <path d=\"M 11.71875 12.40625 \nL 22.015625 12.40625 \nL 22.015625 4 \nL 14.015625 -11.625 \nL 7.71875 -11.625 \nL 11.71875 4 \nz\n\" id=\"DejaVuSans-44\"/>\n      <path d=\"M 45.40625 46.390625 \nL 45.40625 75.984375 \nL 54.390625 75.984375 \nL 54.390625 0 \nL 45.40625 0 \nL 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nz\nM 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\n\" id=\"DejaVuSans-100\"/>\n      <path d=\"M 8.5 21.578125 \nL 8.5 54.6875 \nL 17.484375 54.6875 \nL 17.484375 21.921875 \nQ 17.484375 14.15625 20.5 10.265625 \nQ 23.53125 6.390625 29.59375 6.390625 \nQ 36.859375 6.390625 41.078125 11.03125 \nQ 45.3125 15.671875 45.3125 23.6875 \nL 45.3125 54.6875 \nL 54.296875 54.6875 \nL 54.296875 0 \nL 45.3125 0 \nL 45.3125 8.40625 \nQ 42.046875 3.421875 37.71875 1 \nQ 33.40625 -1.421875 27.6875 -1.421875 \nQ 18.265625 -1.421875 13.375 4.4375 \nQ 8.5 10.296875 8.5 21.578125 \nz\nM 31.109375 56 \nz\n\" id=\"DejaVuSans-117\"/>\n      <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n      <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n     </defs>\n     <g transform=\"translate(67.103125 297.222813)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"100.390625\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"139.253906\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"194.234375\" xlink:href=\"#DejaVuSans-104\"/>\n      <use x=\"257.613281\" xlink:href=\"#DejaVuSans-46\"/>\n      <use x=\"289.400391\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"352.779297\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"416.158203\" xlink:href=\"#DejaVuSans-46\"/>\n      <use x=\"447.945312\" xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"503.658203\" xlink:href=\"#DejaVuSans-83\"/>\n      <use x=\"567.134766\" xlink:href=\"#DejaVuSans-84\"/>\n      <use x=\"628.21875\" xlink:href=\"#DejaVuSans-77\"/>\n      <use x=\"714.498047\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"746.285156\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"778.072266\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"841.451172\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"902.632812\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"934.419922\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"997.896484\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"1036.759766\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1097.941406\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"1161.417969\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1222.599609\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"1285.978516\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1325.1875\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"1356.974609\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1388.761719\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1427.970703\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"1469.083984\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"1530.363281\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"1558.146484\" xlink:href=\"#DejaVuSans-110\"/>\n     </g>\n    </g>\n    <g id=\"line2d_45\">\n     <path d=\"M 39.103125 308.400938 \nL 59.103125 308.400938 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_46\"/>\n    <g id=\"text_18\">\n     <!-- RNNLayer, no dropout, train -->\n     <defs>\n      <path d=\"M 44.390625 34.1875 \nQ 47.5625 33.109375 50.5625 29.59375 \nQ 53.5625 26.078125 56.59375 19.921875 \nL 66.609375 0 \nL 56 0 \nL 46.6875 18.703125 \nQ 43.0625 26.03125 39.671875 28.421875 \nQ 36.28125 30.8125 30.421875 30.8125 \nL 19.671875 30.8125 \nL 19.671875 0 \nL 9.8125 0 \nL 9.8125 72.90625 \nL 32.078125 72.90625 \nQ 44.578125 72.90625 50.734375 67.671875 \nQ 56.890625 62.453125 56.890625 51.90625 \nQ 56.890625 45.015625 53.6875 40.46875 \nQ 50.484375 35.9375 44.390625 34.1875 \nz\nM 19.671875 64.796875 \nL 19.671875 38.921875 \nL 32.078125 38.921875 \nQ 39.203125 38.921875 42.84375 42.21875 \nQ 46.484375 45.515625 46.484375 51.90625 \nQ 46.484375 58.296875 42.84375 61.546875 \nQ 39.203125 64.796875 32.078125 64.796875 \nz\n\" id=\"DejaVuSans-82\"/>\n      <path d=\"M 9.8125 72.90625 \nL 23.09375 72.90625 \nL 55.421875 11.921875 \nL 55.421875 72.90625 \nL 64.984375 72.90625 \nL 64.984375 0 \nL 51.703125 0 \nL 19.390625 60.984375 \nL 19.390625 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-78\"/>\n      <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n     </defs>\n     <g transform=\"translate(67.103125 311.900938)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-82\"/>\n      <use x=\"69.482422\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"144.287109\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"219.091797\" xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"274.804688\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"336.083984\" xlink:href=\"#DejaVuSans-121\"/>\n      <use x=\"395.263672\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"456.787109\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"497.900391\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"529.6875\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"561.474609\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"624.853516\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"686.035156\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"717.822266\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"781.298828\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"820.162109\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"881.34375\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"944.820312\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1006.001953\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"1069.380859\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1108.589844\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"1140.376953\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1172.164062\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1211.373047\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"1252.486328\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"1313.765625\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"1341.548828\" xlink:href=\"#DejaVuSans-110\"/>\n     </g>\n    </g>\n    <g id=\"line2d_47\">\n     <path d=\"M 39.103125 323.079063 \nL 59.103125 323.079063 \n\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_48\"/>\n    <g id=\"text_19\">\n     <!-- RNNLayer, dropout=0.25, train -->\n     <defs>\n      <path d=\"M 10.59375 45.40625 \nL 73.1875 45.40625 \nL 73.1875 37.203125 \nL 10.59375 37.203125 \nz\nM 10.59375 25.484375 \nL 73.1875 25.484375 \nL 73.1875 17.1875 \nL 10.59375 17.1875 \nz\n\" id=\"DejaVuSans-61\"/>\n      <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n     </defs>\n     <g transform=\"translate(67.103125 326.579063)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-82\"/>\n      <use x=\"69.482422\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"144.287109\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"219.091797\" xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"274.804688\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"336.083984\" xlink:href=\"#DejaVuSans-121\"/>\n      <use x=\"395.263672\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"456.787109\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"497.900391\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"529.6875\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"561.474609\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"624.951172\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"663.814453\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"724.996094\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"788.472656\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"849.654297\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"913.033203\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"952.242188\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"1036.03125\" xlink:href=\"#DejaVuSans-48\"/>\n      <use x=\"1099.654297\" xlink:href=\"#DejaVuSans-46\"/>\n      <use x=\"1131.441406\" xlink:href=\"#DejaVuSans-50\"/>\n      <use x=\"1195.064453\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1258.6875\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"1290.474609\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1322.261719\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1361.470703\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"1402.583984\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"1463.863281\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"1491.646484\" xlink:href=\"#DejaVuSans-110\"/>\n     </g>\n    </g>\n    <g id=\"line2d_49\">\n     <path d=\"M 39.103125 337.757188 \nL 59.103125 337.757188 \n\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_50\"/>\n    <g id=\"text_20\">\n     <!-- FastRNNLayer, no dropout, train -->\n     <defs>\n      <path d=\"M 9.8125 72.90625 \nL 51.703125 72.90625 \nL 51.703125 64.59375 \nL 19.671875 64.59375 \nL 19.671875 43.109375 \nL 48.578125 43.109375 \nL 48.578125 34.8125 \nL 19.671875 34.8125 \nL 19.671875 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-70\"/>\n     </defs>\n     <g transform=\"translate(67.103125 341.257188)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-70\"/>\n      <use x=\"48.394531\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"109.673828\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"161.773438\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"200.982422\" xlink:href=\"#DejaVuSans-82\"/>\n      <use x=\"270.464844\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"345.269531\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"420.074219\" xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"475.787109\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"537.066406\" xlink:href=\"#DejaVuSans-121\"/>\n      <use x=\"596.246094\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"657.769531\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"698.882812\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"730.669922\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"762.457031\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"825.835938\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"887.017578\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"918.804688\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"982.28125\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"1021.144531\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1082.326172\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"1145.802734\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1206.984375\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"1270.363281\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1309.572266\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"1341.359375\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1373.146484\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1412.355469\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"1453.46875\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"1514.748047\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"1542.53125\" xlink:href=\"#DejaVuSans-110\"/>\n     </g>\n    </g>\n    <g id=\"line2d_51\">\n     <path d=\"M 39.103125 352.435313 \nL 59.103125 352.435313 \n\" style=\"fill:none;stroke:#9467bd;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_52\"/>\n    <g id=\"text_21\">\n     <!-- FastRNNLayer, dropout=0.25, train -->\n     <g transform=\"translate(67.103125 355.935313)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-70\"/>\n      <use x=\"48.394531\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"109.673828\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"161.773438\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"200.982422\" xlink:href=\"#DejaVuSans-82\"/>\n      <use x=\"270.464844\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"345.269531\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"420.074219\" xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"475.787109\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"537.066406\" xlink:href=\"#DejaVuSans-121\"/>\n      <use x=\"596.246094\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"657.769531\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"698.882812\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"730.669922\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"762.457031\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"825.933594\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"864.796875\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"925.978516\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"989.455078\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1050.636719\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"1114.015625\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1153.224609\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"1237.013672\" xlink:href=\"#DejaVuSans-48\"/>\n      <use x=\"1300.636719\" xlink:href=\"#DejaVuSans-46\"/>\n      <use x=\"1332.423828\" xlink:href=\"#DejaVuSans-50\"/>\n      <use x=\"1396.046875\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1459.669922\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"1491.457031\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1523.244141\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1562.453125\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"1603.566406\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"1664.845703\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"1692.628906\" xlink:href=\"#DejaVuSans-110\"/>\n     </g>\n    </g>\n    <g id=\"line2d_53\">\n     <path d=\"M 39.103125 367.113438 \nL 59.103125 367.113438 \n\" style=\"fill:none;stroke:#8c564b;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_54\"/>\n    <g id=\"text_22\">\n     <!-- HandmadeLSTM, no dropout, train -->\n     <defs>\n      <path d=\"M 9.8125 72.90625 \nL 19.671875 72.90625 \nL 19.671875 43.015625 \nL 55.515625 43.015625 \nL 55.515625 72.90625 \nL 65.375 72.90625 \nL 65.375 0 \nL 55.515625 0 \nL 55.515625 34.71875 \nL 19.671875 34.71875 \nL 19.671875 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-72\"/>\n      <path d=\"M 52 44.1875 \nQ 55.375 50.25 60.0625 53.125 \nQ 64.75 56 71.09375 56 \nQ 79.640625 56 84.28125 50.015625 \nQ 88.921875 44.046875 88.921875 33.015625 \nL 88.921875 0 \nL 79.890625 0 \nL 79.890625 32.71875 \nQ 79.890625 40.578125 77.09375 44.375 \nQ 74.3125 48.1875 68.609375 48.1875 \nQ 61.625 48.1875 57.5625 43.546875 \nQ 53.515625 38.921875 53.515625 30.90625 \nL 53.515625 0 \nL 44.484375 0 \nL 44.484375 32.71875 \nQ 44.484375 40.625 41.703125 44.40625 \nQ 38.921875 48.1875 33.109375 48.1875 \nQ 26.21875 48.1875 22.15625 43.53125 \nQ 18.109375 38.875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.1875 51.21875 25.484375 53.609375 \nQ 29.78125 56 35.6875 56 \nQ 41.65625 56 45.828125 52.96875 \nQ 50 49.953125 52 44.1875 \nz\n\" id=\"DejaVuSans-109\"/>\n     </defs>\n     <g transform=\"translate(67.103125 370.613438)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-72\"/>\n      <use x=\"75.195312\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"136.474609\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"199.853516\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"263.330078\" xlink:href=\"#DejaVuSans-109\"/>\n      <use x=\"360.742188\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"422.021484\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"485.498047\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"547.021484\" xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"602.734375\" xlink:href=\"#DejaVuSans-83\"/>\n      <use x=\"666.210938\" xlink:href=\"#DejaVuSans-84\"/>\n      <use x=\"727.294922\" xlink:href=\"#DejaVuSans-77\"/>\n      <use x=\"813.574219\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"845.361328\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"877.148438\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"940.527344\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1001.708984\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1033.496094\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"1096.972656\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"1135.835938\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1197.017578\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"1260.494141\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1321.675781\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"1385.054688\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1424.263672\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"1456.050781\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1487.837891\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1527.046875\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"1568.160156\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"1629.439453\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"1657.222656\" xlink:href=\"#DejaVuSans-110\"/>\n     </g>\n    </g>\n    <g id=\"line2d_55\">\n     <path d=\"M 39.103125 381.791563 \nL 59.103125 381.791563 \n\" style=\"fill:none;stroke:#e377c2;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_56\"/>\n    <g id=\"text_23\">\n     <!-- HandmadeLSTM, dropout=0.25, train -->\n     <g transform=\"translate(67.103125 385.291563)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-72\"/>\n      <use x=\"75.195312\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"136.474609\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"199.853516\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"263.330078\" xlink:href=\"#DejaVuSans-109\"/>\n      <use x=\"360.742188\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"422.021484\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"485.498047\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"547.021484\" xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"602.734375\" xlink:href=\"#DejaVuSans-83\"/>\n      <use x=\"666.210938\" xlink:href=\"#DejaVuSans-84\"/>\n      <use x=\"727.294922\" xlink:href=\"#DejaVuSans-77\"/>\n      <use x=\"813.574219\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"845.361328\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"877.148438\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"940.625\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"979.488281\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1040.669922\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"1104.146484\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1165.328125\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"1228.707031\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1267.916016\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"1351.705078\" xlink:href=\"#DejaVuSans-48\"/>\n      <use x=\"1415.328125\" xlink:href=\"#DejaVuSans-46\"/>\n      <use x=\"1447.115234\" xlink:href=\"#DejaVuSans-50\"/>\n      <use x=\"1510.738281\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1574.361328\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"1606.148438\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1637.935547\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1677.144531\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"1718.257812\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"1779.537109\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"1807.320312\" xlink:href=\"#DejaVuSans-110\"/>\n     </g>\n    </g>\n    <g id=\"line2d_57\">\n     <path d=\"M 39.103125 396.469688 \nL 59.103125 396.469688 \n\" style=\"fill:none;stroke:#7f7f7f;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_58\"/>\n    <g id=\"text_24\">\n     <!-- torch.nn.LSTM, no dropout, test -->\n     <g transform=\"translate(67.103125 399.969688)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"100.390625\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"139.253906\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"194.234375\" xlink:href=\"#DejaVuSans-104\"/>\n      <use x=\"257.613281\" xlink:href=\"#DejaVuSans-46\"/>\n      <use x=\"289.400391\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"352.779297\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"416.158203\" xlink:href=\"#DejaVuSans-46\"/>\n      <use x=\"447.945312\" xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"503.658203\" xlink:href=\"#DejaVuSans-83\"/>\n      <use x=\"567.134766\" xlink:href=\"#DejaVuSans-84\"/>\n      <use x=\"628.21875\" xlink:href=\"#DejaVuSans-77\"/>\n      <use x=\"714.498047\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"746.285156\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"778.072266\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"841.451172\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"902.632812\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"934.419922\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"997.896484\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"1036.759766\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1097.941406\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"1161.417969\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1222.599609\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"1285.978516\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1325.1875\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"1356.974609\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1388.761719\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1427.970703\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"1489.494141\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"1541.59375\" xlink:href=\"#DejaVuSans-116\"/>\n     </g>\n    </g>\n    <g id=\"line2d_59\">\n     <path d=\"M 39.103125 411.147812 \nL 59.103125 411.147812 \n\" style=\"fill:none;stroke:#bcbd22;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_60\"/>\n    <g id=\"text_25\">\n     <!-- RNNLayer, no dropout, test -->\n     <g transform=\"translate(67.103125 414.647812)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-82\"/>\n      <use x=\"69.482422\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"144.287109\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"219.091797\" xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"274.804688\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"336.083984\" xlink:href=\"#DejaVuSans-121\"/>\n      <use x=\"395.263672\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"456.787109\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"497.900391\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"529.6875\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"561.474609\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"624.853516\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"686.035156\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"717.822266\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"781.298828\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"820.162109\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"881.34375\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"944.820312\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1006.001953\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"1069.380859\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1108.589844\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"1140.376953\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1172.164062\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1211.373047\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"1272.896484\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"1324.996094\" xlink:href=\"#DejaVuSans-116\"/>\n     </g>\n    </g>\n    <g id=\"line2d_61\">\n     <path d=\"M 39.103125 425.825938 \nL 59.103125 425.825938 \n\" style=\"fill:none;stroke:#17becf;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_62\"/>\n    <g id=\"text_26\">\n     <!-- RNNLayer, dropout=0.25, test -->\n     <g transform=\"translate(67.103125 429.325938)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-82\"/>\n      <use x=\"69.482422\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"144.287109\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"219.091797\" xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"274.804688\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"336.083984\" xlink:href=\"#DejaVuSans-121\"/>\n      <use x=\"395.263672\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"456.787109\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"497.900391\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"529.6875\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"561.474609\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"624.951172\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"663.814453\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"724.996094\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"788.472656\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"849.654297\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"913.033203\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"952.242188\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"1036.03125\" xlink:href=\"#DejaVuSans-48\"/>\n      <use x=\"1099.654297\" xlink:href=\"#DejaVuSans-46\"/>\n      <use x=\"1131.441406\" xlink:href=\"#DejaVuSans-50\"/>\n      <use x=\"1195.064453\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1258.6875\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"1290.474609\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1322.261719\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1361.470703\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"1422.994141\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"1475.09375\" xlink:href=\"#DejaVuSans-116\"/>\n     </g>\n    </g>\n    <g id=\"line2d_63\">\n     <path d=\"M 39.103125 440.504063 \nL 59.103125 440.504063 \n\" style=\"fill:none;stroke:#1f77b4;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_64\"/>\n    <g id=\"text_27\">\n     <!-- FastRNNLayer, no dropout, test -->\n     <g transform=\"translate(67.103125 444.004063)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-70\"/>\n      <use x=\"48.394531\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"109.673828\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"161.773438\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"200.982422\" xlink:href=\"#DejaVuSans-82\"/>\n      <use x=\"270.464844\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"345.269531\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"420.074219\" xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"475.787109\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"537.066406\" xlink:href=\"#DejaVuSans-121\"/>\n      <use x=\"596.246094\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"657.769531\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"698.882812\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"730.669922\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"762.457031\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"825.835938\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"887.017578\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"918.804688\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"982.28125\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"1021.144531\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1082.326172\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"1145.802734\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1206.984375\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"1270.363281\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1309.572266\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"1341.359375\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1373.146484\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1412.355469\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"1473.878906\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"1525.978516\" xlink:href=\"#DejaVuSans-116\"/>\n     </g>\n    </g>\n    <g id=\"line2d_65\">\n     <path d=\"M 39.103125 455.182188 \nL 59.103125 455.182188 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_66\"/>\n    <g id=\"text_28\">\n     <!-- FastRNNLayer, dropout=0.25, test -->\n     <g transform=\"translate(67.103125 458.682188)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-70\"/>\n      <use x=\"48.394531\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"109.673828\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"161.773438\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"200.982422\" xlink:href=\"#DejaVuSans-82\"/>\n      <use x=\"270.464844\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"345.269531\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"420.074219\" xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"475.787109\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"537.066406\" xlink:href=\"#DejaVuSans-121\"/>\n      <use x=\"596.246094\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"657.769531\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"698.882812\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"730.669922\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"762.457031\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"825.933594\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"864.796875\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"925.978516\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"989.455078\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1050.636719\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"1114.015625\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1153.224609\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"1237.013672\" xlink:href=\"#DejaVuSans-48\"/>\n      <use x=\"1300.636719\" xlink:href=\"#DejaVuSans-46\"/>\n      <use x=\"1332.423828\" xlink:href=\"#DejaVuSans-50\"/>\n      <use x=\"1396.046875\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1459.669922\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"1491.457031\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1523.244141\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1562.453125\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"1623.976562\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"1676.076172\" xlink:href=\"#DejaVuSans-116\"/>\n     </g>\n    </g>\n    <g id=\"line2d_67\">\n     <path d=\"M 39.103125 469.860312 \nL 59.103125 469.860312 \n\" style=\"fill:none;stroke:#2ca02c;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_68\"/>\n    <g id=\"text_29\">\n     <!-- HandmadeLSTM, no dropout, test -->\n     <g transform=\"translate(67.103125 473.360312)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-72\"/>\n      <use x=\"75.195312\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"136.474609\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"199.853516\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"263.330078\" xlink:href=\"#DejaVuSans-109\"/>\n      <use x=\"360.742188\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"422.021484\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"485.498047\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"547.021484\" xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"602.734375\" xlink:href=\"#DejaVuSans-83\"/>\n      <use x=\"666.210938\" xlink:href=\"#DejaVuSans-84\"/>\n      <use x=\"727.294922\" xlink:href=\"#DejaVuSans-77\"/>\n      <use x=\"813.574219\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"845.361328\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"877.148438\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"940.527344\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1001.708984\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1033.496094\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"1096.972656\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"1135.835938\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1197.017578\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"1260.494141\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1321.675781\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"1385.054688\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1424.263672\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"1456.050781\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1487.837891\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1527.046875\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"1588.570312\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"1640.669922\" xlink:href=\"#DejaVuSans-116\"/>\n     </g>\n    </g>\n    <g id=\"line2d_69\">\n     <path d=\"M 39.103125 484.538437 \nL 59.103125 484.538437 \n\" style=\"fill:none;stroke:#d62728;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_70\"/>\n    <g id=\"text_30\">\n     <!-- HandmadeLSTM, dropout=0.25, test -->\n     <g transform=\"translate(67.103125 488.038437)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-72\"/>\n      <use x=\"75.195312\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"136.474609\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"199.853516\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"263.330078\" xlink:href=\"#DejaVuSans-109\"/>\n      <use x=\"360.742188\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"422.021484\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"485.498047\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"547.021484\" xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"602.734375\" xlink:href=\"#DejaVuSans-83\"/>\n      <use x=\"666.210938\" xlink:href=\"#DejaVuSans-84\"/>\n      <use x=\"727.294922\" xlink:href=\"#DejaVuSans-77\"/>\n      <use x=\"813.574219\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"845.361328\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"877.148438\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"940.625\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"979.488281\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1040.669922\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"1104.146484\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1165.328125\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"1228.707031\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1267.916016\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"1351.705078\" xlink:href=\"#DejaVuSans-48\"/>\n      <use x=\"1415.328125\" xlink:href=\"#DejaVuSans-46\"/>\n      <use x=\"1447.115234\" xlink:href=\"#DejaVuSans-50\"/>\n      <use x=\"1510.738281\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1574.361328\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"1606.148438\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1637.935547\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1677.144531\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"1738.667969\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"1790.767578\" xlink:href=\"#DejaVuSans-116\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_2\">\n   <g id=\"patch_8\">\n    <path d=\"M 30.103125 1033.718125 \nL 1065.503125 1033.718125 \nL 1065.503125 556.918125 \nL 30.103125 556.918125 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_3\">\n    <g id=\"xtick_8\">\n     <g id=\"line2d_71\">\n      <path clip-path=\"url(#p15e0205169)\" d=\"M 144.400528 1033.718125 \nL 144.400528 556.918125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_72\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"144.400528\" xlink:href=\"#m1e8bbe0085\" y=\"1033.718125\"/>\n      </g>\n     </g>\n     <g id=\"text_31\">\n      <!-- 2 -->\n      <g transform=\"translate(141.219278 1048.316562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_73\">\n      <path clip-path=\"url(#p15e0205169)\" d=\"M 278.86806 1033.718125 \nL 278.86806 556.918125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_74\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"278.86806\" xlink:href=\"#m1e8bbe0085\" y=\"1033.718125\"/>\n      </g>\n     </g>\n     <g id=\"text_32\">\n      <!-- 4 -->\n      <g transform=\"translate(275.68681 1048.316562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_10\">\n     <g id=\"line2d_75\">\n      <path clip-path=\"url(#p15e0205169)\" d=\"M 413.335593 1033.718125 \nL 413.335593 556.918125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_76\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"413.335593\" xlink:href=\"#m1e8bbe0085\" y=\"1033.718125\"/>\n      </g>\n     </g>\n     <g id=\"text_33\">\n      <!-- 6 -->\n      <g transform=\"translate(410.154343 1048.316562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_11\">\n     <g id=\"line2d_77\">\n      <path clip-path=\"url(#p15e0205169)\" d=\"M 547.803125 1033.718125 \nL 547.803125 556.918125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_78\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"547.803125\" xlink:href=\"#m1e8bbe0085\" y=\"1033.718125\"/>\n      </g>\n     </g>\n     <g id=\"text_34\">\n      <!-- 8 -->\n      <g transform=\"translate(544.621875 1048.316562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_12\">\n     <g id=\"line2d_79\">\n      <path clip-path=\"url(#p15e0205169)\" d=\"M 682.270657 1033.718125 \nL 682.270657 556.918125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_80\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"682.270657\" xlink:href=\"#m1e8bbe0085\" y=\"1033.718125\"/>\n      </g>\n     </g>\n     <g id=\"text_35\">\n      <!-- 10 -->\n      <g transform=\"translate(675.908157 1048.316562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_13\">\n     <g id=\"line2d_81\">\n      <path clip-path=\"url(#p15e0205169)\" d=\"M 816.73819 1033.718125 \nL 816.73819 556.918125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_82\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"816.73819\" xlink:href=\"#m1e8bbe0085\" y=\"1033.718125\"/>\n      </g>\n     </g>\n     <g id=\"text_36\">\n      <!-- 12 -->\n      <g transform=\"translate(810.37569 1048.316562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_14\">\n     <g id=\"line2d_83\">\n      <path clip-path=\"url(#p15e0205169)\" d=\"M 951.205722 1033.718125 \nL 951.205722 556.918125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_84\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"951.205722\" xlink:href=\"#m1e8bbe0085\" y=\"1033.718125\"/>\n      </g>\n     </g>\n     <g id=\"text_37\">\n      <!-- 14 -->\n      <g transform=\"translate(944.843222 1048.316562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_38\">\n     <!-- Epoch -->\n     <g transform=\"translate(532.492187 1061.994688)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"63.183594\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"126.660156\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"187.841797\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"242.822266\" xlink:href=\"#DejaVuSans-104\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_4\">\n    <g id=\"ytick_8\">\n     <g id=\"line2d_85\">\n      <path clip-path=\"url(#p15e0205169)\" d=\"M 30.103125 1017.985874 \nL 1065.503125 1017.985874 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_86\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#maf725b042b\" y=\"1017.985874\"/>\n      </g>\n     </g>\n     <g id=\"text_39\">\n      <!-- 0.2 -->\n      <g transform=\"translate(7.2 1021.785093)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_9\">\n     <g id=\"line2d_87\">\n      <path clip-path=\"url(#p15e0205169)\" d=\"M 30.103125 934.552215 \nL 1065.503125 934.552215 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_88\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#maf725b042b\" y=\"934.552215\"/>\n      </g>\n     </g>\n     <g id=\"text_40\">\n      <!-- 0.3 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(7.2 938.351434)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_10\">\n     <g id=\"line2d_89\">\n      <path clip-path=\"url(#p15e0205169)\" d=\"M 30.103125 851.118556 \nL 1065.503125 851.118556 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_90\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#maf725b042b\" y=\"851.118556\"/>\n      </g>\n     </g>\n     <g id=\"text_41\">\n      <!-- 0.4 -->\n      <g transform=\"translate(7.2 854.917775)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_11\">\n     <g id=\"line2d_91\">\n      <path clip-path=\"url(#p15e0205169)\" d=\"M 30.103125 767.684897 \nL 1065.503125 767.684897 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_92\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#maf725b042b\" y=\"767.684897\"/>\n      </g>\n     </g>\n     <g id=\"text_42\">\n      <!-- 0.5 -->\n      <g transform=\"translate(7.2 771.484116)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_12\">\n     <g id=\"line2d_93\">\n      <path clip-path=\"url(#p15e0205169)\" d=\"M 30.103125 684.251238 \nL 1065.503125 684.251238 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_94\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#maf725b042b\" y=\"684.251238\"/>\n      </g>\n     </g>\n     <g id=\"text_43\">\n      <!-- 0.6 -->\n      <g transform=\"translate(7.2 688.050457)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_13\">\n     <g id=\"line2d_95\">\n      <path clip-path=\"url(#p15e0205169)\" d=\"M 30.103125 600.817579 \nL 1065.503125 600.817579 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_96\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#maf725b042b\" y=\"600.817579\"/>\n      </g>\n     </g>\n     <g id=\"text_44\">\n      <!-- 0.7 -->\n      <defs>\n       <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n      </defs>\n      <g transform=\"translate(7.2 604.616798)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_97\">\n    <path clip-path=\"url(#p15e0205169)\" d=\"M 77.166761 974.266637 \nL 144.400528 956.912436 \nL 211.634294 900.077427 \nL 278.86806 876.348895 \nL 346.101826 855.39036 \nL 413.335593 834.164837 \nL 480.569359 815.375577 \nL 547.803125 799.856916 \nL 615.036891 786.140423 \nL 682.270657 773.758868 \nL 749.504424 758.27358 \nL 816.73819 735.212517 \nL 883.971956 711.25037 \nL 951.205722 684.75184 \nL 1018.439489 653.24729 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_98\">\n    <path clip-path=\"url(#p15e0205169)\" d=\"M 77.166761 984.979519 \nL 144.400528 914.127655 \nL 211.634294 882.522985 \nL 278.86806 857.459514 \nL 346.101826 837.735797 \nL 413.335593 819.313645 \nL 480.569359 802.960648 \nL 547.803125 784.405002 \nL 615.036891 769.186703 \nL 682.270657 739.784682 \nL 749.504424 719.360122 \nL 816.73819 686.320393 \nL 883.971956 658.720538 \nL 951.205722 624.012136 \nL 1018.439489 590.138071 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_99\">\n    <path clip-path=\"url(#p15e0205169)\" d=\"M 77.166761 994.123848 \nL 144.400528 911.224164 \nL 211.634294 889.498039 \nL 278.86806 872.143838 \nL 346.101826 858.927947 \nL 413.335593 844.010008 \nL 480.569359 836.200618 \nL 547.803125 827.423397 \nL 615.036891 820.61521 \nL 682.270657 812.572206 \nL 749.504424 811.437508 \nL 816.73819 805.396911 \nL 883.971956 799.756796 \nL 951.205722 798.421857 \nL 1018.439489 785.606447 \n\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_100\">\n    <path clip-path=\"url(#p15e0205169)\" d=\"M 77.166761 950.771719 \nL 144.400528 882.823347 \nL 211.634294 858.761079 \nL 278.86806 831.628453 \nL 346.101826 819.7475 \nL 413.335593 801.058361 \nL 480.569359 784.77211 \nL 547.803125 779.766091 \nL 615.036891 750.430816 \nL 682.270657 732.175532 \nL 749.504424 697.166769 \nL 816.73819 690.925931 \nL 883.971956 650.844401 \nL 951.205722 610.395763 \nL 1018.439489 585.966388 \n\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_101\">\n    <path clip-path=\"url(#p15e0205169)\" d=\"M 77.166761 991.921199 \nL 144.400528 927.076559 \nL 211.634294 884.759007 \nL 278.86806 865.70276 \nL 346.101826 841.573746 \nL 413.335593 834.398451 \nL 480.569359 822.784486 \nL 547.803125 813.907144 \nL 615.036891 804.495827 \nL 682.270657 801.62571 \nL 749.504424 793.282344 \nL 816.73819 783.070064 \nL 883.971956 776.8626 \nL 951.205722 772.72429 \nL 1018.439489 774.326216 \n\" style=\"fill:none;stroke:#9467bd;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_102\">\n    <path clip-path=\"url(#p15e0205169)\" d=\"M 77.166761 987.215541 \nL 144.400528 898.342007 \nL 211.634294 862.33204 \nL 278.86806 832.930018 \nL 346.101826 815.909552 \nL 413.335593 795.585113 \nL 480.569359 785.873435 \nL 547.803125 762.245023 \nL 615.036891 755.503583 \nL 682.270657 729.839389 \nL 749.504424 697.800864 \nL 816.73819 679.845941 \nL 883.971956 650.977895 \nL 951.205722 607.659139 \nL 1018.439489 578.590852 \n\" style=\"fill:none;stroke:#8c564b;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_103\">\n    <path clip-path=\"url(#p15e0205169)\" d=\"M 77.166761 1009.575761 \nL 144.400528 922.003793 \nL 211.634294 897.607791 \nL 278.86806 887.695872 \nL 346.101826 866.603843 \nL 413.335593 853.187711 \nL 480.569359 841.974227 \nL 547.803125 837.001581 \nL 615.036891 835.166041 \nL 682.270657 817.544852 \nL 749.504424 812.472085 \nL 816.73819 808.934498 \nL 883.971956 802.059565 \nL 951.205722 798.288363 \nL 1018.439489 799.957036 \n\" style=\"fill:none;stroke:#e377c2;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_104\">\n    <path clip-path=\"url(#p15e0205169)\" d=\"M 77.166761 973.565794 \nL 144.400528 958.914844 \nL 211.634294 901.612607 \nL 278.86806 884.49202 \nL 346.101826 877.950821 \nL 413.335593 859.762283 \nL 480.569359 859.228308 \nL 547.803125 856.191323 \nL 615.036891 852.286627 \nL 682.270657 857.826622 \nL 749.504424 869.807696 \nL 816.73819 868.639625 \nL 883.971956 861.697944 \nL 951.205722 869.841069 \nL 1018.439489 873.044922 \n\" style=\"fill:none;stroke:#7f7f7f;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_105\">\n    <path clip-path=\"url(#p15e0205169)\" d=\"M 77.166761 981.642172 \nL 144.400528 915.095486 \nL 211.634294 889.331172 \nL 278.86806 873.679018 \nL 346.101826 863.600232 \nL 413.335593 854.355782 \nL 480.569359 856.25807 \nL 547.803125 856.758672 \nL 615.036891 849.783618 \nL 682.270657 851.919519 \nL 749.504424 864.16758 \nL 816.73819 867.504927 \nL 883.971956 866.236735 \nL 951.205722 870.975767 \nL 1018.439489 880.787565 \n\" style=\"fill:none;stroke:#bcbd22;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_106\">\n    <path clip-path=\"url(#p15e0205169)\" d=\"M 77.166761 992.02132 \nL 144.400528 909.25513 \nL 211.634294 889.631533 \nL 278.86806 877.817327 \nL 346.101826 870.942394 \nL 413.335593 864.16758 \nL 480.569359 858.727706 \nL 547.803125 856.391563 \nL 615.036891 852.320001 \nL 682.270657 846.546392 \nL 749.504424 843.509406 \nL 816.73819 844.677478 \nL 883.971956 842.574949 \nL 951.205722 841.773986 \nL 1018.439489 840.872903 \n\" style=\"fill:none;stroke:#17becf;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_107\">\n    <path clip-path=\"url(#p15e0205169)\" d=\"M 77.166761 948.635817 \nL 144.400528 897.073816 \nL 211.634294 879.118892 \nL 278.86806 863.733725 \nL 346.101826 855.991082 \nL 413.335593 859.929151 \nL 480.569359 861.397583 \nL 547.803125 855.023251 \nL 615.036891 855.957708 \nL 682.270657 854.122168 \nL 749.504424 869.07348 \nL 816.73819 883.590936 \nL 883.971956 867.304686 \nL 951.205722 879.519374 \nL 1018.439489 885.426477 \n\" style=\"fill:none;stroke:#1f77b4;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_108\">\n    <path clip-path=\"url(#p15e0205169)\" d=\"M 77.166761 992.822283 \nL 144.400528 922.037166 \nL 211.634294 889.297799 \nL 278.86806 874.746968 \nL 346.101826 858.026863 \nL 413.335593 857.759875 \nL 480.569359 852.186507 \nL 547.803125 845.812175 \nL 615.036891 845.311573 \nL 682.270657 842.942058 \nL 749.504424 840.372301 \nL 816.73819 843.142298 \nL 883.971956 841.673866 \nL 951.205722 842.77519 \nL 1018.439489 837.034955 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_109\">\n    <path clip-path=\"url(#p15e0205169)\" d=\"M 77.166761 988.016504 \nL 144.400528 899.243091 \nL 211.634294 884.425273 \nL 278.86806 856.792045 \nL 346.101826 852.787229 \nL 413.335593 852.420121 \nL 480.569359 850.184099 \nL 547.803125 849.249642 \nL 615.036891 855.757468 \nL 682.270657 849.51663 \nL 749.504424 863.833846 \nL 816.73819 858.293851 \nL 883.971956 864.367821 \nL 951.205722 880.286963 \nL 1018.439489 881.955637 \n\" style=\"fill:none;stroke:#2ca02c;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_110\">\n    <path clip-path=\"url(#p15e0205169)\" d=\"M 77.166761 1012.045398 \nL 144.400528 916.764159 \nL 211.634294 893.803216 \nL 278.86806 884.959248 \nL 346.101826 872.64444 \nL 413.335593 865.70276 \nL 480.569359 859.128187 \nL 547.803125 854.556023 \nL 615.036891 853.087591 \nL 682.270657 848.782414 \nL 749.504424 846.613139 \nL 816.73819 844.644104 \nL 883.971956 840.605915 \nL 951.205722 838.236399 \nL 1018.439489 839.804952 \n\" style=\"fill:none;stroke:#d62728;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path d=\"M 30.103125 1033.718125 \nL 30.103125 556.918125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path d=\"M 1065.503125 1033.718125 \nL 1065.503125 556.918125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path d=\"M 30.103125 1033.718125 \nL 1065.503125 1033.718125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_12\">\n    <path d=\"M 30.103125 556.918125 \nL 1065.503125 556.918125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_45\">\n    <!-- Accuracy -->\n    <defs>\n     <path d=\"M 34.1875 63.1875 \nL 20.796875 26.90625 \nL 47.609375 26.90625 \nz\nM 28.609375 72.90625 \nL 39.796875 72.90625 \nL 67.578125 0 \nL 57.328125 0 \nL 50.6875 18.703125 \nL 17.828125 18.703125 \nL 11.1875 0 \nL 0.78125 0 \nz\n\" id=\"DejaVuSans-65\"/>\n    </defs>\n    <g transform=\"translate(520.409375 550.918125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-65\"/>\n     <use x=\"66.658203\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"121.638672\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"176.619141\" xlink:href=\"#DejaVuSans-117\"/>\n     <use x=\"239.998047\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"281.111328\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"342.390625\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"397.371094\" xlink:href=\"#DejaVuSans-121\"/>\n    </g>\n   </g>\n   <g id=\"legend_2\">\n    <g id=\"patch_13\">\n     <path d=\"M 37.103125 770.411875 \nL 256.175 770.411875 \nQ 258.175 770.411875 258.175 768.411875 \nL 258.175 563.918125 \nQ 258.175 561.918125 256.175 561.918125 \nL 37.103125 561.918125 \nQ 35.103125 561.918125 35.103125 563.918125 \nL 35.103125 768.411875 \nQ 35.103125 770.411875 37.103125 770.411875 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_111\">\n     <path d=\"M 39.103125 570.016562 \nL 59.103125 570.016562 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_112\"/>\n    <g id=\"text_46\">\n     <!-- torch.nn.LSTM, no dropout, train -->\n     <g transform=\"translate(67.103125 573.516562)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"100.390625\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"139.253906\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"194.234375\" xlink:href=\"#DejaVuSans-104\"/>\n      <use x=\"257.613281\" xlink:href=\"#DejaVuSans-46\"/>\n      <use x=\"289.400391\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"352.779297\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"416.158203\" xlink:href=\"#DejaVuSans-46\"/>\n      <use x=\"447.945312\" xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"503.658203\" xlink:href=\"#DejaVuSans-83\"/>\n      <use x=\"567.134766\" xlink:href=\"#DejaVuSans-84\"/>\n      <use x=\"628.21875\" xlink:href=\"#DejaVuSans-77\"/>\n      <use x=\"714.498047\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"746.285156\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"778.072266\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"841.451172\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"902.632812\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"934.419922\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"997.896484\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"1036.759766\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1097.941406\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"1161.417969\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1222.599609\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"1285.978516\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1325.1875\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"1356.974609\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1388.761719\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1427.970703\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"1469.083984\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"1530.363281\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"1558.146484\" xlink:href=\"#DejaVuSans-110\"/>\n     </g>\n    </g>\n    <g id=\"line2d_113\">\n     <path d=\"M 39.103125 584.694687 \nL 59.103125 584.694687 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_114\"/>\n    <g id=\"text_47\">\n     <!-- RNNLayer, no dropout, train -->\n     <g transform=\"translate(67.103125 588.194687)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-82\"/>\n      <use x=\"69.482422\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"144.287109\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"219.091797\" xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"274.804688\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"336.083984\" xlink:href=\"#DejaVuSans-121\"/>\n      <use x=\"395.263672\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"456.787109\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"497.900391\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"529.6875\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"561.474609\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"624.853516\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"686.035156\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"717.822266\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"781.298828\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"820.162109\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"881.34375\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"944.820312\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1006.001953\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"1069.380859\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1108.589844\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"1140.376953\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1172.164062\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1211.373047\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"1252.486328\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"1313.765625\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"1341.548828\" xlink:href=\"#DejaVuSans-110\"/>\n     </g>\n    </g>\n    <g id=\"line2d_115\">\n     <path d=\"M 39.103125 599.372813 \nL 59.103125 599.372813 \n\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_116\"/>\n    <g id=\"text_48\">\n     <!-- RNNLayer, dropout=0.25, train -->\n     <g transform=\"translate(67.103125 602.872813)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-82\"/>\n      <use x=\"69.482422\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"144.287109\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"219.091797\" xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"274.804688\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"336.083984\" xlink:href=\"#DejaVuSans-121\"/>\n      <use x=\"395.263672\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"456.787109\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"497.900391\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"529.6875\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"561.474609\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"624.951172\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"663.814453\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"724.996094\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"788.472656\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"849.654297\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"913.033203\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"952.242188\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"1036.03125\" xlink:href=\"#DejaVuSans-48\"/>\n      <use x=\"1099.654297\" xlink:href=\"#DejaVuSans-46\"/>\n      <use x=\"1131.441406\" xlink:href=\"#DejaVuSans-50\"/>\n      <use x=\"1195.064453\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1258.6875\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"1290.474609\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1322.261719\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1361.470703\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"1402.583984\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"1463.863281\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"1491.646484\" xlink:href=\"#DejaVuSans-110\"/>\n     </g>\n    </g>\n    <g id=\"line2d_117\">\n     <path d=\"M 39.103125 614.050937 \nL 59.103125 614.050937 \n\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_118\"/>\n    <g id=\"text_49\">\n     <!-- FastRNNLayer, no dropout, train -->\n     <g transform=\"translate(67.103125 617.550937)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-70\"/>\n      <use x=\"48.394531\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"109.673828\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"161.773438\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"200.982422\" xlink:href=\"#DejaVuSans-82\"/>\n      <use x=\"270.464844\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"345.269531\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"420.074219\" xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"475.787109\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"537.066406\" xlink:href=\"#DejaVuSans-121\"/>\n      <use x=\"596.246094\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"657.769531\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"698.882812\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"730.669922\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"762.457031\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"825.835938\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"887.017578\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"918.804688\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"982.28125\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"1021.144531\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1082.326172\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"1145.802734\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1206.984375\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"1270.363281\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1309.572266\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"1341.359375\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1373.146484\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1412.355469\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"1453.46875\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"1514.748047\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"1542.53125\" xlink:href=\"#DejaVuSans-110\"/>\n     </g>\n    </g>\n    <g id=\"line2d_119\">\n     <path d=\"M 39.103125 628.729062 \nL 59.103125 628.729062 \n\" style=\"fill:none;stroke:#9467bd;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_120\"/>\n    <g id=\"text_50\">\n     <!-- FastRNNLayer, dropout=0.25, train -->\n     <g transform=\"translate(67.103125 632.229062)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-70\"/>\n      <use x=\"48.394531\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"109.673828\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"161.773438\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"200.982422\" xlink:href=\"#DejaVuSans-82\"/>\n      <use x=\"270.464844\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"345.269531\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"420.074219\" xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"475.787109\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"537.066406\" xlink:href=\"#DejaVuSans-121\"/>\n      <use x=\"596.246094\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"657.769531\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"698.882812\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"730.669922\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"762.457031\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"825.933594\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"864.796875\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"925.978516\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"989.455078\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1050.636719\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"1114.015625\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1153.224609\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"1237.013672\" xlink:href=\"#DejaVuSans-48\"/>\n      <use x=\"1300.636719\" xlink:href=\"#DejaVuSans-46\"/>\n      <use x=\"1332.423828\" xlink:href=\"#DejaVuSans-50\"/>\n      <use x=\"1396.046875\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1459.669922\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"1491.457031\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1523.244141\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1562.453125\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"1603.566406\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"1664.845703\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"1692.628906\" xlink:href=\"#DejaVuSans-110\"/>\n     </g>\n    </g>\n    <g id=\"line2d_121\">\n     <path d=\"M 39.103125 643.407187 \nL 59.103125 643.407187 \n\" style=\"fill:none;stroke:#8c564b;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_122\"/>\n    <g id=\"text_51\">\n     <!-- HandmadeLSTM, no dropout, train -->\n     <g transform=\"translate(67.103125 646.907187)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-72\"/>\n      <use x=\"75.195312\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"136.474609\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"199.853516\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"263.330078\" xlink:href=\"#DejaVuSans-109\"/>\n      <use x=\"360.742188\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"422.021484\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"485.498047\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"547.021484\" xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"602.734375\" xlink:href=\"#DejaVuSans-83\"/>\n      <use x=\"666.210938\" xlink:href=\"#DejaVuSans-84\"/>\n      <use x=\"727.294922\" xlink:href=\"#DejaVuSans-77\"/>\n      <use x=\"813.574219\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"845.361328\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"877.148438\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"940.527344\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1001.708984\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1033.496094\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"1096.972656\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"1135.835938\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1197.017578\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"1260.494141\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1321.675781\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"1385.054688\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1424.263672\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"1456.050781\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1487.837891\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1527.046875\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"1568.160156\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"1629.439453\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"1657.222656\" xlink:href=\"#DejaVuSans-110\"/>\n     </g>\n    </g>\n    <g id=\"line2d_123\">\n     <path d=\"M 39.103125 658.085312 \nL 59.103125 658.085312 \n\" style=\"fill:none;stroke:#e377c2;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_124\"/>\n    <g id=\"text_52\">\n     <!-- HandmadeLSTM, dropout=0.25, train -->\n     <g transform=\"translate(67.103125 661.585312)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-72\"/>\n      <use x=\"75.195312\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"136.474609\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"199.853516\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"263.330078\" xlink:href=\"#DejaVuSans-109\"/>\n      <use x=\"360.742188\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"422.021484\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"485.498047\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"547.021484\" xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"602.734375\" xlink:href=\"#DejaVuSans-83\"/>\n      <use x=\"666.210938\" xlink:href=\"#DejaVuSans-84\"/>\n      <use x=\"727.294922\" xlink:href=\"#DejaVuSans-77\"/>\n      <use x=\"813.574219\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"845.361328\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"877.148438\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"940.625\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"979.488281\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1040.669922\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"1104.146484\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1165.328125\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"1228.707031\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1267.916016\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"1351.705078\" xlink:href=\"#DejaVuSans-48\"/>\n      <use x=\"1415.328125\" xlink:href=\"#DejaVuSans-46\"/>\n      <use x=\"1447.115234\" xlink:href=\"#DejaVuSans-50\"/>\n      <use x=\"1510.738281\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1574.361328\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"1606.148438\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1637.935547\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1677.144531\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"1718.257812\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"1779.537109\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"1807.320312\" xlink:href=\"#DejaVuSans-110\"/>\n     </g>\n    </g>\n    <g id=\"line2d_125\">\n     <path d=\"M 39.103125 672.763438 \nL 59.103125 672.763438 \n\" style=\"fill:none;stroke:#7f7f7f;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_126\"/>\n    <g id=\"text_53\">\n     <!-- torch.nn.LSTM, no dropout, test -->\n     <g transform=\"translate(67.103125 676.263438)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"100.390625\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"139.253906\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"194.234375\" xlink:href=\"#DejaVuSans-104\"/>\n      <use x=\"257.613281\" xlink:href=\"#DejaVuSans-46\"/>\n      <use x=\"289.400391\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"352.779297\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"416.158203\" xlink:href=\"#DejaVuSans-46\"/>\n      <use x=\"447.945312\" xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"503.658203\" xlink:href=\"#DejaVuSans-83\"/>\n      <use x=\"567.134766\" xlink:href=\"#DejaVuSans-84\"/>\n      <use x=\"628.21875\" xlink:href=\"#DejaVuSans-77\"/>\n      <use x=\"714.498047\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"746.285156\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"778.072266\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"841.451172\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"902.632812\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"934.419922\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"997.896484\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"1036.759766\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1097.941406\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"1161.417969\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1222.599609\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"1285.978516\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1325.1875\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"1356.974609\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1388.761719\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1427.970703\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"1489.494141\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"1541.59375\" xlink:href=\"#DejaVuSans-116\"/>\n     </g>\n    </g>\n    <g id=\"line2d_127\">\n     <path d=\"M 39.103125 687.441562 \nL 59.103125 687.441562 \n\" style=\"fill:none;stroke:#bcbd22;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_128\"/>\n    <g id=\"text_54\">\n     <!-- RNNLayer, no dropout, test -->\n     <g transform=\"translate(67.103125 690.941562)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-82\"/>\n      <use x=\"69.482422\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"144.287109\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"219.091797\" xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"274.804688\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"336.083984\" xlink:href=\"#DejaVuSans-121\"/>\n      <use x=\"395.263672\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"456.787109\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"497.900391\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"529.6875\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"561.474609\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"624.853516\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"686.035156\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"717.822266\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"781.298828\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"820.162109\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"881.34375\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"944.820312\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1006.001953\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"1069.380859\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1108.589844\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"1140.376953\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1172.164062\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1211.373047\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"1272.896484\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"1324.996094\" xlink:href=\"#DejaVuSans-116\"/>\n     </g>\n    </g>\n    <g id=\"line2d_129\">\n     <path d=\"M 39.103125 702.119687 \nL 59.103125 702.119687 \n\" style=\"fill:none;stroke:#17becf;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_130\"/>\n    <g id=\"text_55\">\n     <!-- RNNLayer, dropout=0.25, test -->\n     <g transform=\"translate(67.103125 705.619687)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-82\"/>\n      <use x=\"69.482422\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"144.287109\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"219.091797\" xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"274.804688\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"336.083984\" xlink:href=\"#DejaVuSans-121\"/>\n      <use x=\"395.263672\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"456.787109\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"497.900391\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"529.6875\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"561.474609\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"624.951172\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"663.814453\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"724.996094\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"788.472656\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"849.654297\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"913.033203\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"952.242188\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"1036.03125\" xlink:href=\"#DejaVuSans-48\"/>\n      <use x=\"1099.654297\" xlink:href=\"#DejaVuSans-46\"/>\n      <use x=\"1131.441406\" xlink:href=\"#DejaVuSans-50\"/>\n      <use x=\"1195.064453\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1258.6875\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"1290.474609\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1322.261719\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1361.470703\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"1422.994141\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"1475.09375\" xlink:href=\"#DejaVuSans-116\"/>\n     </g>\n    </g>\n    <g id=\"line2d_131\">\n     <path d=\"M 39.103125 716.797812 \nL 59.103125 716.797812 \n\" style=\"fill:none;stroke:#1f77b4;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_132\"/>\n    <g id=\"text_56\">\n     <!-- FastRNNLayer, no dropout, test -->\n     <g transform=\"translate(67.103125 720.297812)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-70\"/>\n      <use x=\"48.394531\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"109.673828\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"161.773438\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"200.982422\" xlink:href=\"#DejaVuSans-82\"/>\n      <use x=\"270.464844\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"345.269531\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"420.074219\" xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"475.787109\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"537.066406\" xlink:href=\"#DejaVuSans-121\"/>\n      <use x=\"596.246094\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"657.769531\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"698.882812\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"730.669922\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"762.457031\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"825.835938\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"887.017578\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"918.804688\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"982.28125\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"1021.144531\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1082.326172\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"1145.802734\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1206.984375\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"1270.363281\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1309.572266\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"1341.359375\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1373.146484\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1412.355469\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"1473.878906\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"1525.978516\" xlink:href=\"#DejaVuSans-116\"/>\n     </g>\n    </g>\n    <g id=\"line2d_133\">\n     <path d=\"M 39.103125 731.475937 \nL 59.103125 731.475937 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_134\"/>\n    <g id=\"text_57\">\n     <!-- FastRNNLayer, dropout=0.25, test -->\n     <g transform=\"translate(67.103125 734.975937)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-70\"/>\n      <use x=\"48.394531\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"109.673828\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"161.773438\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"200.982422\" xlink:href=\"#DejaVuSans-82\"/>\n      <use x=\"270.464844\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"345.269531\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"420.074219\" xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"475.787109\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"537.066406\" xlink:href=\"#DejaVuSans-121\"/>\n      <use x=\"596.246094\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"657.769531\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"698.882812\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"730.669922\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"762.457031\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"825.933594\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"864.796875\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"925.978516\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"989.455078\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1050.636719\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"1114.015625\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1153.224609\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"1237.013672\" xlink:href=\"#DejaVuSans-48\"/>\n      <use x=\"1300.636719\" xlink:href=\"#DejaVuSans-46\"/>\n      <use x=\"1332.423828\" xlink:href=\"#DejaVuSans-50\"/>\n      <use x=\"1396.046875\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1459.669922\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"1491.457031\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1523.244141\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1562.453125\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"1623.976562\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"1676.076172\" xlink:href=\"#DejaVuSans-116\"/>\n     </g>\n    </g>\n    <g id=\"line2d_135\">\n     <path d=\"M 39.103125 746.154062 \nL 59.103125 746.154062 \n\" style=\"fill:none;stroke:#2ca02c;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_136\"/>\n    <g id=\"text_58\">\n     <!-- HandmadeLSTM, no dropout, test -->\n     <g transform=\"translate(67.103125 749.654062)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-72\"/>\n      <use x=\"75.195312\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"136.474609\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"199.853516\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"263.330078\" xlink:href=\"#DejaVuSans-109\"/>\n      <use x=\"360.742188\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"422.021484\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"485.498047\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"547.021484\" xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"602.734375\" xlink:href=\"#DejaVuSans-83\"/>\n      <use x=\"666.210938\" xlink:href=\"#DejaVuSans-84\"/>\n      <use x=\"727.294922\" xlink:href=\"#DejaVuSans-77\"/>\n      <use x=\"813.574219\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"845.361328\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"877.148438\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"940.527344\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1001.708984\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1033.496094\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"1096.972656\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"1135.835938\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1197.017578\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"1260.494141\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1321.675781\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"1385.054688\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1424.263672\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"1456.050781\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1487.837891\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1527.046875\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"1588.570312\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"1640.669922\" xlink:href=\"#DejaVuSans-116\"/>\n     </g>\n    </g>\n    <g id=\"line2d_137\">\n     <path d=\"M 39.103125 760.832187 \nL 59.103125 760.832187 \n\" style=\"fill:none;stroke:#d62728;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_138\"/>\n    <g id=\"text_59\">\n     <!-- HandmadeLSTM, dropout=0.25, test -->\n     <g transform=\"translate(67.103125 764.332187)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-72\"/>\n      <use x=\"75.195312\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"136.474609\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"199.853516\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"263.330078\" xlink:href=\"#DejaVuSans-109\"/>\n      <use x=\"360.742188\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"422.021484\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"485.498047\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"547.021484\" xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"602.734375\" xlink:href=\"#DejaVuSans-83\"/>\n      <use x=\"666.210938\" xlink:href=\"#DejaVuSans-84\"/>\n      <use x=\"727.294922\" xlink:href=\"#DejaVuSans-77\"/>\n      <use x=\"813.574219\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"845.361328\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"877.148438\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"940.625\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"979.488281\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1040.669922\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"1104.146484\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1165.328125\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"1228.707031\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1267.916016\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"1351.705078\" xlink:href=\"#DejaVuSans-48\"/>\n      <use x=\"1415.328125\" xlink:href=\"#DejaVuSans-46\"/>\n      <use x=\"1447.115234\" xlink:href=\"#DejaVuSans-50\"/>\n      <use x=\"1510.738281\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1574.361328\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"1606.148438\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1637.935547\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1677.144531\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"1738.667969\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"1790.767578\" xlink:href=\"#DejaVuSans-116\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p689111ef42\">\n   <rect height=\"476.8\" width=\"1035.4\" x=\"30.103125\" y=\"22.318125\"/>\n  </clipPath>\n  <clipPath id=\"p15e0205169\">\n   <rect height=\"476.8\" width=\"1035.4\" x=\"30.103125\" y=\"556.918125\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "application/pdf": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сделайте итоговые выводы о качестве работы моделей с разными реализациями DropOut:"
      ],
      "metadata": {
        "id": "pmuyqcw4WdQt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ответ:**\n",
        "\n",
        "С ростом числа эпох потери на обучении падают, на тесте увеличиваются, точность на обучении возрастает, на тесте в целом также возрастает, но наблюдаются падения точности на последних эпохах в некоторых случаях. На трейне применение dropout дает качество ниже, чем при его отсутствии, есть и небольшое падение качества на последних эпохах для FastRNN и HandmadeLSTM. На тесте ситуация обратная, использование dropout дает лучшее качество, чем модели без него, и без снижения качества на финальных эпохах. Без dropout на тесте качество почти все время ниже, чем с ним, и оно начинает падать на примерно 10 эпохе. Если сравнивать реализации, то их результаты в целом близки, визуально лучшее качество на тесте - у FastRNN с dropout=0.25, наименьшие потери на тесте - также у данной реализации и у модели с RNNLayer с dropout=0.25. В целом можно сказать, что применение dropout эффективно вне зависимости от конкретной реализации, позволяет бороться с переобучением и падением качества на финальных эпохах. Однако все же получаемая в итоге точность достаточно низкая."
      ],
      "metadata": {
        "id": "u32VMd4jWdQu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Бонус. Zoneout (2 балла)"
      ],
      "metadata": {
        "id": "Glue0EtxWdQv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Это еще одна модификация идеи дропаута применительно к рекуррентным нейросетям. В Zoneout на каждом временном шаге с вероятностью p компонента скрытого состояния обновляется, а с вероятностью 1-p берется с предыдущего шага. \n",
        "В Виде формул (m^t_h - бинарная маска):\n",
        " \n",
        "(сначала обычный рекуррентный переход, например LSTM)\n",
        "$$\n",
        "i = \\sigma(h_{t-1}W^i + x_t U^i+b_i) \\quad\n",
        "o = \\sigma(h_{t-1}W^o + x_t U^o+b_o) \n",
        "$$\n",
        "$$\n",
        "f = \\sigma(h_{t-1}W^f + x_t U^f+b_f) \\quad \n",
        "g = tanh(h_{t-1} W^g + x_t U^g+b_g) \n",
        "$$\n",
        "$$\n",
        "c_t = f \\odot c_{t-1} +  i \\odot  g \\quad\n",
        "h_t =  o \\odot tanh(c_t)\n",
        "$$\n",
        "Затем Zoneout:\n",
        "$$\n",
        "h_t = h_t * m_h^t + h_{t-1}*(1-m_h^t)\n",
        "$$\n",
        "В этом методе маска уже должна быть разная во все моменты времени (иначе метод упрощается до дропаута Гала и Гарамани). На входы $x_t$ вновь можно накладывать маску до начала работы рекуррентного слоя.  \n",
        "\n",
        "Если у вас осталось время, вы можете реализовать этот метод. Выберите основу из трех рассмотренных случаев самостоятельно."
      ],
      "metadata": {
        "id": "EKGeUhGsWdQw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для простоты можно реализовать метод на базе RNNLayer."
      ],
      "metadata": {
        "id": "6Mmu65EYN-ZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNLayerZO(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout=None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dropout = dropout\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        \n",
        "        self.rnn_cell = torch.nn.LSTMCell(self.input_size, self.hidden_size)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Initialize h_0, c_0\n",
        "        # YOUR CODE HERE\n",
        "        batch_size = x.size(1)\n",
        "        # Size: (x.size(1), self.hidden_size) for both\n",
        "        h, c = init_h0_c0(batch_size, self.hidden_size, x)\n",
        "        \n",
        "        # Gen masks for input and hidden state\n",
        "        # YOUR CODE HERE\n",
        "        if self.dropout is not None:\n",
        "            # Т. к. наследуемся от torch.nn.Module\n",
        "            # Size: m_x: (self.input_size,), m_h: (self.hidden_size,)\n",
        "            m_x, m_h = gen_dropout_mask(self.input_size, self.hidden_size, self.training, self.dropout, x)\n",
        "            x = m_x * x\n",
        "\n",
        "        # Implement recurrent logic and return what nn.LSTM returns\n",
        "        # Do not forget to apply generated dropout masks!\n",
        "        # YOUR CODE HERE\n",
        "        res = []\n",
        "        # Size: x: (x.size(0), x.size(1), x.size(2)) = (num_batches, batch_size, input_size) (т. к. используем разбиение данных на батчи)\n",
        "        # Size: batch: (x.size(1), x.size(2))\n",
        "        for batch in x:\n",
        "            # Size: (x.size(1), self.hidden_size) for both\n",
        "            h_next, c = self.rnn_cell(batch, (h, c))\n",
        "            if self.dropout is not None:\n",
        "                h = h_next * m_h + h * (1 - m_h)\n",
        "            else:\n",
        "                h = h_next\n",
        "            res.append(h)\n",
        "        res = torch.stack(res)\n",
        "        return res, (h, c)        "
      ],
      "metadata": {
        "id": "bvLHGSbRN9Wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Рассмотрим версии без dropout и с dropout=0.25, сравним результаты."
      ],
      "metadata": {
        "id": "OXJp3gjpPsar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "model = RNNClassifier(embedding_dim=embedding_dim, hidden_dim=hidden_dim, output_size=10, vocab=vocab, rec_layer=RNNLayerZO, dropout=None).to(device)\n",
        "loss_fn = torch.nn.CrossEntropyLoss(reduction='mean')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "start_z = time.time()\n",
        "\n",
        "train_losses_pure_z, train_accuracies_pure_z, test_losses_pure_z, test_accuracies_pure_z = train(\n",
        "    train_dataloader, test_dataloader, model, loss_fn, optimizer, device, num_epochs\n",
        ")\n",
        "\n",
        "training_time_z = time.time() - start_z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IP7lR-tPlkT",
        "outputId": "3026692d-2cb7-4ad7-9aa6-a584aeb28f71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/15. Loss (Train/Test): 1.986/1.992. Accuracy (Train/Test): 0.249/0.252\n",
            "Epoch: 2/15. Loss (Train/Test): 1.761/1.793. Accuracy (Train/Test): 0.335/0.326\n",
            "Epoch: 3/15. Loss (Train/Test): 1.618/1.658. Accuracy (Train/Test): 0.377/0.361\n",
            "Epoch: 4/15. Loss (Train/Test): 1.521/1.590. Accuracy (Train/Test): 0.401/0.384\n",
            "Epoch: 5/15. Loss (Train/Test): 1.493/1.593. Accuracy (Train/Test): 0.415/0.380\n",
            "Epoch: 6/15. Loss (Train/Test): 1.393/1.550. Accuracy (Train/Test): 0.452/0.392\n",
            "Epoch: 7/15. Loss (Train/Test): 1.346/1.543. Accuracy (Train/Test): 0.471/0.394\n",
            "Epoch: 8/15. Loss (Train/Test): 1.286/1.551. Accuracy (Train/Test): 0.499/0.392\n",
            "Epoch: 9/15. Loss (Train/Test): 1.229/1.572. Accuracy (Train/Test): 0.522/0.393\n",
            "Epoch: 10/15. Loss (Train/Test): 1.172/1.596. Accuracy (Train/Test): 0.543/0.392\n",
            "Epoch: 11/15. Loss (Train/Test): 1.110/1.665. Accuracy (Train/Test): 0.567/0.391\n",
            "Epoch: 12/15. Loss (Train/Test): 1.024/1.688. Accuracy (Train/Test): 0.611/0.385\n",
            "Epoch: 13/15. Loss (Train/Test): 0.971/1.783. Accuracy (Train/Test): 0.635/0.365\n",
            "Epoch: 14/15. Loss (Train/Test): 0.863/1.843. Accuracy (Train/Test): 0.683/0.377\n",
            "Epoch: 15/15. Loss (Train/Test): 0.779/1.958. Accuracy (Train/Test): 0.721/0.365\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "model = RNNClassifier(embedding_dim=embedding_dim, hidden_dim=hidden_dim, output_size=10, vocab=vocab, rec_layer=RNNLayerZO, dropout=0.25).to(device)\n",
        "loss_fn = torch.nn.CrossEntropyLoss(reduction='mean')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "start_z1 = time.time()\n",
        "\n",
        "train_losses_pure_z1, train_accuracies_pure_z1, test_losses_pure_z1, test_accuracies_pure_z1 = train(\n",
        "    train_dataloader, test_dataloader, model, loss_fn, optimizer, device, num_epochs\n",
        ")\n",
        "\n",
        "training_time_z1 = time.time() - start_z1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ytnTyo9Qgu8",
        "outputId": "d05e46d1-b005-47f9-8fa1-ede4ef5f1a4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/15. Loss (Train/Test): 2.024/2.023. Accuracy (Train/Test): 0.235/0.237\n",
            "Epoch: 2/15. Loss (Train/Test): 2.051/2.053. Accuracy (Train/Test): 0.245/0.253\n",
            "Epoch: 3/15. Loss (Train/Test): 1.892/1.915. Accuracy (Train/Test): 0.324/0.329\n",
            "Epoch: 4/15. Loss (Train/Test): 1.664/1.701. Accuracy (Train/Test): 0.360/0.354\n",
            "Epoch: 5/15. Loss (Train/Test): 1.601/1.656. Accuracy (Train/Test): 0.373/0.359\n",
            "Epoch: 6/15. Loss (Train/Test): 1.558/1.632. Accuracy (Train/Test): 0.395/0.377\n",
            "Epoch: 7/15. Loss (Train/Test): 1.536/1.629. Accuracy (Train/Test): 0.393/0.366\n",
            "Epoch: 8/15. Loss (Train/Test): 1.489/1.596. Accuracy (Train/Test): 0.416/0.383\n",
            "Epoch: 9/15. Loss (Train/Test): 1.496/1.622. Accuracy (Train/Test): 0.423/0.393\n",
            "Epoch: 10/15. Loss (Train/Test): 1.440/1.570. Accuracy (Train/Test): 0.436/0.398\n",
            "Epoch: 11/15. Loss (Train/Test): 1.436/1.590. Accuracy (Train/Test): 0.440/0.394\n",
            "Epoch: 12/15. Loss (Train/Test): 1.406/1.577. Accuracy (Train/Test): 0.450/0.403\n",
            "Epoch: 13/15. Loss (Train/Test): 1.426/1.607. Accuracy (Train/Test): 0.446/0.400\n",
            "Epoch: 14/15. Loss (Train/Test): 1.353/1.555. Accuracy (Train/Test): 0.467/0.413\n",
            "Epoch: 15/15. Loss (Train/Test): 1.353/1.581. Accuracy (Train/Test): 0.469/0.409\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Training time, RNNLayer with ZoneOut, no dropout: {training_time_z}')\n",
        "print(f'Training time, RNNLayer with ZoneOut, dropout=0.25: {training_time_z1}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hhJTC4wQwUw",
        "outputId": "0055564a-80e1-4aa7-8758-2e0efd770527"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time, RNNLayer with ZoneOut, no dropout: 556.783346414566\n",
            "Training time, RNNLayer with ZoneOut, dropout=0.25: 757.6040179729462\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(2, 1, figsize=(15, 15))\n",
        "\n",
        "# YOUR CODE HERE\n",
        "epoch_nums = np.arange(num_epochs) + 1\n",
        "\n",
        "axes[0].plot(epoch_nums, train_losses_pure_z, label='RNNLayer with ZoneOut, no dropout, train')\n",
        "axes[0].plot(epoch_nums, train_losses_pure_z1, label='RNNLayer with ZoneOut, dropout=0.25, train')\n",
        "\n",
        "axes[0].plot(epoch_nums, test_losses_pure_z, label='RNNLayer with ZoneOut, no dropout, test', linestyle='dashed')\n",
        "axes[0].plot(epoch_nums, test_losses_pure_z1, label='RNNLayer with ZoneOut, dropout=0.25, test', linestyle='dashed')\n",
        "\n",
        "\n",
        "axes[0].legend()\n",
        "axes[0].grid(True)\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_title('CrossEntropy Loss')\n",
        "\n",
        "axes[1].plot(epoch_nums, train_accuracies_pure_z, label='RNNLayer with ZoneOut, no dropout, train')\n",
        "axes[1].plot(epoch_nums, train_accuracies_pure_z1, label='RNNLayer with ZoneOut, dropout=0.25, train')\n",
        "\n",
        "axes[1].plot(epoch_nums, test_accuracies_pure_z, label='RNNLayer with ZoneOut, no dropout, test', linestyle='dashed')\n",
        "axes[1].plot(epoch_nums, test_accuracies_pure_z1, label='RNNLayer with ZoneOut, dropout=0.25, test', linestyle='dashed')\n",
        "\n",
        "\n",
        "\n",
        "axes[1].legend()\n",
        "axes[1].grid(True)\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_title('Accuracy')\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FTJ-khw4RGWN",
        "outputId": "bb2f3263-b805-41dc-9089-46c0f56ff585"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x1080 with 2 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"1071.274375pt\" version=\"1.1\" viewBox=\"0 0 1072.703125 1071.274375\" width=\"1072.703125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 1071.274375 \nL 1072.703125 1071.274375 \nL 1072.703125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 499.118125 \nL 1065.503125 499.118125 \nL 1065.503125 22.318125 \nL 30.103125 22.318125 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path clip-path=\"url(#pec7bf9b7dd)\" d=\"M 144.400528 499.118125 \nL 144.400528 22.318125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m977f8bf087\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"144.400528\" xlink:href=\"#m977f8bf087\" y=\"499.118125\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 2 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(141.219278 513.716563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path clip-path=\"url(#pec7bf9b7dd)\" d=\"M 278.86806 499.118125 \nL 278.86806 22.318125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"278.86806\" xlink:href=\"#m977f8bf087\" y=\"499.118125\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 4 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(275.68681 513.716563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path clip-path=\"url(#pec7bf9b7dd)\" d=\"M 413.335593 499.118125 \nL 413.335593 22.318125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"413.335593\" xlink:href=\"#m977f8bf087\" y=\"499.118125\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 6 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(410.154343 513.716563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path clip-path=\"url(#pec7bf9b7dd)\" d=\"M 547.803125 499.118125 \nL 547.803125 22.318125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"547.803125\" xlink:href=\"#m977f8bf087\" y=\"499.118125\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 8 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g transform=\"translate(544.621875 513.716563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path clip-path=\"url(#pec7bf9b7dd)\" d=\"M 682.270657 499.118125 \nL 682.270657 22.318125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"682.270657\" xlink:href=\"#m977f8bf087\" y=\"499.118125\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 10 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(675.908157 513.716563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_11\">\n      <path clip-path=\"url(#pec7bf9b7dd)\" d=\"M 816.73819 499.118125 \nL 816.73819 22.318125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"816.73819\" xlink:href=\"#m977f8bf087\" y=\"499.118125\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 12 -->\n      <g transform=\"translate(810.37569 513.716563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_13\">\n      <path clip-path=\"url(#pec7bf9b7dd)\" d=\"M 951.205722 499.118125 \nL 951.205722 22.318125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"951.205722\" xlink:href=\"#m977f8bf087\" y=\"499.118125\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 14 -->\n      <g transform=\"translate(944.843222 513.716563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_8\">\n     <!-- Epoch -->\n     <defs>\n      <path d=\"M 9.8125 72.90625 \nL 55.90625 72.90625 \nL 55.90625 64.59375 \nL 19.671875 64.59375 \nL 19.671875 43.015625 \nL 54.390625 43.015625 \nL 54.390625 34.71875 \nL 19.671875 34.71875 \nL 19.671875 8.296875 \nL 56.78125 8.296875 \nL 56.78125 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-69\"/>\n      <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n      <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n      <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 75.984375 \nL 18.109375 75.984375 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-104\"/>\n     </defs>\n     <g transform=\"translate(532.492187 527.394688)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"63.183594\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"126.660156\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"187.841797\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"242.822266\" xlink:href=\"#DejaVuSans-104\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_15\">\n      <path clip-path=\"url(#pec7bf9b7dd)\" d=\"M 30.103125 470.194174 \nL 1065.503125 470.194174 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_16\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m02769dda55\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m02769dda55\" y=\"470.194174\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.8 -->\n      <defs>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n      </defs>\n      <g transform=\"translate(7.2 473.993393)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_17\">\n      <path clip-path=\"url(#pec7bf9b7dd)\" d=\"M 30.103125 402.149015 \nL 1065.503125 402.149015 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_18\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m02769dda55\" y=\"402.149015\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 1.0 -->\n      <g transform=\"translate(7.2 405.948234)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_19\">\n      <path clip-path=\"url(#pec7bf9b7dd)\" d=\"M 30.103125 334.103856 \nL 1065.503125 334.103856 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_20\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m02769dda55\" y=\"334.103856\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 1.2 -->\n      <g transform=\"translate(7.2 337.903075)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_21\">\n      <path clip-path=\"url(#pec7bf9b7dd)\" d=\"M 30.103125 266.058697 \nL 1065.503125 266.058697 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_22\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m02769dda55\" y=\"266.058697\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 1.4 -->\n      <g transform=\"translate(7.2 269.857916)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_23\">\n      <path clip-path=\"url(#pec7bf9b7dd)\" d=\"M 30.103125 198.013538 \nL 1065.503125 198.013538 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_24\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m02769dda55\" y=\"198.013538\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 1.6 -->\n      <g transform=\"translate(7.2 201.812756)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_25\">\n      <path clip-path=\"url(#pec7bf9b7dd)\" d=\"M 30.103125 129.968379 \nL 1065.503125 129.968379 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_26\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m02769dda55\" y=\"129.968379\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 1.8 -->\n      <g transform=\"translate(7.2 133.767597)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_27\">\n      <path clip-path=\"url(#pec7bf9b7dd)\" d=\"M 30.103125 61.923219 \nL 1065.503125 61.923219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_28\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m02769dda55\" y=\"61.923219\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 2.0 -->\n      <g transform=\"translate(7.2 65.722438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_29\">\n    <path clip-path=\"url(#pec7bf9b7dd)\" d=\"M 77.166761 66.747484 \nL 144.400528 143.165396 \nL 211.634294 191.961473 \nL 278.86806 224.798386 \nL 346.101826 234.430731 \nL 413.335593 268.325484 \nL 480.569359 284.340034 \nL 547.803125 304.721897 \nL 615.036891 324.33381 \nL 682.270657 343.697945 \nL 749.504424 364.628304 \nL 816.73819 393.992726 \nL 883.971956 411.91162 \nL 951.205722 448.752866 \nL 1018.439489 477.445398 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_30\">\n    <path clip-path=\"url(#pec7bf9b7dd)\" d=\"M 77.166761 53.874036 \nL 144.400528 44.64854 \nL 211.634294 98.676447 \nL 278.86806 176.387811 \nL 346.101826 197.797237 \nL 413.335593 212.247281 \nL 480.569359 219.701092 \nL 547.803125 235.703958 \nL 615.036891 233.469756 \nL 682.270657 252.445647 \nL 749.504424 253.800089 \nL 816.73819 264.043189 \nL 883.971956 257.189803 \nL 951.205722 282.049208 \nL 1018.439489 282.13652 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_31\">\n    <path clip-path=\"url(#pec7bf9b7dd)\" d=\"M 77.166761 64.702861 \nL 144.400528 132.225614 \nL 211.634294 178.194272 \nL 278.86806 201.438383 \nL 346.101826 200.477674 \nL 413.335593 215.186699 \nL 480.569359 217.536389 \nL 547.803125 214.719007 \nL 615.036891 207.687011 \nL 682.270657 199.369556 \nL 749.504424 175.802725 \nL 816.73819 168.175535 \nL 883.971956 135.691681 \nL 951.205722 115.341827 \nL 1018.439489 76.116714 \n\" style=\"fill:none;stroke:#2ca02c;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_32\">\n    <path clip-path=\"url(#pec7bf9b7dd)\" d=\"M 77.166761 54.172435 \nL 144.400528 43.990852 \nL 211.634294 90.980495 \nL 278.86806 163.574715 \nL 346.101826 179.13047 \nL 413.335593 187.24466 \nL 480.569359 188.28213 \nL 547.803125 199.460458 \nL 615.036891 190.676981 \nL 682.270657 208.212911 \nL 749.504424 201.283342 \nL 816.73819 205.818031 \nL 883.971956 195.626283 \nL 951.205722 213.33333 \nL 1018.439489 204.378436 \n\" style=\"fill:none;stroke:#d62728;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 499.118125 \nL 30.103125 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 1065.503125 499.118125 \nL 1065.503125 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 499.118125 \nL 1065.503125 499.118125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 22.318125 \nL 1065.503125 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_16\">\n    <!-- CrossEntropy Loss -->\n    <defs>\n     <path d=\"M 64.40625 67.28125 \nL 64.40625 56.890625 \nQ 59.421875 61.53125 53.78125 63.8125 \nQ 48.140625 66.109375 41.796875 66.109375 \nQ 29.296875 66.109375 22.65625 58.46875 \nQ 16.015625 50.828125 16.015625 36.375 \nQ 16.015625 21.96875 22.65625 14.328125 \nQ 29.296875 6.6875 41.796875 6.6875 \nQ 48.140625 6.6875 53.78125 8.984375 \nQ 59.421875 11.28125 64.40625 15.921875 \nL 64.40625 5.609375 \nQ 59.234375 2.09375 53.4375 0.328125 \nQ 47.65625 -1.421875 41.21875 -1.421875 \nQ 24.65625 -1.421875 15.125 8.703125 \nQ 5.609375 18.84375 5.609375 36.375 \nQ 5.609375 53.953125 15.125 64.078125 \nQ 24.65625 74.21875 41.21875 74.21875 \nQ 47.75 74.21875 53.53125 72.484375 \nQ 59.328125 70.75 64.40625 67.28125 \nz\n\" id=\"DejaVuSans-67\"/>\n     <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n     <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n     <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n     <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n     <path d=\"M 32.171875 -5.078125 \nQ 28.375 -14.84375 24.75 -17.8125 \nQ 21.140625 -20.796875 15.09375 -20.796875 \nL 7.90625 -20.796875 \nL 7.90625 -13.28125 \nL 13.1875 -13.28125 \nQ 16.890625 -13.28125 18.9375 -11.515625 \nQ 21 -9.765625 23.484375 -3.21875 \nL 25.09375 0.875 \nL 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 11.921875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nz\n\" id=\"DejaVuSans-121\"/>\n     <path id=\"DejaVuSans-32\"/>\n     <path d=\"M 9.8125 72.90625 \nL 19.671875 72.90625 \nL 19.671875 8.296875 \nL 55.171875 8.296875 \nL 55.171875 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-76\"/>\n    </defs>\n    <g transform=\"translate(492.982812 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-67\"/>\n     <use x=\"69.824219\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"108.6875\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"169.869141\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"221.96875\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"274.068359\" xlink:href=\"#DejaVuSans-69\"/>\n     <use x=\"337.251953\" xlink:href=\"#DejaVuSans-110\"/>\n     <use x=\"400.630859\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"439.839844\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"478.703125\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"539.884766\" xlink:href=\"#DejaVuSans-112\"/>\n     <use x=\"603.361328\" xlink:href=\"#DejaVuSans-121\"/>\n     <use x=\"662.541016\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"694.328125\" xlink:href=\"#DejaVuSans-76\"/>\n     <use x=\"748.291016\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"809.472656\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"861.572266\" xlink:href=\"#DejaVuSans-115\"/>\n    </g>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 37.103125 494.118125 \nL 295.767187 494.118125 \nQ 297.767187 494.118125 297.767187 492.118125 \nL 297.767187 434.405625 \nQ 297.767187 432.405625 295.767187 432.405625 \nL 37.103125 432.405625 \nQ 35.103125 432.405625 35.103125 434.405625 \nL 35.103125 492.118125 \nQ 35.103125 494.118125 37.103125 494.118125 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_33\">\n     <path d=\"M 39.103125 440.504062 \nL 59.103125 440.504062 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_34\"/>\n    <g id=\"text_17\">\n     <!-- RNNLayer with ZoneOut, no dropout, train -->\n     <defs>\n      <path d=\"M 44.390625 34.1875 \nQ 47.5625 33.109375 50.5625 29.59375 \nQ 53.5625 26.078125 56.59375 19.921875 \nL 66.609375 0 \nL 56 0 \nL 46.6875 18.703125 \nQ 43.0625 26.03125 39.671875 28.421875 \nQ 36.28125 30.8125 30.421875 30.8125 \nL 19.671875 30.8125 \nL 19.671875 0 \nL 9.8125 0 \nL 9.8125 72.90625 \nL 32.078125 72.90625 \nQ 44.578125 72.90625 50.734375 67.671875 \nQ 56.890625 62.453125 56.890625 51.90625 \nQ 56.890625 45.015625 53.6875 40.46875 \nQ 50.484375 35.9375 44.390625 34.1875 \nz\nM 19.671875 64.796875 \nL 19.671875 38.921875 \nL 32.078125 38.921875 \nQ 39.203125 38.921875 42.84375 42.21875 \nQ 46.484375 45.515625 46.484375 51.90625 \nQ 46.484375 58.296875 42.84375 61.546875 \nQ 39.203125 64.796875 32.078125 64.796875 \nz\n\" id=\"DejaVuSans-82\"/>\n      <path d=\"M 9.8125 72.90625 \nL 23.09375 72.90625 \nL 55.421875 11.921875 \nL 55.421875 72.90625 \nL 64.984375 72.90625 \nL 64.984375 0 \nL 51.703125 0 \nL 19.390625 60.984375 \nL 19.390625 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-78\"/>\n      <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n      <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n      <path d=\"M 4.203125 54.6875 \nL 13.1875 54.6875 \nL 24.421875 12.015625 \nL 35.59375 54.6875 \nL 46.1875 54.6875 \nL 57.421875 12.015625 \nL 68.609375 54.6875 \nL 77.59375 54.6875 \nL 63.28125 0 \nL 52.6875 0 \nL 40.921875 44.828125 \nL 29.109375 0 \nL 18.5 0 \nz\n\" id=\"DejaVuSans-119\"/>\n      <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n      <path d=\"M 5.609375 72.90625 \nL 62.890625 72.90625 \nL 62.890625 65.375 \nL 16.796875 8.296875 \nL 64.015625 8.296875 \nL 64.015625 0 \nL 4.5 0 \nL 4.5 7.515625 \nL 50.59375 64.59375 \nL 5.609375 64.59375 \nz\n\" id=\"DejaVuSans-90\"/>\n      <path d=\"M 39.40625 66.21875 \nQ 28.65625 66.21875 22.328125 58.203125 \nQ 16.015625 50.203125 16.015625 36.375 \nQ 16.015625 22.609375 22.328125 14.59375 \nQ 28.65625 6.59375 39.40625 6.59375 \nQ 50.140625 6.59375 56.421875 14.59375 \nQ 62.703125 22.609375 62.703125 36.375 \nQ 62.703125 50.203125 56.421875 58.203125 \nQ 50.140625 66.21875 39.40625 66.21875 \nz\nM 39.40625 74.21875 \nQ 54.734375 74.21875 63.90625 63.9375 \nQ 73.09375 53.65625 73.09375 36.375 \nQ 73.09375 19.140625 63.90625 8.859375 \nQ 54.734375 -1.421875 39.40625 -1.421875 \nQ 24.03125 -1.421875 14.8125 8.828125 \nQ 5.609375 19.09375 5.609375 36.375 \nQ 5.609375 53.65625 14.8125 63.9375 \nQ 24.03125 74.21875 39.40625 74.21875 \nz\n\" id=\"DejaVuSans-79\"/>\n      <path d=\"M 8.5 21.578125 \nL 8.5 54.6875 \nL 17.484375 54.6875 \nL 17.484375 21.921875 \nQ 17.484375 14.15625 20.5 10.265625 \nQ 23.53125 6.390625 29.59375 6.390625 \nQ 36.859375 6.390625 41.078125 11.03125 \nQ 45.3125 15.671875 45.3125 23.6875 \nL 45.3125 54.6875 \nL 54.296875 54.6875 \nL 54.296875 0 \nL 45.3125 0 \nL 45.3125 8.40625 \nQ 42.046875 3.421875 37.71875 1 \nQ 33.40625 -1.421875 27.6875 -1.421875 \nQ 18.265625 -1.421875 13.375 4.4375 \nQ 8.5 10.296875 8.5 21.578125 \nz\nM 31.109375 56 \nz\n\" id=\"DejaVuSans-117\"/>\n      <path d=\"M 11.71875 12.40625 \nL 22.015625 12.40625 \nL 22.015625 4 \nL 14.015625 -11.625 \nL 7.71875 -11.625 \nL 11.71875 4 \nz\n\" id=\"DejaVuSans-44\"/>\n      <path d=\"M 45.40625 46.390625 \nL 45.40625 75.984375 \nL 54.390625 75.984375 \nL 54.390625 0 \nL 45.40625 0 \nL 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nz\nM 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\n\" id=\"DejaVuSans-100\"/>\n     </defs>\n     <g transform=\"translate(67.103125 444.004062)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-82\"/>\n      <use x=\"69.482422\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"144.287109\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"219.091797\" xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"274.804688\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"336.083984\" xlink:href=\"#DejaVuSans-121\"/>\n      <use x=\"395.263672\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"456.787109\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"497.900391\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"529.6875\" xlink:href=\"#DejaVuSans-119\"/>\n      <use x=\"611.474609\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"639.257812\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"678.466797\" xlink:href=\"#DejaVuSans-104\"/>\n      <use x=\"741.845703\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"773.632812\" xlink:href=\"#DejaVuSans-90\"/>\n      <use x=\"842.138672\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"903.320312\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"966.699219\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"1028.222656\" xlink:href=\"#DejaVuSans-79\"/>\n      <use x=\"1106.933594\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"1170.3125\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1209.521484\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"1241.308594\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1273.095703\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"1336.474609\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1397.65625\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1429.443359\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"1492.919922\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"1531.783203\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1592.964844\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"1656.441406\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1717.623047\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"1781.001953\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1820.210938\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"1851.998047\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1883.785156\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1922.994141\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"1964.107422\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"2025.386719\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"2053.169922\" xlink:href=\"#DejaVuSans-110\"/>\n     </g>\n    </g>\n    <g id=\"line2d_35\">\n     <path d=\"M 39.103125 455.182187 \nL 59.103125 455.182187 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_36\"/>\n    <g id=\"text_18\">\n     <!-- RNNLayer with ZoneOut, dropout=0.25, train -->\n     <defs>\n      <path d=\"M 10.59375 45.40625 \nL 73.1875 45.40625 \nL 73.1875 37.203125 \nL 10.59375 37.203125 \nz\nM 10.59375 25.484375 \nL 73.1875 25.484375 \nL 73.1875 17.1875 \nL 10.59375 17.1875 \nz\n\" id=\"DejaVuSans-61\"/>\n      <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n     </defs>\n     <g transform=\"translate(67.103125 458.682187)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-82\"/>\n      <use x=\"69.482422\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"144.287109\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"219.091797\" xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"274.804688\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"336.083984\" xlink:href=\"#DejaVuSans-121\"/>\n      <use x=\"395.263672\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"456.787109\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"497.900391\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"529.6875\" xlink:href=\"#DejaVuSans-119\"/>\n      <use x=\"611.474609\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"639.257812\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"678.466797\" xlink:href=\"#DejaVuSans-104\"/>\n      <use x=\"741.845703\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"773.632812\" xlink:href=\"#DejaVuSans-90\"/>\n      <use x=\"842.138672\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"903.320312\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"966.699219\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"1028.222656\" xlink:href=\"#DejaVuSans-79\"/>\n      <use x=\"1106.933594\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"1170.3125\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1209.521484\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"1241.308594\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1273.095703\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"1336.572266\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"1375.435547\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1436.617188\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"1500.09375\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1561.275391\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"1624.654297\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1663.863281\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"1747.652344\" xlink:href=\"#DejaVuSans-48\"/>\n      <use x=\"1811.275391\" xlink:href=\"#DejaVuSans-46\"/>\n      <use x=\"1843.0625\" xlink:href=\"#DejaVuSans-50\"/>\n      <use x=\"1906.685547\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1970.308594\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"2002.095703\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"2033.882812\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"2073.091797\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"2114.205078\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"2175.484375\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"2203.267578\" xlink:href=\"#DejaVuSans-110\"/>\n     </g>\n    </g>\n    <g id=\"line2d_37\">\n     <path d=\"M 39.103125 469.860312 \nL 59.103125 469.860312 \n\" style=\"fill:none;stroke:#2ca02c;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_38\"/>\n    <g id=\"text_19\">\n     <!-- RNNLayer with ZoneOut, no dropout, test -->\n     <g transform=\"translate(67.103125 473.360312)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-82\"/>\n      <use x=\"69.482422\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"144.287109\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"219.091797\" xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"274.804688\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"336.083984\" xlink:href=\"#DejaVuSans-121\"/>\n      <use x=\"395.263672\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"456.787109\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"497.900391\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"529.6875\" xlink:href=\"#DejaVuSans-119\"/>\n      <use x=\"611.474609\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"639.257812\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"678.466797\" xlink:href=\"#DejaVuSans-104\"/>\n      <use x=\"741.845703\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"773.632812\" xlink:href=\"#DejaVuSans-90\"/>\n      <use x=\"842.138672\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"903.320312\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"966.699219\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"1028.222656\" xlink:href=\"#DejaVuSans-79\"/>\n      <use x=\"1106.933594\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"1170.3125\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1209.521484\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"1241.308594\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1273.095703\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"1336.474609\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1397.65625\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1429.443359\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"1492.919922\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"1531.783203\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1592.964844\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"1656.441406\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1717.623047\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"1781.001953\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1820.210938\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"1851.998047\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1883.785156\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1922.994141\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"1984.517578\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"2036.617188\" xlink:href=\"#DejaVuSans-116\"/>\n     </g>\n    </g>\n    <g id=\"line2d_39\">\n     <path d=\"M 39.103125 484.538437 \nL 59.103125 484.538437 \n\" style=\"fill:none;stroke:#d62728;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_40\"/>\n    <g id=\"text_20\">\n     <!-- RNNLayer with ZoneOut, dropout=0.25, test -->\n     <g transform=\"translate(67.103125 488.038437)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-82\"/>\n      <use x=\"69.482422\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"144.287109\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"219.091797\" xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"274.804688\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"336.083984\" xlink:href=\"#DejaVuSans-121\"/>\n      <use x=\"395.263672\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"456.787109\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"497.900391\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"529.6875\" xlink:href=\"#DejaVuSans-119\"/>\n      <use x=\"611.474609\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"639.257812\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"678.466797\" xlink:href=\"#DejaVuSans-104\"/>\n      <use x=\"741.845703\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"773.632812\" xlink:href=\"#DejaVuSans-90\"/>\n      <use x=\"842.138672\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"903.320312\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"966.699219\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"1028.222656\" xlink:href=\"#DejaVuSans-79\"/>\n      <use x=\"1106.933594\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"1170.3125\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1209.521484\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"1241.308594\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1273.095703\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"1336.572266\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"1375.435547\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1436.617188\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"1500.09375\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1561.275391\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"1624.654297\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1663.863281\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"1747.652344\" xlink:href=\"#DejaVuSans-48\"/>\n      <use x=\"1811.275391\" xlink:href=\"#DejaVuSans-46\"/>\n      <use x=\"1843.0625\" xlink:href=\"#DejaVuSans-50\"/>\n      <use x=\"1906.685547\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1970.308594\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"2002.095703\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"2033.882812\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"2073.091797\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"2134.615234\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"2186.714844\" xlink:href=\"#DejaVuSans-116\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_2\">\n   <g id=\"patch_8\">\n    <path d=\"M 30.103125 1033.718125 \nL 1065.503125 1033.718125 \nL 1065.503125 556.918125 \nL 30.103125 556.918125 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_3\">\n    <g id=\"xtick_8\">\n     <g id=\"line2d_41\">\n      <path clip-path=\"url(#p4f896fd4f6)\" d=\"M 144.400528 1033.718125 \nL 144.400528 556.918125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_42\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"144.400528\" xlink:href=\"#m977f8bf087\" y=\"1033.718125\"/>\n      </g>\n     </g>\n     <g id=\"text_21\">\n      <!-- 2 -->\n      <g transform=\"translate(141.219278 1048.316562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_43\">\n      <path clip-path=\"url(#p4f896fd4f6)\" d=\"M 278.86806 1033.718125 \nL 278.86806 556.918125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_44\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"278.86806\" xlink:href=\"#m977f8bf087\" y=\"1033.718125\"/>\n      </g>\n     </g>\n     <g id=\"text_22\">\n      <!-- 4 -->\n      <g transform=\"translate(275.68681 1048.316562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_10\">\n     <g id=\"line2d_45\">\n      <path clip-path=\"url(#p4f896fd4f6)\" d=\"M 413.335593 1033.718125 \nL 413.335593 556.918125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_46\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"413.335593\" xlink:href=\"#m977f8bf087\" y=\"1033.718125\"/>\n      </g>\n     </g>\n     <g id=\"text_23\">\n      <!-- 6 -->\n      <g transform=\"translate(410.154343 1048.316562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_11\">\n     <g id=\"line2d_47\">\n      <path clip-path=\"url(#p4f896fd4f6)\" d=\"M 547.803125 1033.718125 \nL 547.803125 556.918125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_48\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"547.803125\" xlink:href=\"#m977f8bf087\" y=\"1033.718125\"/>\n      </g>\n     </g>\n     <g id=\"text_24\">\n      <!-- 8 -->\n      <g transform=\"translate(544.621875 1048.316562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_12\">\n     <g id=\"line2d_49\">\n      <path clip-path=\"url(#p4f896fd4f6)\" d=\"M 682.270657 1033.718125 \nL 682.270657 556.918125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_50\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"682.270657\" xlink:href=\"#m977f8bf087\" y=\"1033.718125\"/>\n      </g>\n     </g>\n     <g id=\"text_25\">\n      <!-- 10 -->\n      <g transform=\"translate(675.908157 1048.316562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_13\">\n     <g id=\"line2d_51\">\n      <path clip-path=\"url(#p4f896fd4f6)\" d=\"M 816.73819 1033.718125 \nL 816.73819 556.918125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_52\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"816.73819\" xlink:href=\"#m977f8bf087\" y=\"1033.718125\"/>\n      </g>\n     </g>\n     <g id=\"text_26\">\n      <!-- 12 -->\n      <g transform=\"translate(810.37569 1048.316562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_14\">\n     <g id=\"line2d_53\">\n      <path clip-path=\"url(#p4f896fd4f6)\" d=\"M 951.205722 1033.718125 \nL 951.205722 556.918125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_54\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"951.205722\" xlink:href=\"#m977f8bf087\" y=\"1033.718125\"/>\n      </g>\n     </g>\n     <g id=\"text_27\">\n      <!-- 14 -->\n      <g transform=\"translate(944.843222 1048.316562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_28\">\n     <!-- Epoch -->\n     <g transform=\"translate(532.492187 1061.994688)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"63.183594\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"126.660156\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"187.841797\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"242.822266\" xlink:href=\"#DejaVuSans-104\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_4\">\n    <g id=\"ytick_8\">\n     <g id=\"line2d_55\">\n      <path clip-path=\"url(#p4f896fd4f6)\" d=\"M 30.103125 953.839868 \nL 1065.503125 953.839868 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_56\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m02769dda55\" y=\"953.839868\"/>\n      </g>\n     </g>\n     <g id=\"text_29\">\n      <!-- 0.3 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(7.2 957.639087)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_9\">\n     <g id=\"line2d_57\">\n      <path clip-path=\"url(#p4f896fd4f6)\" d=\"M 30.103125 864.622318 \nL 1065.503125 864.622318 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_58\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m02769dda55\" y=\"864.622318\"/>\n      </g>\n     </g>\n     <g id=\"text_30\">\n      <!-- 0.4 -->\n      <g transform=\"translate(7.2 868.421537)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_10\">\n     <g id=\"line2d_59\">\n      <path clip-path=\"url(#p4f896fd4f6)\" d=\"M 30.103125 775.404768 \nL 1065.503125 775.404768 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_60\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m02769dda55\" y=\"775.404768\"/>\n      </g>\n     </g>\n     <g id=\"text_31\">\n      <!-- 0.5 -->\n      <g transform=\"translate(7.2 779.203987)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_11\">\n     <g id=\"line2d_61\">\n      <path clip-path=\"url(#p4f896fd4f6)\" d=\"M 30.103125 686.187218 \nL 1065.503125 686.187218 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_62\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m02769dda55\" y=\"686.187218\"/>\n      </g>\n     </g>\n     <g id=\"text_32\">\n      <!-- 0.6 -->\n      <g transform=\"translate(7.2 689.986436)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_12\">\n     <g id=\"line2d_63\">\n      <path clip-path=\"url(#p4f896fd4f6)\" d=\"M 30.103125 596.969668 \nL 1065.503125 596.969668 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_64\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m02769dda55\" y=\"596.969668\"/>\n      </g>\n     </g>\n     <g id=\"text_33\">\n      <!-- 0.7 -->\n      <defs>\n       <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n      </defs>\n      <g transform=\"translate(7.2 600.768886)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_65\">\n    <path clip-path=\"url(#p4f896fd4f6)\" d=\"M 77.166761 999.376506 \nL 144.400528 922.827848 \nL 211.634294 885.32079 \nL 278.86806 863.301898 \nL 346.101826 851.560869 \nL 413.335593 818.193505 \nL 480.569359 800.992361 \nL 547.803125 776.189882 \nL 615.036891 755.919655 \nL 682.270657 736.791412 \nL 749.504424 715.700383 \nL 816.73819 676.408974 \nL 883.971956 654.711266 \nL 951.205722 612.208025 \nL 1018.439489 578.590852 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_66\">\n    <path clip-path=\"url(#p4f896fd4f6)\" d=\"M 77.166761 1012.045398 \nL 144.400528 1002.624024 \nL 211.634294 932.8559 \nL 278.86806 900.130903 \nL 346.101826 888.461247 \nL 413.335593 869.225944 \nL 480.569359 871.117356 \nL 547.803125 850.525945 \nL 615.036891 844.387778 \nL 682.270657 832.825183 \nL 749.504424 828.685489 \nL 816.73819 819.763734 \nL 883.971956 823.332436 \nL 951.205722 805.20343 \nL 1018.439489 802.669651 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_67\">\n    <path clip-path=\"url(#p4f896fd4f6)\" d=\"M 77.166761 996.914101 \nL 144.400528 931.000175 \nL 211.634294 899.774033 \nL 278.86806 879.075561 \nL 346.101826 882.67995 \nL 413.335593 871.581287 \nL 480.569359 870.153806 \nL 547.803125 871.90247 \nL 615.036891 871.153043 \nL 682.270657 871.866783 \nL 749.504424 872.544836 \nL 816.73819 878.183386 \nL 883.971956 896.276705 \nL 951.205722 885.499225 \nL 1018.439489 896.205331 \n\" style=\"fill:none;stroke:#2ca02c;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_68\">\n    <path clip-path=\"url(#p4f896fd4f6)\" d=\"M 77.166761 1010.475169 \nL 144.400528 996.200361 \nL 211.634294 928.002466 \nL 278.86806 905.947887 \nL 346.101826 901.272888 \nL 413.335593 885.427851 \nL 480.569359 894.956285 \nL 547.803125 879.361057 \nL 615.036891 871.010295 \nL 682.270657 866.692165 \nL 749.504424 869.618501 \nL 816.73819 861.910104 \nL 883.971956 864.408196 \nL 951.205722 853.452281 \nL 1018.439489 856.735486 \n\" style=\"fill:none;stroke:#d62728;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path d=\"M 30.103125 1033.718125 \nL 30.103125 556.918125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path d=\"M 1065.503125 1033.718125 \nL 1065.503125 556.918125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path d=\"M 30.103125 1033.718125 \nL 1065.503125 1033.718125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_12\">\n    <path d=\"M 30.103125 556.918125 \nL 1065.503125 556.918125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_34\">\n    <!-- Accuracy -->\n    <defs>\n     <path d=\"M 34.1875 63.1875 \nL 20.796875 26.90625 \nL 47.609375 26.90625 \nz\nM 28.609375 72.90625 \nL 39.796875 72.90625 \nL 67.578125 0 \nL 57.328125 0 \nL 50.6875 18.703125 \nL 17.828125 18.703125 \nL 11.1875 0 \nL 0.78125 0 \nz\n\" id=\"DejaVuSans-65\"/>\n    </defs>\n    <g transform=\"translate(520.409375 550.918125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-65\"/>\n     <use x=\"66.658203\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"121.638672\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"176.619141\" xlink:href=\"#DejaVuSans-117\"/>\n     <use x=\"239.998047\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"281.111328\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"342.390625\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"397.371094\" xlink:href=\"#DejaVuSans-121\"/>\n    </g>\n   </g>\n   <g id=\"legend_2\">\n    <g id=\"patch_13\">\n     <path d=\"M 37.103125 623.630625 \nL 295.767187 623.630625 \nQ 297.767187 623.630625 297.767187 621.630625 \nL 297.767187 563.918125 \nQ 297.767187 561.918125 295.767187 561.918125 \nL 37.103125 561.918125 \nQ 35.103125 561.918125 35.103125 563.918125 \nL 35.103125 621.630625 \nQ 35.103125 623.630625 37.103125 623.630625 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_69\">\n     <path d=\"M 39.103125 570.016562 \nL 59.103125 570.016562 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_70\"/>\n    <g id=\"text_35\">\n     <!-- RNNLayer with ZoneOut, no dropout, train -->\n     <g transform=\"translate(67.103125 573.516562)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-82\"/>\n      <use x=\"69.482422\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"144.287109\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"219.091797\" xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"274.804688\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"336.083984\" xlink:href=\"#DejaVuSans-121\"/>\n      <use x=\"395.263672\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"456.787109\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"497.900391\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"529.6875\" xlink:href=\"#DejaVuSans-119\"/>\n      <use x=\"611.474609\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"639.257812\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"678.466797\" xlink:href=\"#DejaVuSans-104\"/>\n      <use x=\"741.845703\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"773.632812\" xlink:href=\"#DejaVuSans-90\"/>\n      <use x=\"842.138672\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"903.320312\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"966.699219\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"1028.222656\" xlink:href=\"#DejaVuSans-79\"/>\n      <use x=\"1106.933594\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"1170.3125\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1209.521484\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"1241.308594\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1273.095703\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"1336.474609\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1397.65625\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1429.443359\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"1492.919922\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"1531.783203\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1592.964844\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"1656.441406\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1717.623047\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"1781.001953\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1820.210938\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"1851.998047\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1883.785156\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1922.994141\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"1964.107422\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"2025.386719\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"2053.169922\" xlink:href=\"#DejaVuSans-110\"/>\n     </g>\n    </g>\n    <g id=\"line2d_71\">\n     <path d=\"M 39.103125 584.694687 \nL 59.103125 584.694687 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_72\"/>\n    <g id=\"text_36\">\n     <!-- RNNLayer with ZoneOut, dropout=0.25, train -->\n     <g transform=\"translate(67.103125 588.194687)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-82\"/>\n      <use x=\"69.482422\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"144.287109\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"219.091797\" xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"274.804688\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"336.083984\" xlink:href=\"#DejaVuSans-121\"/>\n      <use x=\"395.263672\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"456.787109\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"497.900391\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"529.6875\" xlink:href=\"#DejaVuSans-119\"/>\n      <use x=\"611.474609\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"639.257812\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"678.466797\" xlink:href=\"#DejaVuSans-104\"/>\n      <use x=\"741.845703\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"773.632812\" xlink:href=\"#DejaVuSans-90\"/>\n      <use x=\"842.138672\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"903.320312\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"966.699219\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"1028.222656\" xlink:href=\"#DejaVuSans-79\"/>\n      <use x=\"1106.933594\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"1170.3125\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1209.521484\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"1241.308594\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1273.095703\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"1336.572266\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"1375.435547\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1436.617188\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"1500.09375\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1561.275391\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"1624.654297\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1663.863281\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"1747.652344\" xlink:href=\"#DejaVuSans-48\"/>\n      <use x=\"1811.275391\" xlink:href=\"#DejaVuSans-46\"/>\n      <use x=\"1843.0625\" xlink:href=\"#DejaVuSans-50\"/>\n      <use x=\"1906.685547\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1970.308594\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"2002.095703\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"2033.882812\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"2073.091797\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"2114.205078\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"2175.484375\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"2203.267578\" xlink:href=\"#DejaVuSans-110\"/>\n     </g>\n    </g>\n    <g id=\"line2d_73\">\n     <path d=\"M 39.103125 599.372812 \nL 59.103125 599.372812 \n\" style=\"fill:none;stroke:#2ca02c;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_74\"/>\n    <g id=\"text_37\">\n     <!-- RNNLayer with ZoneOut, no dropout, test -->\n     <g transform=\"translate(67.103125 602.872812)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-82\"/>\n      <use x=\"69.482422\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"144.287109\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"219.091797\" xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"274.804688\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"336.083984\" xlink:href=\"#DejaVuSans-121\"/>\n      <use x=\"395.263672\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"456.787109\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"497.900391\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"529.6875\" xlink:href=\"#DejaVuSans-119\"/>\n      <use x=\"611.474609\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"639.257812\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"678.466797\" xlink:href=\"#DejaVuSans-104\"/>\n      <use x=\"741.845703\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"773.632812\" xlink:href=\"#DejaVuSans-90\"/>\n      <use x=\"842.138672\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"903.320312\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"966.699219\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"1028.222656\" xlink:href=\"#DejaVuSans-79\"/>\n      <use x=\"1106.933594\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"1170.3125\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1209.521484\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"1241.308594\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1273.095703\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"1336.474609\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1397.65625\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1429.443359\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"1492.919922\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"1531.783203\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1592.964844\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"1656.441406\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1717.623047\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"1781.001953\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1820.210938\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"1851.998047\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1883.785156\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1922.994141\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"1984.517578\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"2036.617188\" xlink:href=\"#DejaVuSans-116\"/>\n     </g>\n    </g>\n    <g id=\"line2d_75\">\n     <path d=\"M 39.103125 614.050937 \nL 59.103125 614.050937 \n\" style=\"fill:none;stroke:#d62728;stroke-dasharray:5.55,2.4;stroke-dashoffset:0;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_76\"/>\n    <g id=\"text_38\">\n     <!-- RNNLayer with ZoneOut, dropout=0.25, test -->\n     <g transform=\"translate(67.103125 617.550937)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-82\"/>\n      <use x=\"69.482422\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"144.287109\" xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"219.091797\" xlink:href=\"#DejaVuSans-76\"/>\n      <use x=\"274.804688\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"336.083984\" xlink:href=\"#DejaVuSans-121\"/>\n      <use x=\"395.263672\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"456.787109\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"497.900391\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"529.6875\" xlink:href=\"#DejaVuSans-119\"/>\n      <use x=\"611.474609\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"639.257812\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"678.466797\" xlink:href=\"#DejaVuSans-104\"/>\n      <use x=\"741.845703\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"773.632812\" xlink:href=\"#DejaVuSans-90\"/>\n      <use x=\"842.138672\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"903.320312\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"966.699219\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"1028.222656\" xlink:href=\"#DejaVuSans-79\"/>\n      <use x=\"1106.933594\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"1170.3125\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1209.521484\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"1241.308594\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1273.095703\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"1336.572266\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"1375.435547\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1436.617188\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"1500.09375\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1561.275391\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"1624.654297\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1663.863281\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"1747.652344\" xlink:href=\"#DejaVuSans-48\"/>\n      <use x=\"1811.275391\" xlink:href=\"#DejaVuSans-46\"/>\n      <use x=\"1843.0625\" xlink:href=\"#DejaVuSans-50\"/>\n      <use x=\"1906.685547\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1970.308594\" xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"2002.095703\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"2033.882812\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"2073.091797\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"2134.615234\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"2186.714844\" xlink:href=\"#DejaVuSans-116\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pec7bf9b7dd\">\n   <rect height=\"476.8\" width=\"1035.4\" x=\"30.103125\" y=\"22.318125\"/>\n  </clipPath>\n  <clipPath id=\"p4f896fd4f6\">\n   <rect height=\"476.8\" width=\"1035.4\" x=\"30.103125\" y=\"556.918125\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "application/pdf": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Данная реализация dropout также позволяет бороться с переобучением и падением качества на последних эпохах и ведет к меньшим потерям на тесте. Итоговое качество почти такое же, как и у RNNLayer, время работы возросло."
      ],
      "metadata": {
        "id": "YwVPkMxTQEws"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Часть 2. Language Modeling с помощью LSTM. (3 балла)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-03-31T16:05:00.702763Z",
          "start_time": "2021-03-31T16:05:00.674835Z"
        },
        "id": "MPoPfl6TWdQx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Во второй части мы попробуем обучить модель для генерации отзывов по их началу."
      ],
      "metadata": {
        "id": "ioBhW_e_WdQy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Концептуально модель будет выглядеть следующим образом:\n",
        "    \n",
        "![image info](https://blog.feedly.com/wp-content/uploads/2019/03/Screen-Shot-2019-03-06-at-12.08.35-PM.png)"
      ],
      "metadata": {
        "id": "hzX1Joj7WdQz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В процессе обучения будем тренировать сеть предсказывать вероятность следующего символа при условии всех предыдущих. Эту вероятность можно моделировать с помощью скрытого состояния $h^{(t)}$ пропуская его через линейный слой с выходной размерностью равной размерности словаря:\n",
        "$$\n",
        "p(x^{t}|x^{t-1}, ..., x^{1}) = SoftMax(Linear(h^{(t)}))\n",
        "$$"
      ],
      "metadata": {
        "id": "0Cuw_2yvWdQ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обратите внимание, что для вычисления $p(x^{t}|x^{t-1}, ..., x^{1})$ для всех моментов времени достаточно сделать один проход по RNN, а затем применить линейное преобразование ко всем скрытым состояниям."
      ],
      "metadata": {
        "id": "M3fcDfHeWdQ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В качестве функции потерь необходимо использовать `CrossEntropy`."
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:37:56.10052Z",
          "start_time": "2021-04-02T00:37:56.072747Z"
        },
        "id": "scRGou0vWdQ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Рассмотрим другой важный момент. Для того, чтобы решить данную задачу, модель должна уметь определять момент начала генерации предложения и оповещать о завершении генерации -- конце предложения. Для этого добавим в словарь вспомогательные токены `<sos>`, `<eos>`. Добавив `<sos>` в начало каждого предложения и `<eos>` в конец.\n",
        "\n",
        "Модель сможет начинать генерацию как только ей будет передан токен `<sos>` и заканчивать генерацию, как только на очередном месте самым вероятным токеном оказывается `<eos>`."
      ],
      "metadata": {
        "id": "H9e69bEmWdQ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для решения этой задачи мы воспользуемся уже реализованной LSTM с дропаутом `FastRNNLayer` и классом `RNNClassifier`, то есть архитектура сети принципиально не поменяется. "
      ],
      "metadata": {
        "id": "zeexoBkQWdQ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Реализация модели и цикла обучения (1 балл)"
      ],
      "metadata": {
        "id": "0OEf4e4vWdQ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Не используйте циклы в `RNNLM`, `LMCrossEntropyLoss`, `LMAccuracy`**"
      ],
      "metadata": {
        "id": "3czScfwdWdQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNLM(RNNClassifier):\n",
        "    def __init__(\n",
        "        self, embedding_dim, hidden_dim, vocab, dropout=0.5, layers_dropout=0.5, num_layers=1\n",
        "    ):\n",
        "        super().__init__(\n",
        "            embedding_dim=embedding_dim, hidden_dim=hidden_dim, output_size=len(vocab), vocab=vocab,\n",
        "            rec_layer=FastRNNLayer, dropout=dropout, layers_dropout=layers_dropout, num_layers=num_layers\n",
        "        )\n",
        "    \n",
        "    def forward(self, tokens, tokens_lens):\n",
        "        \"\"\"\n",
        "        :param torch.tensor(dtype=torch.long) tokens: Batch of texts represented with tokens. Shape: [T, B]\n",
        "        :param torch.tensor(dtype=torch.long) tokens_lens: Number of non-padding tokens for each object in batch. Shape: [B]\n",
        "        :return torch.tensor: Distribution of next token for each time step. Shape: [T, B, V], V -- size of vocabulary\n",
        "        \"\"\"\n",
        "        # Make embeddings for all tokens\n",
        "        # YOUR CODE HERE\n",
        "        embeddings = self.word_embeddings(tokens)\n",
        "        \n",
        "        # Forward pass embeddings through network\n",
        "        # YOUR CODE HERE\n",
        "        embeddings = self.rnn(embeddings)[0]\n",
        "        \n",
        "        # Take all hidden states from the last layer of LSTM for each step and perform linear transformation\n",
        "        # YOUR CODE HERE\n",
        "        embeddings = self.output(embeddings)\n",
        "        return embeddings"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T02:07:02.815198Z",
          "start_time": "2021-04-02T02:07:02.787445Z"
        },
        "id": "ImnG0KPgWdQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Реализуем функцию потерь для данной задачи. \n",
        "\n",
        "Моменты на которые нужно обратить внимание:\n",
        "1. Распределение вероятности следующего токена для последнего токена в последовательности не участвует в подсчёте функции потерь.\n",
        "2. Необходимо учитывать, что в одном батче могут быть тексты разной длины."
      ],
      "metadata": {
        "id": "U5S2NXibWdQ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для решения второй проблемы можно воспользоваться функцией `torch.nn.utils.rnn.pack_padded_sequence`. \n",
        "\n",
        "Принимая на вход батч тензоров и длину каждого тензора без учёта паддинга эта функция позволяет получить все элементы в тензорах, которые не относятся к паддингу в виде плоского массива:"
      ],
      "metadata": {
        "id": "63ATyQroWdQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "padded_tensors = torch.tensor([\n",
        "    [[1, 11, 111], [2, 22, 222], [3, 33, 333]],\n",
        "    [[4, 44, 444], [5, 55, 555], [6, 66, 666]],\n",
        "    [[7, 77, 777], [0, 0, 0], [8, 88, 888]],\n",
        "    [[9, 99, 999], [0, 0, 0], [0, 0, 0]]\n",
        "])\n",
        "tensors_lens = torch.tensor([4, 2, 3])"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:54:40.004897Z",
          "start_time": "2021-04-02T00:54:39.977287Z"
        },
        "id": "0X5uB3GFWdQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обратите внимание, что `torch.nn.utils.rnn.pack_padded_sequence` автоматически переупорядочивает тензоры в батче по убыванию их длины."
      ],
      "metadata": {
        "id": "8jnRfZvzWdRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.nn.utils.rnn.pack_padded_sequence(padded_tensors, tensors_lens, batch_first=False, enforce_sorted=False)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:54:24.517023Z",
          "start_time": "2021-04-02T00:54:24.490588Z"
        },
        "id": "U9Blwi5RWdRB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6c3906e-fa88-43e0-a8f7-dc295b4fee8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PackedSequence(data=tensor([[  1,  11, 111],\n",
              "        [  3,  33, 333],\n",
              "        [  2,  22, 222],\n",
              "        [  4,  44, 444],\n",
              "        [  6,  66, 666],\n",
              "        [  5,  55, 555],\n",
              "        [  7,  77, 777],\n",
              "        [  8,  88, 888],\n",
              "        [  9,  99, 999]]), batch_sizes=tensor([3, 3, 2, 1]), sorted_indices=tensor([0, 2, 1]), unsorted_indices=tensor([0, 2, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LMCrossEntropyLoss(torch.nn.CrossEntropyLoss):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        \n",
        "    def forward(self, outputs, tokens, tokens_lens):\n",
        "        \"\"\"\n",
        "        :param torch.tensor outputs: Output from RNNLM.forward. Shape: [T, B, V]\n",
        "        :param torch.tensor tokens: Batch of tokens. Shape: [T, B]\n",
        "        :param torch.tensor tokens_lens: Length of each sequence in batch\n",
        "        :return torch.tensor: CrossEntropyLoss between corresponding logits and tokens\n",
        "        \"\"\"\n",
        "        # Use torch.nn.utils.rnn.pack_padded_sequence().data to remove padding and flatten logits and tokens\n",
        "        # Do not forget specify enforce_sorted=False and correct value of batch_first \n",
        "        # YOUR CODE HERE\n",
        "        packed_outputs = torch.nn.utils.rnn.pack_padded_sequence(outputs, tokens_lens.cpu() + 1, batch_first=False, enforce_sorted=False).data\n",
        "        packed_tokens = torch.nn.utils.rnn.pack_padded_sequence(tokens[1:], tokens_lens.cpu() + 1, batch_first=False, enforce_sorted=False).data\n",
        "        \n",
        "        # Use super().forward(..., ...) to compute CrossEntropyLoss\n",
        "        # YOUR CODE HERE\n",
        "        \n",
        "        ce_loss = super().forward(packed_outputs, packed_tokens)\n",
        "        return ce_loss"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T02:07:06.289671Z",
          "start_time": "2021-04-02T02:07:06.262883Z"
        },
        "id": "33Vu3B1rWdRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для оценки качества нам также необходимо вычислять долю правильно предсказанных токенов. Реализуйте класс для вычисления точности."
      ],
      "metadata": {
        "id": "4aScA9uTWdRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LMAccuracy(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "    def forward(self, outputs, tokens, tokens_lens):\n",
        "        \"\"\"\n",
        "        :param torch.tensor outputs: Output from RNNLM.forward. Shape: [T, B, V]\n",
        "        :param torch.tensor tokens: Batch of tokens. Shape: [T, B]\n",
        "        :param torch.tensor tokens_lens: Length of each sequence in batch\n",
        "        :return torch.tensor: Accuracy for given logits and tokens\n",
        "        \"\"\"\n",
        "        # Use torch.nn.utils.rnn.pack_padded_sequence().data to remove padding and flatten logits and tokens\n",
        "        # Do not forget specify enforce_sorted=False and correct value of batch_first \n",
        "        # YOUR CODE HERE\n",
        "        packed_outputs = torch.nn.utils.rnn.pack_padded_sequence(outputs, tokens_lens.cpu() + 1, batch_first=False, enforce_sorted=False).data\n",
        "        packed_tokens = torch.nn.utils.rnn.pack_padded_sequence(tokens[1:], tokens_lens.cpu() + 1, batch_first=False, enforce_sorted=False).data\n",
        "        \n",
        "        \n",
        "        preds = packed_outputs.argmax(axis=1)\n",
        "        return (preds == packed_tokens).sum()"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T02:07:07.335981Z",
          "start_time": "2021-04-02T02:07:07.309586Z"
        },
        "id": "lnHoF69hWdRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модифицируйте функции `train_epoch`, `evaluate`, `train` для обучения LM.\n",
        "\n",
        "**При вычислении точности, обратите внимание на то, что мы не предсказываем первый токен в каждой последовательности и токены, относящиеся к паддингу.**"
      ],
      "metadata": {
        "id": "SmYboke0WdRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch_lm(dataloader, model, loss_fn, optimizer, device):\n",
        "    model.train()\n",
        "    for idx, data in enumerate(dataloader):\n",
        "        # 1. Take data from batch\n",
        "        # 2. Perform forward pass\n",
        "        # 3. Evaluate loss\n",
        "        # 4. Make optimizer step\n",
        "        # YOUR CODE HERE\n",
        "        model.zero_grad()\n",
        "        tokens = data['tokens'].to(device)\n",
        "        tokens_lens = data['tokens_lens'].to(device)\n",
        "        res = model(tokens, tokens_lens)\n",
        "        loss = loss_fn(res, tokens, tokens_lens)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "def evaluate_lm(dataloader, model, loss_fn, device):\n",
        "    model.eval()\n",
        "    \n",
        "    total_tokens = 0\n",
        "    total_loss = 0.0\n",
        "    total_accuracy = 0.0\n",
        "    \n",
        "    accuracy_fn = LMAccuracy()\n",
        "    with torch.no_grad():\n",
        "        for idx, data in enumerate(dataloader):\n",
        "            # 1. Take data from batch\n",
        "            # 2. Perform forward pass\n",
        "            # 3. Evaluate loss\n",
        "            # 4. Evaluate accuracy\n",
        "            # YOUR CODE HERE\n",
        "            tokens = data['tokens'].to(device)\n",
        "            tokens_lens = data['tokens_lens'].to(device)\n",
        "            res = model(tokens, tokens_lens)\n",
        "            loss = loss_fn(res, tokens, tokens_lens).item()\n",
        "            accuracy = accuracy_fn(res, tokens, tokens_lens).item()\n",
        "            tokens_num = (tokens_lens).sum().item()\n",
        "            total_loss += loss * tokens_num\n",
        "            total_accuracy += accuracy\n",
        "            total_tokens += tokens_num \n",
        "\n",
        "    return total_loss / total_tokens, total_accuracy / total_tokens\n",
        "\n",
        "def train_lm(\n",
        "    train_loader, test_loader, model, loss_fn, optimizer, device, num_epochs\n",
        "):\n",
        "    test_losses = []\n",
        "    train_losses = []\n",
        "    test_accuracies = []\n",
        "    train_accuracies = []\n",
        "    for epoch in range(num_epochs):\n",
        "        train_epoch_lm(train_loader, model, loss_fn, optimizer, device)\n",
        "        \n",
        "        train_loss, train_acc = evaluate_lm(train_loader, model, loss_fn, device)\n",
        "        train_accuracies.append(train_acc)\n",
        "        train_losses.append(train_loss)\n",
        "        \n",
        "        test_loss, test_acc = evaluate_lm(test_loader, model, loss_fn, device)\n",
        "        test_accuracies.append(test_acc)\n",
        "        test_losses.append(test_loss)\n",
        "        \n",
        "        print(\n",
        "            'Epoch: {0:d}/{1:d}. Loss (Train/Test): {2:.3f}/{3:.3f}. Accuracy (Train/Test): {4:.3f}/{5:.3f}'.format(\n",
        "                epoch + 1, num_epochs, train_losses[-1], test_losses[-1], train_accuracies[-1], test_accuracies[-1]\n",
        "            )\n",
        "        )\n",
        "    return train_losses, train_accuracies, test_losses, test_accuracies"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T02:07:31.492984Z",
          "start_time": "2021-04-02T02:07:31.459655Z"
        },
        "id": "gQ8ZuRDCWdRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь у нас всё готово для обучения модели."
      ],
      "metadata": {
        "id": "PFyJrENPWdRG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим словарь с `<sos>`, `<eos>` токенами.\n",
        "\n",
        "Обратите внимание, что в отличие от классификации текстов нам необходимо значительно увеличить размер словаря, чтобы доля `<unk>` токенов была не велика.\n",
        "\n",
        "Так же, так как задача генерации значительно сложнее задачи классификации текстов будем обучать модель только на префиксах рецензий длины $20$. Это позволяет значительно ускорить обучение."
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T01:06:12.73618Z",
          "start_time": "2021-04-02T01:06:12.708814Z"
        },
        "id": "qJe_nP6oWdRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "specials = ['<pad>', '<unk>', '<sos>', '<eos>']\n",
        "for special in specials:\n",
        "    counter[special] = 0\n",
        "# min_freq=8 is approximately equivalent to max_size=30000. You can lower min_freq in order to make model vocabulary more diverse \n",
        "#lm_vocab = torchtext.vocab.vocab(counter, specials=specials, special_first=True, min_freq=8)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:06:20.093645Z",
          "start_time": "2021-04-02T00:06:19.926668Z"
        },
        "id": "ovrTcpjoWdRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_by_freq_tuples = sorted(counter.items(), key=lambda x: x[1], reverse=True)[:30000]\n",
        "ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
        "lm_vocab = torchtext.vocab.vocab(ordered_dict)\n",
        "lm_vocab.insert_token('<pad>', 0)\n",
        "lm_vocab.insert_token('<unk>', 1)\n",
        "lm_vocab.insert_token('<sos>', 2)\n",
        "lm_vocab.insert_token('<eos>', 3)\n",
        "lm_vocab.set_default_index(vocab['<unk>'])"
      ],
      "metadata": {
        "id": "FajmI2UVeyVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lm_test_dataset = LargeMovieReviewDataset(test_data_path, lm_vocab, max_len=20, pad_sos=True, pad_eos=True)\n",
        "lm_train_dataset = LargeMovieReviewDataset(train_data_path, lm_vocab, max_len=20, pad_sos=True, pad_eos=True)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T00:06:58.566893Z",
          "start_time": "2021-04-02T00:06:21.430692Z"
        },
        "id": "GAjvLOJyWdRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим даталоадеры для тестовой и обучающей выборок:"
      ],
      "metadata": {
        "id": "rMTI13bAWdRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lm_test_dataloader = DataLoader(\n",
        "    lm_test_dataset, batch_size=96, shuffle=False, num_workers=3, \n",
        "    collate_fn=partial(collate_fn, padding_value=lm_vocab.lookup_indices(['<pad>'])[0])\n",
        ")\n",
        "lm_train_dataloader = DataLoader(\n",
        "    lm_train_dataset, batch_size=96, shuffle=True, num_workers=3, \n",
        "    collate_fn=partial(collate_fn, padding_value=lm_vocab.lookup_indices(['<pad>'])[0])\n",
        ")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T12:29:16.213723Z",
          "start_time": "2021-04-02T12:29:16.186954Z"
        },
        "id": "cqpf6hxZWdRK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3be7edad-e1bd-4d9a-967b-63949a213af5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Убедитесь, что все предложения имеют в начале `<sos>` токен, а в конце -- `<eos>` токен."
      ],
      "metadata": {
        "id": "r_ggtK_MWdRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(lm_train_dataloader))\n",
        "batch['tokens'], batch['tokens_lens']"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T12:29:17.218115Z",
          "start_time": "2021-04-02T12:29:16.922801Z"
        },
        "id": "-nZFeTBiWdRM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96d7b345-e208-41d8-c86a-56e17a92fa91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[    2,     2,     2,  ...,     2,     2,     2],\n",
              "         [  520,   488,     4,  ...,  1095,   107,    75],\n",
              "         [   30,  7094,  2963,  ...,     4,     5,     9],\n",
              "         ...,\n",
              "         [   48, 18526,  1208,  ...,   782,     5,  2401],\n",
              "         [   14,   376,    33,  ...,   400,   626,   361],\n",
              "         [    3,     3,     3,  ...,     3,     3,     3]]),\n",
              " tensor([20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
              "         20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
              "         20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
              "         20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
              "         20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
              "         20, 20, 20, 20, 20, 20]))"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим модель, функцию потерь и оптимизатор: "
      ],
      "metadata": {
        "id": "WysUXYsjWdRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lm_model = RNNLM(\n",
        "    embedding_dim=512, hidden_dim=512, vocab=lm_vocab, dropout=0.6, layers_dropout=0.6, num_layers=2\n",
        ").to(device=device)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T14:15:32.916424Z",
          "start_time": "2021-04-02T14:15:32.525452Z"
        },
        "id": "2F_yodWqWdRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lm_loss_fn = LMCrossEntropyLoss(reduction='mean')\n",
        "lm_optimizer = torch.optim.Adam(lm_model.parameters(), lr=0.005, weight_decay=1.2e-6)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T14:15:33.332806Z",
          "start_time": "2021-04-02T14:15:33.307749Z"
        },
        "id": "AbGoPO7YWdRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучим модель:"
      ],
      "metadata": {
        "id": "yFujHKKkWdRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "    \n",
        "    lm_train_losses, lm_train_accuracies, lm_test_losses, lm_test_accuracies = train_lm(\n",
        "        lm_train_dataloader, lm_test_dataloader, lm_model, lm_loss_fn, lm_optimizer, device, 10\n",
        "    )"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T14:20:33.447251Z",
          "start_time": "2021-04-02T14:15:33.797444Z"
        },
        "scrolled": true,
        "id": "T00zToduWdRQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13a17e29-8a92-434e-87c1-92ca05dbc64e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/10. Loss (Train/Test): 7.605/7.738. Accuracy (Train/Test): 0.075/0.075\n",
            "Epoch: 2/10. Loss (Train/Test): 7.382/7.581. Accuracy (Train/Test): 0.086/0.085\n",
            "Epoch: 3/10. Loss (Train/Test): 7.171/7.469. Accuracy (Train/Test): 0.093/0.091\n",
            "Epoch: 4/10. Loss (Train/Test): 6.974/7.383. Accuracy (Train/Test): 0.099/0.096\n",
            "Epoch: 5/10. Loss (Train/Test): 6.780/7.336. Accuracy (Train/Test): 0.104/0.100\n",
            "Epoch: 6/10. Loss (Train/Test): 6.595/7.306. Accuracy (Train/Test): 0.110/0.104\n",
            "Epoch: 7/10. Loss (Train/Test): 6.459/7.326. Accuracy (Train/Test): 0.114/0.105\n",
            "Epoch: 8/10. Loss (Train/Test): 6.280/7.321. Accuracy (Train/Test): 0.120/0.107\n",
            "Epoch: 9/10. Loss (Train/Test): 6.130/7.331. Accuracy (Train/Test): 0.124/0.108\n",
            "Epoch: 10/10. Loss (Train/Test): 5.992/7.369. Accuracy (Train/Test): 0.130/0.109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Реализация декодера. (2 балла)"
      ],
      "metadata": {
        "id": "8oVLs-DHWdRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь, реализуем последнюю деталь -- декодирование с использованием обученной модели.\n",
        "Есть несколько вариантов. Рассмотрим два самых простых:\n",
        "1. **Жадное декодирование.** На каждом шаге мы выбираем токен с максимальной вероятностью и используем его для обновления скрытого состояния RNN.\n",
        "2. **Top-k sampling.** На очередном шаге рассматриваются $k$ токенов с самыми большими вероятностями. Остальные токены игнорируются. Из выбранных токенов семплируется следующий токен пропорционально их вероятностям.\n",
        "\n",
        "Прочитать подробнее про разные варианты декодирования можно по ссылкам:\n",
        "1. [От huggingface](https://huggingface.co/blog/how-to-generate)\n",
        "2. [На towardsdatascience](https://towardsdatascience.com/decoding-strategies-that-you-need-to-know-for-response-generation-ba95ee0faadc)"
      ],
      "metadata": {
        "id": "-H5he49sWdRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Существенным в процессе декодирования является критерий останова. Как только очередной самый вероятный символ оказался `<eos>`, то данная последовательность считается сгенерированной. Однако, может так оказаться, что `<eos>` никогда не будет выбран, тогда необходимо прекратить генерацию, как только длина последовательности перейдёт порог `max_generated_len`."
      ],
      "metadata": {
        "id": "hZ-u1n6EWdRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decode(model, start_tokens, start_tokens_lens, max_generated_len=20, top_k=None):\n",
        "    \"\"\"\n",
        "    :param RNNLM model: Model\n",
        "    :param torch.tensor start_tokens: Batch of seed tokens. Shape: [T, B]\n",
        "    :param torch.tensor start_tokens_lens: Length of each sequence in batch. Shape: [B]\n",
        "    :return Tuple[torch.tensor, torch.tensor]. Newly predicted tokens and length of generated part. Shape [T*, B], [B]\n",
        "    \"\"\"\n",
        "    # Get embedding for start_tokens\n",
        "    # YOUR CODE HERE\n",
        "    embedding = model.word_embeddings(start_tokens)\n",
        "    \n",
        "    # Pass embedding through rnn and collect hidden states and cell states for each time moment\n",
        "    all_h, all_c = [], []\n",
        "    h = embedding.new_zeros([model.rnn.num_layers, start_tokens.shape[1], model.hidden_dim])\n",
        "    c = embedding.new_zeros([model.rnn.num_layers, start_tokens.shape[1], model.hidden_dim])\n",
        "    for time_step in range(start_tokens.shape[0]):\n",
        "        res, (h, c) = model.rnn(embedding[time_step].unsqueeze(dim=0), (h, c))\n",
        "        all_h.append(h)\n",
        "        all_c.append(c)\n",
        "    \n",
        "    all_h = torch.stack(all_h, dim=1)\n",
        "    all_c = torch.stack(all_c, dim=1)\n",
        "    # Take final hidden state and cell state for each start sequence in batch\n",
        "    # We will use them as h_0, c_0 for generation new tokens\n",
        "    h = all_h[:, start_tokens_lens - 1, torch.arange(start_tokens_lens.shape[0])]\n",
        "    c = all_c[:, start_tokens_lens - 1, torch.arange(start_tokens_lens.shape[0])]\n",
        "    \n",
        "    # List of predicted tokens for each time step\n",
        "    predicted_tokens = []\n",
        "    # Length of generated part for each object in the batch\n",
        "    decoded_lens = torch.zeros_like(start_tokens_lens, dtype=torch.long)\n",
        "    # Boolean mask where we store if the sequence has already generated\n",
        "    # i.e. `<eos>` was selected on any step\n",
        "    is_finished_decoding = torch.zeros_like(start_tokens_lens, dtype=torch.bool)\n",
        "    \n",
        "    # Stop when all sequences in the batch are finished\n",
        "    while not torch.all(is_finished_decoding) and torch.max(decoded_lens) < max_generated_len:\n",
        "        # Evaluate next token distribution using hidden state h.\n",
        "        # Note. Over first dimension h has hidden states for each layer of LSTM.\n",
        "        #     We must use hidden state from the last layer\n",
        "        # YOUR CODE HERE\n",
        "        logits = model.output(h[-1])\n",
        "        \n",
        "        if top_k is not None:\n",
        "            # Top-k sampling. Use only top-k most probable logits to sample next token\n",
        "            indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n",
        "            # Mask non top-k logits\n",
        "            logits[indices_to_remove] = -1e10\n",
        "            # Sample next_token. \n",
        "            # YOUR CODE HERE\n",
        "            next_token = torch.distributions.categorical.Categorical(logits=logits).sample()\n",
        "        else:\n",
        "            # Select most probable token\n",
        "            # YOUR CODE HERE\n",
        "            next_token = logits.argmax(axis=1)\n",
        "            \n",
        "        predicted_tokens.append(next_token)\n",
        "        \n",
        "        decoded_lens += (~is_finished_decoding)\n",
        "        is_finished_decoding |= (next_token == torch.tensor(model.vocab.lookup_indices(['<eos>'])[0]))\n",
        "\n",
        "        # Evaluate embedding for next token\n",
        "        # YOUR CODE HERE\n",
        "        embedding = model.word_embeddings(next_token)\n",
        "\n",
        "        # Update hidden and cell states\n",
        "        # YOUR CODE HERE\n",
        "        res, (h, c) = model.rnn(embedding.unsqueeze(dim=0), (h, c))\n",
        "\n",
        "    return torch.stack(predicted_tokens), decoded_lens"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T14:28:21.578336Z",
          "start_time": "2021-04-02T14:28:21.547183Z"
        },
        "id": "S9H7kzg6WdRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попробуем сгенерировать продолжения для нескольких префиксов:"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T01:38:06.232189Z",
          "start_time": "2021-04-02T01:38:06.205413Z"
        },
        "id": "YIwZCn72WdRT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_tokens = torch.tensor([\n",
        "    lm_model.vocab.lookup_indices(['<sos>', '<pad>', '<pad>', '<pad>']),\n",
        "    lm_model.vocab.lookup_indices(['<sos>', 'my', 'favorite', 'movie']),\n",
        "    lm_model.vocab.lookup_indices(['<sos>', 'the', 'best', 'movie']),\n",
        "    lm_model.vocab.lookup_indices(['<sos>', 'the', 'worst', 'movie']),\n",
        "]).T\n",
        "\n",
        "start_tokens_lens = torch.tensor([1, 4, 4, 4])"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T14:28:22.568613Z",
          "start_time": "2021-04-02T14:28:22.54581Z"
        },
        "id": "gWT8mS3VWdRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lm_model = lm_model.cpu()\n",
        "lm_model.eval()\n",
        "decoded_tokens, decoded_lens = decode(lm_model, start_tokens, start_tokens_lens, max_generated_len=20, top_k=5)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T14:28:28.222137Z",
          "start_time": "2021-04-02T14:28:27.930196Z"
        },
        "id": "iStqfHFlWdRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for text_idx in range(start_tokens.shape[1]):\n",
        "    decoded_text_tokens = decoded_tokens[:decoded_lens[text_idx], text_idx]\n",
        "    tokens = start_tokens[:start_tokens_lens[text_idx], text_idx].tolist() + decoded_text_tokens.tolist()\n",
        "    words = np.array(lm_model.vocab.get_itos())[np.array(tokens)]\n",
        "    print(' '.join(words))"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T14:28:28.75138Z",
          "start_time": "2021-04-02T14:28:28.708461Z"
        },
        "id": "YpQAJCgDWdRV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd591375-7241-475e-b9a4-3af421088887"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sos> movie really bad bad acting bad acting bad script bad acting bad directing bad effects bad acting bad special effects\n",
            "<sos> <unk> favorite movie ever seen life movie one best movies ever made movie seen one favorite movies seen year later movie one <eos>\n",
            "<sos> <unk> best movie ever seen movie ever seen life movie made people get back watching movie really liked movie much <eos>\n",
            "<sos> <unk> worst movie ever seen life life like movies like one worse movies ever seen worse acting atrocious script horrible acting <eos>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попробуйте выполнить семплирование для разных $k$. Сравните результаты top-k семплирования с жадным декодированием. Опишите ваши наблюдения."
      ],
      "metadata": {
        "id": "0sEBTaW_WdRW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Рассмотрим жадное декодирование."
      ],
      "metadata": {
        "id": "Dmh8K5OiJaPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "decoded_tokens, decoded_lens = decode(lm_model, start_tokens, start_tokens_lens, max_generated_len=20, top_k=None)\n",
        "for text_idx in range(start_tokens.shape[1]):\n",
        "    decoded_text_tokens = decoded_tokens[:decoded_lens[text_idx], text_idx]\n",
        "    tokens = start_tokens[:start_tokens_lens[text_idx], text_idx].tolist() + decoded_text_tokens.tolist()\n",
        "    words = np.array(lm_model.vocab.get_itos())[np.array(tokens)]\n",
        "    print(' '.join(words))"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T17:06:36.404126Z",
          "start_time": "2021-04-02T17:06:36.399654Z"
        },
        "id": "eM7rEQ5mWdRX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ff9c77e-9137-4db2-8556-971522468ebb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sos> movie bad acting bad acting bad directing bad acting bad directing bad special effects bad acting bad special effects bad\n",
            "<sos> <unk> favorite movie ever seen movie really liked movie like movie like movie like movie like movie like movie like movie like <eos>\n",
            "<sos> <unk> best movie ever seen life movie like movie like movie like movie like movie like movie like movie like movie like <eos>\n",
            "<sos> <unk> worst movie ever seen life movie bad acting bad acting bad special effects bad acting bad special effects bad acting bad <eos>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Переберем различные значения k для стратегии top-k."
      ],
      "metadata": {
        "id": "J0quyOv-JwKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k_values = np.arange(1, 21, dtype=int)\n",
        "\n",
        "for k in k_values:\n",
        "    print(f'k={k}:')\n",
        "    decoded_tokens, decoded_lens = decode(lm_model, start_tokens, start_tokens_lens, max_generated_len=20, top_k=k)\n",
        "    for text_idx in range(start_tokens.shape[1]):\n",
        "        decoded_text_tokens = decoded_tokens[:decoded_lens[text_idx], text_idx]\n",
        "        tokens = start_tokens[:start_tokens_lens[text_idx], text_idx].tolist() + decoded_text_tokens.tolist()\n",
        "        words = np.array(lm_model.vocab.get_itos())[np.array(tokens)]\n",
        "        print(' '.join(words))\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRr5NrPEJ2nP",
        "outputId": "9c753cba-cff1-401e-d591-9ba2f12fe651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k=1:\n",
            "<sos> movie bad acting bad acting bad directing bad acting bad directing bad special effects bad acting bad special effects bad\n",
            "<sos> <unk> favorite movie ever seen movie really liked movie like movie like movie like movie like movie like movie like movie like <eos>\n",
            "<sos> <unk> best movie ever seen life movie like movie like movie like movie like movie like movie like movie like movie like <eos>\n",
            "<sos> <unk> worst movie ever seen life movie bad acting bad acting bad special effects bad acting bad special effects bad acting bad <eos>\n",
            "\n",
            "k=2:\n",
            "<sos> movie bad acting bad acting bad script bad acting bad directing bad special effects bad acting bad special effects bad\n",
            "<sos> <unk> favorite movie seen movie since years ago still liked movie much better movie like movie like movie movie shows <eos>\n",
            "<sos> <unk> best movie ever made life movie ever made movie made one movies like one movies like movie like movie <eos>\n",
            "<sos> <unk> worst movie ever seen life bad acting bad directing terrible acting bad special effects bad acting bad editing bad acting bad <eos>\n",
            "\n",
            "k=3:\n",
            "<sos> one worst movies ever made one worst movies ever seen life movie ever made life bad movie bad acting bad\n",
            "<sos> <unk> favorite movie seen years old daughter remember watching movie theater saw movie theater time ago saw movie years ago still <eos>\n",
            "<sos> <unk> best movie seen long time watching movie first time see one favorite movies seen long time see one favorite movies ever seen\n",
            "<sos> <unk> worst movie ever seen one worst movie ever seen life bad acting bad acting bad special effects bad acting bad <eos>\n",
            "\n",
            "k=4:\n",
            "<sos> movie great example movie great job movie good job like movie good movie like movie good job like movie good\n",
            "<sos> <unk> favorite movie seen many times one movies seen year old daughter movie one best movies ever seen life one <eos>\n",
            "<sos> <unk> best movie ever seen one best movies ever seen saw movie one best movies ever seen life even worse movie ever made\n",
            "<sos> <unk> worst movie ever seen movie bad one movies ever made one worst movies ever seen life even worse movies ever made movie\n",
            "\n",
            "k=5:\n",
            "<sos> film great acting great cast excellent story line good story line characters good job story line good story good story\n",
            "<sos> <unk> favorite movie ever seen life like movie movie bad movie ever watched movie almost even though movie bad acting bad bad <eos>\n",
            "<sos> <unk> best movie ever seen saw movie first movie ever seen movie since saw dvd years old daughter movie really love <eos>\n",
            "<sos> <unk> worst movie ever seen life movie one worst seen movie ever made bad acting bad script bad effects bad <eos>\n",
            "\n",
            "k=6:\n",
            "<sos> first saw movie theater time time ago found really bad one movies seen bad movies like like movie one worst\n",
            "<sos> <unk> favorite movie one favorite movies ever seen life movie really liked movie like many times like love movies like love story <eos>\n",
            "<sos> <unk> best movie ever seen one best movies ever seen movie even worse movie could better even though one movies ever see <eos>\n",
            "<sos> <unk> worst movie ever seen plot totally boring plot ridiculous acting atrocious plot bad special effects terrible acting horrible directing bad <eos>\n",
            "\n",
            "k=7:\n",
            "<sos> saw movie years ago one afternoon one worst movies ever made one ever seen worse movies ever watched movie <eos>\n",
            "<sos> <unk> favorite movie seen long ago movie theater movie came back one favorites movie could give movie would recommend movie <eos>\n",
            "<sos> <unk> best movie ever made certainly worst ever seen bad acting bad effects bad special effects bad acting bad <eos>\n",
            "<sos> <unk> worst movie ever seen life bad movie nothing bad even worse acting terrible script terrible special effects horrible special effects whatsoever <eos>\n",
            "\n",
            "k=8:\n",
            "<sos> movie terrible acting terrible bad effects bad plot totally predictable bad script bad script bad acting bad editing bad script\n",
            "<sos> <unk> favorite movie seen long time ago watching one movies like <unk> great job like great movie good acting movie <eos>\n",
            "<sos> <unk> best movie ever made movie ever seen life really funny movies made movie like many times like movie <eos>\n",
            "<sos> <unk> worst movie ever seen life even witless movie made good plot bad acting bad special effects acting bad directing bad directing bad\n",
            "\n",
            "k=9:\n",
            "<sos> film made lot <unk> good story good idea great acting excellent characters good performances excellent photography values good plot twists\n",
            "<sos> <unk> favorite movie time movie good acting good job good story line also really bad movie bad plot good movie <eos>\n",
            "<sos> <unk> best movie ever seen first time life like story line interesting character development one favorite movies ever seen life <eos>\n",
            "<sos> <unk> worst movie ever seen plot <unk> plot totally awful acting atrocious plot bad acting atrocious editing bad special effects terrible special effects\n",
            "\n",
            "k=10:\n",
            "<sos> first saw movie yesterday years old daughter saw movie year ago loved movie even liked many years ago never seen\n",
            "<sos> <unk> favorite movie movie ever really liked seeing first time see movie first time movie found movie really liked movie like <eos>\n",
            "<sos> <unk> best movie ever made movie ever see seen movie one best movie ever made story line movie made people get back watching\n",
            "<sos> <unk> worst movie ever seen seen worse plot movie sucks even worse acting poor special effects bad everything terrible acting terrible <eos>\n",
            "\n",
            "k=11:\n",
            "<sos> film one favourite movies ever made film <unk> beautiful story line like two actors <unk> <unk> film <unk> <unk> <unk>\n",
            "<sos> <unk> favorite movie ever made movie <unk> life good one good acting good movie great see movie great job also <eos>\n",
            "<sos> <unk> best movie ever seen movie one best movies seen worse seen long time watching movie one best movies seen year old movie\n",
            "<sos> <unk> worst movie ever made surpassing movies like like bad guy bad guys worse movie bad even bad even worse bad <eos>\n",
            "\n",
            "k=12:\n",
            "<sos> film bad acting bad acting horrible special effects bad writing acting bad special effects movie could written bad plot terrible\n",
            "<sos> <unk> favorite movie seen long time life back time remember see movie really think movie made many problems people know going see movie\n",
            "<sos> <unk> best movie ever made life <unk> every time time saw movie movie one movies really like movie like <eos>\n",
            "<sos> <unk> worst movie ever made bad bad movies bad movie really bad bad movies like bad acting bad bad bad <eos>\n",
            "\n",
            "k=13:\n",
            "<sos> one worst movies ever seen saw last night see first half hour watching film <unk> <unk> one better bad movie\n",
            "<sos> <unk> favorite movie seen times time time watch loved every time watching movie see one favorite <unk> ever seen loved movie movie <eos>\n",
            "<sos> <unk> best movie ever seen movie <unk> funny movie made watch movie bad acting awful bad story ridiculous plot bad editing <eos>\n",
            "<sos> <unk> worst movie ever saw film one worst films ever made one could make movie bad movie bad bad acting bad editing effects\n",
            "\n",
            "k=14:\n",
            "<sos> rented film thought film really love one two people see story good acting good characters especially characters really really found\n",
            "<sos> <unk> favorite movie seen times years ago remember see movie thought great one best ever seen movie long running life first half time\n",
            "<sos> <unk> best movie ever seen life like movie could considered better movie like <unk> even worse movies seen lot people <eos>\n",
            "<sos> <unk> worst movie ever seen life plot bad acting terrible casting terrible acting bad special effects horrible directing acting <eos>\n",
            "\n",
            "k=15:\n",
            "<sos> remember seeing series yesterday first saw last years old boy year old kid still wanted see movie even though <unk>\n",
            "<sos> <unk> favorite movie made long time watch one thing movie great cast actors great cast good casting great job story good <eos>\n",
            "<sos> <unk> best movie ever seen life seen one times first saw movie time first released movie even though like movie movie good movie\n",
            "<sos> <unk> worst movie ever seen acting worst seen long time watching film acting poor acting bad directing bad direction bad <eos>\n",
            "\n",
            "k=16:\n",
            "<sos> one worst film ever made entire family one time favorites even witless plot non existent acting atrocious script wooden continuity\n",
            "<sos> <unk> favorite movie like lot <unk> good things even interesting plot twists twists done great acting good editing plot twists development <eos>\n",
            "<sos> <unk> best movie ever seen movie really liked movie bad casting great job really great plot totally ridiculous unrealistic plot development <eos>\n",
            "<sos> <unk> worst movie ever seen terrible film seen one reviewer said bad acting amateurish script really bad script bad editing bad acting bad\n",
            "\n",
            "k=17:\n",
            "<sos> first saw movie expecting forward seeing bad idea bad movies bad acting bad script effects awful script poor acting terrible\n",
            "<sos> <unk> favorite movie movie one favorite movies time watched movie one <unk> even though one funniest movies ever seen plot <unk> <eos>\n",
            "<sos> <unk> best movie ever seen seen worse even yaphet <unk> film really bad mean see lot people see watching bad movies made <eos>\n",
            "<sos> <unk> worst movie ever seen life life like like <unk> <unk> good movie watch one movies bad one better <eos>\n",
            "\n",
            "k=18:\n",
            "<sos> well done movie could possibly better <unk> <unk> movie ever made life movie would expect movie made like really <eos>\n",
            "<sos> <unk> favorite movie <unk> really good thing first movie seen one movies time seen years ago loved see film great movie <eos>\n",
            "<sos> <unk> best movie ever written poorly made poorly written made plot lines one <unk> first minutes story <unk> acting horrendous <eos>\n",
            "<sos> <unk> worst movie seen lot times really bad acting bad movie bad effects bad acting atrocious story bad <eos>\n",
            "\n",
            "k=19:\n",
            "<sos> remember film first film ever seen saw film thought going thinking good idea <unk> first saw movie times like movie\n",
            "<sos> <unk> favorite movie buff one favorites great movies good thing seen lot laugh cry one point see movie like good <eos>\n",
            "<sos> <unk> best movie seen years old years seen every time time remember movie theater watching movie movie came see great <eos>\n",
            "<sos> <unk> worst movie ever made seen lot sense plot goes plot movie totally slow depth totally slow lacking acting lacklustre scripting <eos>\n",
            "\n",
            "k=20:\n",
            "<sos> first time saw film ago found much enjoyed something really great thing got great one best movies ever made think\n",
            "<sos> <unk> favorite movie like movies seen lot times like many reasons movie made <unk> think movies made one good one watch <eos>\n",
            "<sos> <unk> best movie ever seen saw <unk> movie theater saw movies times really enjoy bad movies like like watching many times <eos>\n",
            "<sos> <unk> worst movie ever seen seen long time <unk> even though ever encountered <unk> really bad bad taste even worse worse <eos>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ответ:**\n",
        "\n",
        "Стратегия жадного сэмплирования выдает результат, идентичный стратегии с top-k=1. При малых k генерируются однообразные, простые и повторяющиеся слова, с ростом k генерируются все более разнообразные и сложные слова, предложения в целом становятся сложнее и осмысленнее, с добавлением комментариев, похожих на реальные человеческие ('movie could possibly better', 'seen long ago movie theater', 'yesterday years old daughter saw movie' и т. д.), появляются токены \\<unk> среди остальных. В целом продолжения согласуются с соответствующими префиксами и достаточно логичны и адекватны."
      ],
      "metadata": {
        "id": "YHdjYd9VWdRY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Бонус. Cущественное улучшение качества. (до 3 баллов)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-02T15:04:51.67826Z",
          "start_time": "2021-04-02T15:04:51.673587Z"
        },
        "id": "9bfn8PwjWdRZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Та модель, которая использовалась в предыдущей части во многом заимствует улучшения LSTM из статьи [Regularizing and Optimizing LSTM Language Models](https://arxiv.org/pdf/1708.02182.pdf). Вы можете попробовать применить другие варианты регуляризации из данной статьи для существенного улучшения качества LM.\n",
        "\n",
        "Например:\n",
        "1. Dropout для эмбеддингов\n",
        "2. Dropout входов и выходов RNN\n",
        "3. Регуляризация активаций (AR/TAR)\n",
        "4. NT-ASGD\n",
        "5. Tied веса эмбеддингов и софтмакса"
      ],
      "metadata": {
        "id": "11P-Jej4WdRZ"
      }
    }
  ]
}